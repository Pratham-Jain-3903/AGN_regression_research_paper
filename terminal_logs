(venv_py310) PS D:\College\agn> python pipeline.py --train_path data/train.csv --test_path data\test.csv
2025-04-19 20:02:57,757 - INFO - Loading and analyzing data...
2025-04-19 20:02:57,850 - INFO - 
Dataset Shape: (7999, 102)
2025-04-19 20:02:58,030 - INFO - Saved dtypes report to viz/eda/dtypes_report.csv
2025-04-19 20:02:58,046 - INFO - Saved missing_values report to viz/eda/missing_values_report.csv
2025-04-19 20:02:58,046 - INFO - Saved duplicates report to viz/eda/duplicates_report.csv
2025-04-19 20:02:58,046 - INFO - Saved cardinality report to viz/eda/cardinality_report.csv
2025-04-19 20:02:58,046 - INFO - Saved statistics report to viz/eda/statistics_report.csv
2025-04-19 20:03:08,732 - INFO - Performing feature selection...
2025-04-19 20:03:52,063 - INFO - Selected 6 features: ['feature_11', 'feature_49', 'feature_43', 'feature_19', 'feature_92', 'feature_68']
2025-04-19 20:03:52,063 - INFO - Training models...
                    Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 7)
4        Transformed data shape     (7719, 7)
5   Transformed train set shape     (5319, 7)
6    Transformed test set shape     (2400, 7)
7              Numeric features             6
8      Rows with missing values         11.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          4697
Processing:  89%|████████████████████████████▌   | 67/75 [00:40<00:04,  1.71it/s][LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005312 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Start training from score 5.984631
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Start training from score 5.960250
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003836 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Start training from score 5.987939
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Start training from score 5.911782
[LightGBM] [Info] Start training from score 5.948892
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Start training from score 6.009292
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001131 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Start training from score 6.042987
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Start training from score 6.056294
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Number of data points in the train set: 4787, number of used features: 6
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000663 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1530
[LightGBM] [Info] Start training from score 6.073304
[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 6
[LightGBM] [Info] Start training from score 6.025740
                                    Model     MAE      MSE    RMSE      R2  \
huber                     Huber Regressor  4.9656  33.0402  5.7472  0.0020        
br                         Bayesian Ridge  4.9781  33.2121  5.7621 -0.0031        
lr                      Linear Regression  4.9761  33.2138  5.7622 -0.0032        
ridge                    Ridge Regression  4.9761  33.2138  5.7622 -0.0032        
lar                Least Angle Regression  4.9761  33.2138  5.7622 -0.0032        
omp           Orthogonal Matching Pursuit  4.9888  33.3210  5.7715 -0.0064        
lasso                    Lasso Regression  4.9895  33.3845  5.7769 -0.0083        
dummy                     Dummy Regressor  4.9895  33.3845  5.7769 -0.0083        
llar         Lasso Least Angle Regression  4.9895  33.3845  5.7769 -0.0083        
en                            Elastic Net  4.9895  33.3845  5.7769 -0.0083        
gbr           Gradient Boosting Regressor  5.0066  33.7994  5.8124 -0.0207        
ada                    AdaBoost Regressor  5.0177  33.9043  5.8217 -0.0240        
rf                Random Forest Regressor  5.0637  34.9523  5.9105 -0.0556        
et                  Extra Trees Regressor  5.0620  35.0699  5.9206 -0.0593        
lightgbm  Light Gradient Boosting Machine  5.0736  35.2796  5.9382 -0.0653        
knn                 K Neighbors Regressor  5.2601  39.4585  6.2804 -0.1921        
par          Passive Aggressive Regressor  6.2795  60.3220  7.7272 -0.8171        
dt                Decision Tree Regressor  6.6424  66.9268  8.1788 -1.0228        

           RMSLE    MAPE  TT (Sec)
huber     0.8068  1.1146     0.118
br        0.7988  1.0797     0.106
lr        0.7987  1.0785     0.664
ridge     0.7987  1.0785     0.108
lar       0.7987  1.0785     0.109
omp       0.7999  1.0871     0.109
lasso     0.8000  1.0859     0.108
dummy     0.8000  1.0859     0.116
llar      0.8000  1.0859     0.110
en        0.8000  1.0859     0.104
gbr       0.8017  1.0824     0.265
ada       0.7906  1.0375     0.143
rf        0.8069  1.0871     0.895
et        0.8076  1.0824     0.381
lightgbm  0.8102  1.0906     0.199
knn       0.8360  1.1138     0.110
par       0.9810  1.3032     0.109
dt        1.1192  1.3439     0.125
Processing:   0%|                                          | 0/7 [00:00<?, ?it/s]Fitting 10 folds for each of 10 candidates, totalling 100 fits
Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
         MAE      MSE    RMSE      R2   RMSLE    MAPE
Fold
0     4.9077  32.6710  5.7159  0.0045  0.7879  1.0920
1     4.9668  33.2981  5.7704  0.0157  0.8222  1.0164
2     4.9663  33.2869  5.7695 -0.0159  0.7851  1.1533
3     5.0498  33.4749  5.7857 -0.0000  0.7865  1.1532
4     4.8899  32.4832  5.6994  0.0117  0.8330  1.1234
5     4.9279  32.7694  5.7245 -0.0074  0.7978  1.0228
6     4.7615  31.0681  5.5739 -0.0005  0.7927  1.0915
7     4.8656  31.8331  5.6421  0.0025  0.7778  1.1153
8     5.2308  35.0937  5.9240  0.0164  0.8440  1.1606
9     5.0864  34.4358  5.8682 -0.0078  0.8512  1.2582
Mean  4.9653  33.0414  5.7474  0.0019  0.8078  1.1187
Std   0.1242   1.1112  0.0966  0.0101  0.0257  0.0669
Processing:   0%|                                          | 0/7 [00:00<?, ?it/s]Fitting 10 folds for each of 10 candidates, totalling 100 fits
Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
         MAE      MSE    RMSE      R2   RMSLE    MAPE
Fold
0     4.9256  32.9829  5.7431 -0.0050  0.7800  1.0545
1     5.0056  33.8328  5.8166 -0.0001  0.8152  0.9831
2     4.9639  33.3327  5.7734 -0.0173  0.7744  1.1063
3     5.0903  33.8322  5.8165 -0.0107  0.7782  1.1150
4     4.9286  32.8700  5.7332 -0.0000  0.8256  1.0895
5     4.9443  32.8498  5.7315 -0.0099  0.7880  0.9882
6     4.7523  30.9403  5.5624  0.0036  0.7822  1.0515
7     4.8572  31.8155  5.6405  0.0031  0.7677  1.0744
8     5.2389  35.3785  5.9480  0.0084  0.8358  1.1196
9     5.0697  34.2672  5.8538 -0.0029  0.8405  1.2128
Mean  4.9776  33.2102  5.7619 -0.0031  0.7987  1.0795
Std   0.1272   1.1833  0.1029  0.0074  0.0261  0.0637
Processing:   0%|                                          | 0/7 [00:00<?, ?it/s]Fitting 10 folds for each of 2 candidates, totalling 20 fits
Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
         MAE      MSE    RMSE      R2   RMSLE    MAPE
Fold
0     4.9234  32.9694  5.7419 -0.0046  0.7796  1.0531
1     4.9994  33.7900  5.8129  0.0012  0.8149  0.9823
2     4.9687  33.4050  5.7797 -0.0195  0.7752  1.1076
3     5.0869  33.8266  5.8161 -0.0105  0.7781  1.1138
4     4.9239  32.8333  5.7300  0.0011  0.8253  1.0880
5     4.9442  32.9031  5.7361 -0.0116  0.7883  0.9868
6     4.7530  30.9559  5.5638  0.0031  0.7822  1.0503
7     4.8549  31.8179  5.6407  0.0030  0.7676  1.0727
8     5.2355  35.3295  5.9439  0.0098  0.8351  1.1183
9     5.0716  34.3069  5.8572 -0.0040  0.8406  1.2119
Mean  4.9761  33.2138  5.7622 -0.0032  0.7987  1.0785
Std   0.1266   1.1732  0.1020  0.0082  0.0260  0.0638
         MAE      MSE    RMSE      R2   RMSLE    MAPE
Fold
0     4.9173  32.8424  5.7308 -0.0007  0.7821  1.0651
1     4.9909  33.6195  5.7982  0.0062  0.8170  0.9927
2     4.9637  33.2964  5.7703 -0.0162  0.7776  1.1203
3     5.0757  33.6792  5.8034 -0.0061  0.7805  1.1259
4     4.9138  32.7004  5.7184  0.0051  0.8276  1.0991
5     4.9386  32.8018  5.7273 -0.0084  0.7908  0.9980
6     4.7544  30.9388  5.5623  0.0037  0.7851  1.0631
7     4.8565  31.7718  5.6367  0.0045  0.7705  1.0858
8     5.2338  35.2323  5.9357  0.0125  0.8379  1.1314
9     5.0729  34.2850  5.8553 -0.0034  0.8436  1.2259
Mean  4.9717  33.1167  5.7538 -0.0003  0.8013  1.0907
Std   0.1257   1.1551  0.1005  0.0080  0.0260  0.0646
         MAE      MSE    RMSE      R2   RMSLE    MAPE
Fold
0     4.9244  32.9866  5.7434 -0.0051  0.7797  1.0530
1     4.9990  33.7812  5.8122  0.0014  0.8148  0.9821
2     4.9696  33.4195  5.7810 -0.0200  0.7752  1.1074
3     5.0867  33.8170  5.8152 -0.0102  0.7782  1.1143
4     4.9232  32.8319  5.7299  0.0011  0.8254  1.0885
5     4.9422  32.9105  5.7368 -0.0118  0.7884  0.9869
6     4.7530  30.9545  5.5637  0.0032  0.7823  1.0509
7     4.8561  31.8328  5.6421  0.0026  0.7677  1.0727
8     5.2359  35.3474  5.9454  0.0093  0.8352  1.1182
9     5.0720  34.3030  5.8569 -0.0039  0.8407  1.2123
Mean  4.9762  33.2184  5.7626 -0.0033  0.7988  1.0786
Std   0.1266   1.1733  0.1020  0.0082  0.0260  0.0639