2025-04-19 19:44:20,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:44:20,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:44:20,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:44:20,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:45:13,637:INFO:PyCaret RegressionExperiment
2025-04-19 19:45:13,637:INFO:Logging name: agn_modeling
2025-04-19 19:45:13,637:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 19:45:13,637:INFO:version 3.0.4
2025-04-19 19:45:13,637:INFO:Initializing setup()
2025-04-19 19:45:13,637:INFO:self.USI: b21c
2025-04-19 19:45:13,637:INFO:self._variable_keys: {'html_param', 'gpu_n_jobs_param', 'y', 'X', 'gpu_param', 'log_plots_param', 'n_jobs_param', 'target_param', 'memory', 'fold_groups_param', 'seed', 'fold_generator', 'exp_name_log', 'pipeline', '_available_plots', 'idx', 'X_test', 'exp_id', 'data', 'USI', 'transform_target_param', 'y_test', 'y_train', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'logging_param'}
2025-04-19 19:45:13,637:INFO:Checking environment
2025-04-19 19:45:13,637:INFO:python_version: 3.10.9
2025-04-19 19:45:13,637:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 19:45:13,639:INFO:machine: AMD64
2025-04-19 19:45:13,651:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:45:13,659:INFO:Memory: svmem(total=16952647680, available=4435275776, percent=73.8, used=12517371904, free=4435275776)
2025-04-19 19:45:13,659:INFO:Physical Core: 4
2025-04-19 19:45:13,659:INFO:Logical Core: 8
2025-04-19 19:45:13,659:INFO:Checking libraries
2025-04-19 19:45:13,659:INFO:System:
2025-04-19 19:45:13,659:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 19:45:13,659:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 19:45:13,659:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:45:13,660:INFO:PyCaret required dependencies:
2025-04-19 19:45:13,685:INFO:                 pip: 25.0.1
2025-04-19 19:45:13,685:INFO:          setuptools: 65.5.0
2025-04-19 19:45:13,685:INFO:             pycaret: 3.0.4
2025-04-19 19:45:13,685:INFO:             IPython: 8.35.0
2025-04-19 19:45:13,685:INFO:          ipywidgets: 8.1.6
2025-04-19 19:45:13,685:INFO:                tqdm: 4.67.1
2025-04-19 19:45:13,685:INFO:               numpy: 1.23.5
2025-04-19 19:45:13,685:INFO:              pandas: 1.5.3
2025-04-19 19:45:13,685:INFO:              jinja2: 3.1.6
2025-04-19 19:45:13,685:INFO:               scipy: 1.10.1
2025-04-19 19:45:13,686:INFO:              joblib: 1.2.0
2025-04-19 19:45:13,686:INFO:             sklearn: 1.2.2
2025-04-19 19:45:13,686:INFO:                pyod: 2.0.4
2025-04-19 19:45:13,686:INFO:            imblearn: 0.12.4
2025-04-19 19:45:13,686:INFO:   category_encoders: 2.7.0
2025-04-19 19:45:13,686:INFO:            lightgbm: 4.6.0
2025-04-19 19:45:13,686:INFO:               numba: 0.60.0
2025-04-19 19:45:13,686:INFO:            requests: 2.32.3
2025-04-19 19:45:13,686:INFO:          matplotlib: 3.7.1
2025-04-19 19:45:13,686:INFO:          scikitplot: 0.3.7
2025-04-19 19:45:13,686:INFO:         yellowbrick: 1.5
2025-04-19 19:45:13,686:INFO:              plotly: 5.24.1
2025-04-19 19:45:13,686:INFO:    plotly-resampler: Not installed
2025-04-19 19:45:13,686:INFO:             kaleido: 0.2.1
2025-04-19 19:45:13,686:INFO:           schemdraw: 0.15
2025-04-19 19:45:13,686:INFO:         statsmodels: 0.14.4
2025-04-19 19:45:13,686:INFO:              sktime: 0.21.1
2025-04-19 19:45:13,686:INFO:               tbats: 1.1.3
2025-04-19 19:45:13,686:INFO:            pmdarima: 2.0.4
2025-04-19 19:45:13,686:INFO:              psutil: 7.0.0
2025-04-19 19:45:13,686:INFO:          markupsafe: 3.0.2
2025-04-19 19:45:13,687:INFO:             pickle5: Not installed
2025-04-19 19:45:13,687:INFO:         cloudpickle: 3.1.1
2025-04-19 19:45:13,687:INFO:         deprecation: 2.1.0
2025-04-19 19:45:13,687:INFO:              xxhash: 3.5.0
2025-04-19 19:45:13,687:INFO:           wurlitzer: Not installed
2025-04-19 19:45:13,687:INFO:PyCaret optional dependencies:
2025-04-19 19:45:13,961:INFO:                shap: Not installed
2025-04-19 19:45:13,962:INFO:           interpret: Not installed
2025-04-19 19:45:13,962:INFO:                umap: Not installed
2025-04-19 19:45:13,962:INFO:    pandas_profiling: Not installed
2025-04-19 19:45:13,962:INFO:  explainerdashboard: Not installed
2025-04-19 19:45:13,962:INFO:             autoviz: Not installed
2025-04-19 19:45:13,962:INFO:           fairlearn: Not installed
2025-04-19 19:45:13,962:INFO:          deepchecks: Not installed
2025-04-19 19:45:13,962:INFO:             xgboost: Not installed
2025-04-19 19:45:13,962:INFO:            catboost: Not installed
2025-04-19 19:45:13,962:INFO:              kmodes: Not installed
2025-04-19 19:45:13,962:INFO:             mlxtend: Not installed
2025-04-19 19:45:13,962:INFO:       statsforecast: Not installed
2025-04-19 19:45:13,962:INFO:        tune_sklearn: Not installed
2025-04-19 19:45:13,962:INFO:                 ray: Not installed
2025-04-19 19:45:13,962:INFO:            hyperopt: Not installed
2025-04-19 19:45:13,962:INFO:              optuna: Not installed
2025-04-19 19:45:13,962:INFO:               skopt: Not installed
2025-04-19 19:45:13,962:INFO:              mlflow: 2.21.3
2025-04-19 19:45:13,962:INFO:              gradio: Not installed
2025-04-19 19:45:13,962:INFO:             fastapi: 0.115.12
2025-04-19 19:45:13,962:INFO:             uvicorn: 0.34.2
2025-04-19 19:45:13,962:INFO:              m2cgen: Not installed
2025-04-19 19:45:13,962:INFO:           evidently: Not installed
2025-04-19 19:45:13,962:INFO:               fugue: Not installed
2025-04-19 19:45:13,962:INFO:           streamlit: Not installed
2025-04-19 19:45:13,962:INFO:             prophet: Not installed
2025-04-19 19:45:13,962:INFO:None
2025-04-19 19:45:13,962:INFO:Set up data.
2025-04-19 19:45:13,967:INFO:Set up train/test split.
2025-04-19 19:45:13,969:INFO:Set up index.
2025-04-19 19:45:13,970:INFO:Set up folding strategy.
2025-04-19 19:45:13,970:INFO:Assigning column types.
2025-04-19 19:45:13,972:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:45:13,972:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:45:13,976:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:45:13,979:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,072:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,077:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,080:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,165:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,166:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 19:45:14,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,467:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 19:45:14,478:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,582:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,685:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,687:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 19:45:14,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,890:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:45:14,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:14,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:14,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:45:15,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,090:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 19:45:15,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:15,278:INFO:Preparing preprocessing pipeline...
2025-04-19 19:45:15,278:INFO:Set up target transformation.
2025-04-19 19:45:15,278:INFO:Set up simple imputation.
2025-04-19 19:45:15,278:INFO:Set up removing multicollinearity.
2025-04-19 19:45:15,278:INFO:Set up removing outliers.
2025-04-19 19:45:15,278:INFO:Set up feature normalization.
2025-04-19 19:45:15,446:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:15,761:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:45:15,772:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 19:45:15,772:INFO:Creating final display dataframe.
2025-04-19 19:45:16,002:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:16,520:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 6)
4        Transformed data shape     (7719, 6)
5   Transformed train set shape     (5319, 6)
6    Transformed test set shape     (2400, 6)
7              Numeric features             5
8      Rows with missing values          9.7%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          b21c
2025-04-19 19:45:16,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:16,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:16,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:16,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:45:16,720:INFO:setup() successfully completed in 3.14s...............
2025-04-19 19:45:16,720:INFO:Initializing compare_models()
2025-04-19 19:45:16,720:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 19:45:16,720:INFO:Checking exceptions
2025-04-19 19:45:16,722:INFO:Preparing display monitor
2025-04-19 19:45:16,726:INFO:Initializing Linear Regression
2025-04-19 19:45:16,726:INFO:Total runtime is 0.0 minutes
2025-04-19 19:45:16,726:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:16,726:INFO:Initializing create_model()
2025-04-19 19:45:16,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:16,726:INFO:Checking exceptions
2025-04-19 19:45:16,726:INFO:Importing libraries
2025-04-19 19:45:16,726:INFO:Copying training dataset
2025-04-19 19:45:16,730:INFO:Defining folds
2025-04-19 19:45:16,730:INFO:Declaring metric variables
2025-04-19 19:45:16,730:INFO:Importing untrained model
2025-04-19 19:45:16,730:INFO:Linear Regression Imported successfully
2025-04-19 19:45:16,730:INFO:Starting cross validation
2025-04-19 19:45:16,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:21,722:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:21,730:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:21,776:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:21,898:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:21,932:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:21,954:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:22,114:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:22,186:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:23,048:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:23,082:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:45:23,483:INFO:Calculating mean and std
2025-04-19 19:45:23,483:INFO:Creating metrics dataframe
2025-04-19 19:45:23,571:INFO:Uploading results into container
2025-04-19 19:45:23,572:INFO:Uploading model into container now
2025-04-19 19:45:23,572:INFO:_master_model_container: 1
2025-04-19 19:45:23,572:INFO:_display_container: 2
2025-04-19 19:45:23,572:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:45:23,572:INFO:create_model() successfully completed......................................
2025-04-19 19:45:23,742:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:23,742:INFO:Creating metrics dataframe
2025-04-19 19:45:23,746:INFO:Initializing Lasso Regression
2025-04-19 19:45:23,746:INFO:Total runtime is 0.11699620485305787 minutes
2025-04-19 19:45:23,747:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:23,747:INFO:Initializing create_model()
2025-04-19 19:45:23,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:23,747:INFO:Checking exceptions
2025-04-19 19:45:23,747:INFO:Importing libraries
2025-04-19 19:45:23,747:INFO:Copying training dataset
2025-04-19 19:45:23,752:INFO:Defining folds
2025-04-19 19:45:23,752:INFO:Declaring metric variables
2025-04-19 19:45:23,752:INFO:Importing untrained model
2025-04-19 19:45:23,753:INFO:Lasso Regression Imported successfully
2025-04-19 19:45:23,753:INFO:Starting cross validation
2025-04-19 19:45:23,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:24,495:INFO:Calculating mean and std
2025-04-19 19:45:24,496:INFO:Creating metrics dataframe
2025-04-19 19:45:24,584:INFO:Uploading results into container
2025-04-19 19:45:24,585:INFO:Uploading model into container now
2025-04-19 19:45:24,586:INFO:_master_model_container: 2
2025-04-19 19:45:24,586:INFO:_display_container: 2
2025-04-19 19:45:24,586:INFO:Lasso(random_state=42)
2025-04-19 19:45:24,586:INFO:create_model() successfully completed......................................
2025-04-19 19:45:24,822:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:24,822:INFO:Creating metrics dataframe
2025-04-19 19:45:24,826:INFO:Initializing Ridge Regression
2025-04-19 19:45:24,826:INFO:Total runtime is 0.13500583569208782 minutes
2025-04-19 19:45:24,826:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:24,826:INFO:Initializing create_model()
2025-04-19 19:45:24,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:24,826:INFO:Checking exceptions
2025-04-19 19:45:24,826:INFO:Importing libraries
2025-04-19 19:45:24,826:INFO:Copying training dataset
2025-04-19 19:45:24,830:INFO:Defining folds
2025-04-19 19:45:24,830:INFO:Declaring metric variables
2025-04-19 19:45:24,831:INFO:Importing untrained model
2025-04-19 19:45:24,831:INFO:Ridge Regression Imported successfully
2025-04-19 19:45:24,831:INFO:Starting cross validation
2025-04-19 19:45:24,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:25,554:INFO:Calculating mean and std
2025-04-19 19:45:25,555:INFO:Creating metrics dataframe
2025-04-19 19:45:25,653:INFO:Uploading results into container
2025-04-19 19:45:25,654:INFO:Uploading model into container now
2025-04-19 19:45:25,654:INFO:_master_model_container: 3
2025-04-19 19:45:25,654:INFO:_display_container: 2
2025-04-19 19:45:25,655:INFO:Ridge(random_state=42)
2025-04-19 19:45:25,655:INFO:create_model() successfully completed......................................
2025-04-19 19:45:25,754:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:25,754:INFO:Creating metrics dataframe
2025-04-19 19:45:25,759:INFO:Initializing Elastic Net
2025-04-19 19:45:25,759:INFO:Total runtime is 0.15054647127787274 minutes
2025-04-19 19:45:25,759:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:25,760:INFO:Initializing create_model()
2025-04-19 19:45:25,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:25,760:INFO:Checking exceptions
2025-04-19 19:45:25,760:INFO:Importing libraries
2025-04-19 19:45:25,760:INFO:Copying training dataset
2025-04-19 19:45:25,763:INFO:Defining folds
2025-04-19 19:45:25,764:INFO:Declaring metric variables
2025-04-19 19:45:25,764:INFO:Importing untrained model
2025-04-19 19:45:25,764:INFO:Elastic Net Imported successfully
2025-04-19 19:45:25,764:INFO:Starting cross validation
2025-04-19 19:45:25,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:26,443:INFO:Calculating mean and std
2025-04-19 19:45:26,444:INFO:Creating metrics dataframe
2025-04-19 19:45:26,526:INFO:Uploading results into container
2025-04-19 19:45:26,527:INFO:Uploading model into container now
2025-04-19 19:45:26,527:INFO:_master_model_container: 4
2025-04-19 19:45:26,528:INFO:_display_container: 2
2025-04-19 19:45:26,528:INFO:ElasticNet(random_state=42)
2025-04-19 19:45:26,528:INFO:create_model() successfully completed......................................
2025-04-19 19:45:26,622:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:26,622:INFO:Creating metrics dataframe
2025-04-19 19:45:26,626:INFO:Initializing Least Angle Regression
2025-04-19 19:45:26,626:INFO:Total runtime is 0.16500986417134605 minutes
2025-04-19 19:45:26,626:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:26,627:INFO:Initializing create_model()
2025-04-19 19:45:26,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:26,627:INFO:Checking exceptions
2025-04-19 19:45:26,627:INFO:Importing libraries
2025-04-19 19:45:26,627:INFO:Copying training dataset
2025-04-19 19:45:26,632:INFO:Defining folds
2025-04-19 19:45:26,632:INFO:Declaring metric variables
2025-04-19 19:45:26,632:INFO:Importing untrained model
2025-04-19 19:45:26,632:INFO:Least Angle Regression Imported successfully
2025-04-19 19:45:26,632:INFO:Starting cross validation
2025-04-19 19:45:26,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:27,297:INFO:Calculating mean and std
2025-04-19 19:45:27,299:INFO:Creating metrics dataframe
2025-04-19 19:45:27,379:INFO:Uploading results into container
2025-04-19 19:45:27,379:INFO:Uploading model into container now
2025-04-19 19:45:27,380:INFO:_master_model_container: 5
2025-04-19 19:45:27,380:INFO:_display_container: 2
2025-04-19 19:45:27,380:INFO:Lars(random_state=42)
2025-04-19 19:45:27,380:INFO:create_model() successfully completed......................................
2025-04-19 19:45:27,473:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:27,473:INFO:Creating metrics dataframe
2025-04-19 19:45:27,477:INFO:Initializing Lasso Least Angle Regression
2025-04-19 19:45:27,477:INFO:Total runtime is 0.17918018102645877 minutes
2025-04-19 19:45:27,477:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:27,478:INFO:Initializing create_model()
2025-04-19 19:45:27,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:27,478:INFO:Checking exceptions
2025-04-19 19:45:27,478:INFO:Importing libraries
2025-04-19 19:45:27,478:INFO:Copying training dataset
2025-04-19 19:45:27,481:INFO:Defining folds
2025-04-19 19:45:27,481:INFO:Declaring metric variables
2025-04-19 19:45:27,481:INFO:Importing untrained model
2025-04-19 19:45:27,481:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 19:45:27,482:INFO:Starting cross validation
2025-04-19 19:45:27,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:28,179:INFO:Calculating mean and std
2025-04-19 19:45:28,179:INFO:Creating metrics dataframe
2025-04-19 19:45:28,265:INFO:Uploading results into container
2025-04-19 19:45:28,266:INFO:Uploading model into container now
2025-04-19 19:45:28,266:INFO:_master_model_container: 6
2025-04-19 19:45:28,266:INFO:_display_container: 2
2025-04-19 19:45:28,267:INFO:LassoLars(random_state=42)
2025-04-19 19:45:28,267:INFO:create_model() successfully completed......................................
2025-04-19 19:45:28,366:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:28,366:INFO:Creating metrics dataframe
2025-04-19 19:45:28,372:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 19:45:28,372:INFO:Total runtime is 0.19410681724548343 minutes
2025-04-19 19:45:28,372:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:28,372:INFO:Initializing create_model()
2025-04-19 19:45:28,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:28,372:INFO:Checking exceptions
2025-04-19 19:45:28,372:INFO:Importing libraries
2025-04-19 19:45:28,372:INFO:Copying training dataset
2025-04-19 19:45:28,376:INFO:Defining folds
2025-04-19 19:45:28,377:INFO:Declaring metric variables
2025-04-19 19:45:28,377:INFO:Importing untrained model
2025-04-19 19:45:28,377:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:45:28,377:INFO:Starting cross validation
2025-04-19 19:45:28,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:29,131:INFO:Calculating mean and std
2025-04-19 19:45:29,132:INFO:Creating metrics dataframe
2025-04-19 19:45:29,220:INFO:Uploading results into container
2025-04-19 19:45:29,220:INFO:Uploading model into container now
2025-04-19 19:45:29,221:INFO:_master_model_container: 7
2025-04-19 19:45:29,221:INFO:_display_container: 2
2025-04-19 19:45:29,221:INFO:OrthogonalMatchingPursuit()
2025-04-19 19:45:29,221:INFO:create_model() successfully completed......................................
2025-04-19 19:45:29,316:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:29,316:INFO:Creating metrics dataframe
2025-04-19 19:45:29,321:INFO:Initializing Bayesian Ridge
2025-04-19 19:45:29,321:INFO:Total runtime is 0.2099156737327576 minutes
2025-04-19 19:45:29,321:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:29,322:INFO:Initializing create_model()
2025-04-19 19:45:29,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:29,322:INFO:Checking exceptions
2025-04-19 19:45:29,322:INFO:Importing libraries
2025-04-19 19:45:29,322:INFO:Copying training dataset
2025-04-19 19:45:29,325:INFO:Defining folds
2025-04-19 19:45:29,325:INFO:Declaring metric variables
2025-04-19 19:45:29,325:INFO:Importing untrained model
2025-04-19 19:45:29,325:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:45:29,325:INFO:Starting cross validation
2025-04-19 19:45:29,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:30,241:INFO:Calculating mean and std
2025-04-19 19:45:30,241:INFO:Creating metrics dataframe
2025-04-19 19:45:30,317:INFO:Uploading results into container
2025-04-19 19:45:30,319:INFO:Uploading model into container now
2025-04-19 19:45:30,319:INFO:_master_model_container: 8
2025-04-19 19:45:30,319:INFO:_display_container: 2
2025-04-19 19:45:30,320:INFO:BayesianRidge()
2025-04-19 19:45:30,320:INFO:create_model() successfully completed......................................
2025-04-19 19:45:30,426:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:30,426:INFO:Creating metrics dataframe
2025-04-19 19:45:30,431:INFO:Initializing Passive Aggressive Regressor
2025-04-19 19:45:30,431:INFO:Total runtime is 0.2284146030743917 minutes
2025-04-19 19:45:30,431:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:30,431:INFO:Initializing create_model()
2025-04-19 19:45:30,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:30,431:INFO:Checking exceptions
2025-04-19 19:45:30,431:INFO:Importing libraries
2025-04-19 19:45:30,431:INFO:Copying training dataset
2025-04-19 19:45:30,435:INFO:Defining folds
2025-04-19 19:45:30,436:INFO:Declaring metric variables
2025-04-19 19:45:30,436:INFO:Importing untrained model
2025-04-19 19:45:30,436:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 19:45:30,437:INFO:Starting cross validation
2025-04-19 19:45:30,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:31,195:INFO:Calculating mean and std
2025-04-19 19:45:31,195:INFO:Creating metrics dataframe
2025-04-19 19:45:31,280:INFO:Uploading results into container
2025-04-19 19:45:31,280:INFO:Uploading model into container now
2025-04-19 19:45:31,281:INFO:_master_model_container: 9
2025-04-19 19:45:31,281:INFO:_display_container: 2
2025-04-19 19:45:31,281:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 19:45:31,281:INFO:create_model() successfully completed......................................
2025-04-19 19:45:31,384:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:31,384:INFO:Creating metrics dataframe
2025-04-19 19:45:31,389:INFO:Initializing Huber Regressor
2025-04-19 19:45:31,389:INFO:Total runtime is 0.24438404639561973 minutes
2025-04-19 19:45:31,389:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:31,389:INFO:Initializing create_model()
2025-04-19 19:45:31,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:31,389:INFO:Checking exceptions
2025-04-19 19:45:31,390:INFO:Importing libraries
2025-04-19 19:45:31,390:INFO:Copying training dataset
2025-04-19 19:45:31,394:INFO:Defining folds
2025-04-19 19:45:31,394:INFO:Declaring metric variables
2025-04-19 19:45:31,394:INFO:Importing untrained model
2025-04-19 19:45:31,395:INFO:Huber Regressor Imported successfully
2025-04-19 19:45:31,395:INFO:Starting cross validation
2025-04-19 19:45:31,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:32,243:INFO:Calculating mean and std
2025-04-19 19:45:32,243:INFO:Creating metrics dataframe
2025-04-19 19:45:32,343:INFO:Uploading results into container
2025-04-19 19:45:32,344:INFO:Uploading model into container now
2025-04-19 19:45:32,346:INFO:_master_model_container: 10
2025-04-19 19:45:32,346:INFO:_display_container: 2
2025-04-19 19:45:32,346:INFO:HuberRegressor()
2025-04-19 19:45:32,346:INFO:create_model() successfully completed......................................
2025-04-19 19:45:32,465:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:32,465:INFO:Creating metrics dataframe
2025-04-19 19:45:32,473:INFO:Initializing K Neighbors Regressor
2025-04-19 19:45:32,473:INFO:Total runtime is 0.2624608675638835 minutes
2025-04-19 19:45:32,473:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:32,473:INFO:Initializing create_model()
2025-04-19 19:45:32,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:32,474:INFO:Checking exceptions
2025-04-19 19:45:32,474:INFO:Importing libraries
2025-04-19 19:45:32,474:INFO:Copying training dataset
2025-04-19 19:45:32,479:INFO:Defining folds
2025-04-19 19:45:32,479:INFO:Declaring metric variables
2025-04-19 19:45:32,479:INFO:Importing untrained model
2025-04-19 19:45:32,479:INFO:K Neighbors Regressor Imported successfully
2025-04-19 19:45:32,479:INFO:Starting cross validation
2025-04-19 19:45:32,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:33,481:INFO:Calculating mean and std
2025-04-19 19:45:33,482:INFO:Creating metrics dataframe
2025-04-19 19:45:33,572:INFO:Uploading results into container
2025-04-19 19:45:33,573:INFO:Uploading model into container now
2025-04-19 19:45:33,573:INFO:_master_model_container: 11
2025-04-19 19:45:33,573:INFO:_display_container: 2
2025-04-19 19:45:33,573:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 19:45:33,573:INFO:create_model() successfully completed......................................
2025-04-19 19:45:33,672:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:33,672:INFO:Creating metrics dataframe
2025-04-19 19:45:33,677:INFO:Initializing Decision Tree Regressor
2025-04-19 19:45:33,677:INFO:Total runtime is 0.2825127561887105 minutes
2025-04-19 19:45:33,677:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:33,678:INFO:Initializing create_model()
2025-04-19 19:45:33,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:33,678:INFO:Checking exceptions
2025-04-19 19:45:33,678:INFO:Importing libraries
2025-04-19 19:45:33,678:INFO:Copying training dataset
2025-04-19 19:45:33,681:INFO:Defining folds
2025-04-19 19:45:33,681:INFO:Declaring metric variables
2025-04-19 19:45:33,681:INFO:Importing untrained model
2025-04-19 19:45:33,681:INFO:Decision Tree Regressor Imported successfully
2025-04-19 19:45:33,682:INFO:Starting cross validation
2025-04-19 19:45:33,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:34,534:INFO:Calculating mean and std
2025-04-19 19:45:34,535:INFO:Creating metrics dataframe
2025-04-19 19:45:34,630:INFO:Uploading results into container
2025-04-19 19:45:34,631:INFO:Uploading model into container now
2025-04-19 19:45:34,631:INFO:_master_model_container: 12
2025-04-19 19:45:34,631:INFO:_display_container: 2
2025-04-19 19:45:34,631:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 19:45:34,632:INFO:create_model() successfully completed......................................
2025-04-19 19:45:34,756:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:34,756:INFO:Creating metrics dataframe
2025-04-19 19:45:34,761:INFO:Initializing Random Forest Regressor
2025-04-19 19:45:34,761:INFO:Total runtime is 0.30059357086817423 minutes
2025-04-19 19:45:34,761:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:34,761:INFO:Initializing create_model()
2025-04-19 19:45:34,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:34,762:INFO:Checking exceptions
2025-04-19 19:45:34,762:INFO:Importing libraries
2025-04-19 19:45:34,762:INFO:Copying training dataset
2025-04-19 19:45:34,766:INFO:Defining folds
2025-04-19 19:45:34,766:INFO:Declaring metric variables
2025-04-19 19:45:34,766:INFO:Importing untrained model
2025-04-19 19:45:34,766:INFO:Random Forest Regressor Imported successfully
2025-04-19 19:45:34,767:INFO:Starting cross validation
2025-04-19 19:45:34,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:38,384:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:38,814:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:39,189:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:39,335:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-19 19:45:40,375:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 19:45:43,947:INFO:Calculating mean and std
2025-04-19 19:45:43,947:INFO:Creating metrics dataframe
2025-04-19 19:45:44,067:INFO:Uploading results into container
2025-04-19 19:45:44,068:INFO:Uploading model into container now
2025-04-19 19:45:44,069:INFO:_master_model_container: 13
2025-04-19 19:45:44,069:INFO:_display_container: 2
2025-04-19 19:45:44,069:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:45:44,070:INFO:create_model() successfully completed......................................
2025-04-19 19:45:44,208:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:44,208:INFO:Creating metrics dataframe
2025-04-19 19:45:44,218:INFO:Initializing Extra Trees Regressor
2025-04-19 19:45:44,218:INFO:Total runtime is 0.45819907983144126 minutes
2025-04-19 19:45:44,218:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:44,219:INFO:Initializing create_model()
2025-04-19 19:45:44,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:44,219:INFO:Checking exceptions
2025-04-19 19:45:44,219:INFO:Importing libraries
2025-04-19 19:45:44,219:INFO:Copying training dataset
2025-04-19 19:45:44,223:INFO:Defining folds
2025-04-19 19:45:44,223:INFO:Declaring metric variables
2025-04-19 19:45:44,223:INFO:Importing untrained model
2025-04-19 19:45:44,224:INFO:Extra Trees Regressor Imported successfully
2025-04-19 19:45:44,224:INFO:Starting cross validation
2025-04-19 19:45:44,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:46,989:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:46,998:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:47,041:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:47,109:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 19:45:48,644:INFO:Calculating mean and std
2025-04-19 19:45:48,645:INFO:Creating metrics dataframe
2025-04-19 19:45:48,764:INFO:Uploading results into container
2025-04-19 19:45:48,765:INFO:Uploading model into container now
2025-04-19 19:45:48,765:INFO:_master_model_container: 14
2025-04-19 19:45:48,765:INFO:_display_container: 2
2025-04-19 19:45:48,765:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:45:48,765:INFO:create_model() successfully completed......................................
2025-04-19 19:45:48,884:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:48,884:INFO:Creating metrics dataframe
2025-04-19 19:45:48,889:INFO:Initializing AdaBoost Regressor
2025-04-19 19:45:48,889:INFO:Total runtime is 0.5360614816347758 minutes
2025-04-19 19:45:48,889:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:48,889:INFO:Initializing create_model()
2025-04-19 19:45:48,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:48,889:INFO:Checking exceptions
2025-04-19 19:45:48,889:INFO:Importing libraries
2025-04-19 19:45:48,889:INFO:Copying training dataset
2025-04-19 19:45:48,893:INFO:Defining folds
2025-04-19 19:45:48,893:INFO:Declaring metric variables
2025-04-19 19:45:48,893:INFO:Importing untrained model
2025-04-19 19:45:48,893:INFO:AdaBoost Regressor Imported successfully
2025-04-19 19:45:48,893:INFO:Starting cross validation
2025-04-19 19:45:48,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:50,186:INFO:Calculating mean and std
2025-04-19 19:45:50,187:INFO:Creating metrics dataframe
2025-04-19 19:45:50,292:INFO:Uploading results into container
2025-04-19 19:45:50,292:INFO:Uploading model into container now
2025-04-19 19:45:50,292:INFO:_master_model_container: 15
2025-04-19 19:45:50,292:INFO:_display_container: 2
2025-04-19 19:45:50,293:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 19:45:50,293:INFO:create_model() successfully completed......................................
2025-04-19 19:45:50,400:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:50,400:INFO:Creating metrics dataframe
2025-04-19 19:45:50,406:INFO:Initializing Gradient Boosting Regressor
2025-04-19 19:45:50,406:INFO:Total runtime is 0.5613397161165874 minutes
2025-04-19 19:45:50,406:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:50,407:INFO:Initializing create_model()
2025-04-19 19:45:50,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:50,407:INFO:Checking exceptions
2025-04-19 19:45:50,407:INFO:Importing libraries
2025-04-19 19:45:50,407:INFO:Copying training dataset
2025-04-19 19:45:50,412:INFO:Defining folds
2025-04-19 19:45:50,412:INFO:Declaring metric variables
2025-04-19 19:45:50,413:INFO:Importing untrained model
2025-04-19 19:45:50,413:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 19:45:50,414:INFO:Starting cross validation
2025-04-19 19:45:50,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:53,542:INFO:Calculating mean and std
2025-04-19 19:45:53,542:INFO:Creating metrics dataframe
2025-04-19 19:45:53,652:INFO:Uploading results into container
2025-04-19 19:45:53,652:INFO:Uploading model into container now
2025-04-19 19:45:53,653:INFO:_master_model_container: 16
2025-04-19 19:45:53,653:INFO:_display_container: 2
2025-04-19 19:45:53,653:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 19:45:53,653:INFO:create_model() successfully completed......................................
2025-04-19 19:45:53,763:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:53,763:INFO:Creating metrics dataframe
2025-04-19 19:45:53,772:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:45:53,772:INFO:Total runtime is 0.61742928425471 minutes
2025-04-19 19:45:53,772:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:53,772:INFO:Initializing create_model()
2025-04-19 19:45:53,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:53,773:INFO:Checking exceptions
2025-04-19 19:45:53,773:INFO:Importing libraries
2025-04-19 19:45:53,773:INFO:Copying training dataset
2025-04-19 19:45:53,776:INFO:Defining folds
2025-04-19 19:45:53,776:INFO:Declaring metric variables
2025-04-19 19:45:53,777:INFO:Importing untrained model
2025-04-19 19:45:53,777:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:45:53,777:INFO:Starting cross validation
2025-04-19 19:45:53,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:56,197:INFO:Calculating mean and std
2025-04-19 19:45:56,200:INFO:Creating metrics dataframe
2025-04-19 19:45:56,356:INFO:Uploading results into container
2025-04-19 19:45:56,357:INFO:Uploading model into container now
2025-04-19 19:45:56,357:INFO:_master_model_container: 17
2025-04-19 19:45:56,357:INFO:_display_container: 2
2025-04-19 19:45:56,358:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:45:56,358:INFO:create_model() successfully completed......................................
2025-04-19 19:45:56,511:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:56,512:INFO:Creating metrics dataframe
2025-04-19 19:45:56,519:INFO:Initializing Dummy Regressor
2025-04-19 19:45:56,519:INFO:Total runtime is 0.6632161537806194 minutes
2025-04-19 19:45:56,519:INFO:SubProcess create_model() called ==================================
2025-04-19 19:45:56,520:INFO:Initializing create_model()
2025-04-19 19:45:56,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A204712D10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:56,520:INFO:Checking exceptions
2025-04-19 19:45:56,520:INFO:Importing libraries
2025-04-19 19:45:56,520:INFO:Copying training dataset
2025-04-19 19:45:56,526:INFO:Defining folds
2025-04-19 19:45:56,526:INFO:Declaring metric variables
2025-04-19 19:45:56,526:INFO:Importing untrained model
2025-04-19 19:45:56,527:INFO:Dummy Regressor Imported successfully
2025-04-19 19:45:56,527:INFO:Starting cross validation
2025-04-19 19:45:56,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:45:57,679:INFO:Calculating mean and std
2025-04-19 19:45:57,679:INFO:Creating metrics dataframe
2025-04-19 19:45:57,788:INFO:Uploading results into container
2025-04-19 19:45:57,789:INFO:Uploading model into container now
2025-04-19 19:45:57,790:INFO:_master_model_container: 18
2025-04-19 19:45:57,790:INFO:_display_container: 2
2025-04-19 19:45:57,790:INFO:DummyRegressor()
2025-04-19 19:45:57,790:INFO:create_model() successfully completed......................................
2025-04-19 19:45:57,900:INFO:SubProcess create_model() end ==================================
2025-04-19 19:45:57,901:INFO:Creating metrics dataframe
2025-04-19 19:45:57,909:INFO:Initializing create_model()
2025-04-19 19:45:57,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:57,909:INFO:Checking exceptions
2025-04-19 19:45:57,910:INFO:Importing libraries
2025-04-19 19:45:57,910:INFO:Copying training dataset
2025-04-19 19:45:57,913:INFO:Defining folds
2025-04-19 19:45:57,913:INFO:Declaring metric variables
2025-04-19 19:45:57,913:INFO:Importing untrained model
2025-04-19 19:45:57,913:INFO:Declaring custom model
2025-04-19 19:45:57,913:INFO:Huber Regressor Imported successfully
2025-04-19 19:45:57,924:INFO:Cross validation set to False
2025-04-19 19:45:57,924:INFO:Fitting Model
2025-04-19 19:45:58,113:INFO:HuberRegressor()
2025-04-19 19:45:58,113:INFO:create_model() successfully completed......................................
2025-04-19 19:45:58,239:INFO:Initializing create_model()
2025-04-19 19:45:58,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:58,239:INFO:Checking exceptions
2025-04-19 19:45:58,240:INFO:Importing libraries
2025-04-19 19:45:58,240:INFO:Copying training dataset
2025-04-19 19:45:58,242:INFO:Defining folds
2025-04-19 19:45:58,242:INFO:Declaring metric variables
2025-04-19 19:45:58,242:INFO:Importing untrained model
2025-04-19 19:45:58,242:INFO:Declaring custom model
2025-04-19 19:45:58,242:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:45:58,247:INFO:Cross validation set to False
2025-04-19 19:45:58,247:INFO:Fitting Model
2025-04-19 19:45:58,394:INFO:BayesianRidge()
2025-04-19 19:45:58,394:INFO:create_model() successfully completed......................................
2025-04-19 19:45:58,511:INFO:Initializing create_model()
2025-04-19 19:45:58,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:45:58,512:INFO:Checking exceptions
2025-04-19 19:45:58,512:INFO:Importing libraries
2025-04-19 19:45:58,512:INFO:Copying training dataset
2025-04-19 19:45:58,517:INFO:Defining folds
2025-04-19 19:45:58,517:INFO:Declaring metric variables
2025-04-19 19:45:58,517:INFO:Importing untrained model
2025-04-19 19:45:58,517:INFO:Declaring custom model
2025-04-19 19:45:58,519:INFO:Linear Regression Imported successfully
2025-04-19 19:45:58,528:INFO:Cross validation set to False
2025-04-19 19:45:58,528:INFO:Fitting Model
2025-04-19 19:45:58,678:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:45:58,678:INFO:create_model() successfully completed......................................
2025-04-19 19:45:58,810:INFO:_master_model_container: 18
2025-04-19 19:45:58,810:INFO:_display_container: 2
2025-04-19 19:45:58,811:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 19:45:58,811:INFO:compare_models() successfully completed......................................
2025-04-19 19:45:58,811:INFO:Initializing tune_model()
2025-04-19 19:45:58,811:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>)
2025-04-19 19:45:58,811:INFO:Checking exceptions
2025-04-19 19:45:58,814:INFO:Copying training dataset
2025-04-19 19:45:58,818:INFO:Checking base model
2025-04-19 19:45:58,818:INFO:Base model : Huber Regressor
2025-04-19 19:45:58,818:INFO:Declaring metric variables
2025-04-19 19:45:58,818:INFO:Defining Hyperparameters
2025-04-19 19:45:58,942:INFO:Tuning with n_jobs=-1
2025-04-19 19:45:58,942:INFO:Initializing RandomizedSearchCV
2025-04-19 19:46:12,752:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.3, 'actual_estimator__alpha': 0.3}
2025-04-19 19:46:12,752:INFO:Hyperparameter search completed
2025-04-19 19:46:12,752:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:12,752:INFO:Initializing create_model()
2025-04-19 19:46:12,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A20005E950>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.3, 'alpha': 0.3})
2025-04-19 19:46:12,753:INFO:Checking exceptions
2025-04-19 19:46:12,753:INFO:Importing libraries
2025-04-19 19:46:12,753:INFO:Copying training dataset
2025-04-19 19:46:12,756:INFO:Defining folds
2025-04-19 19:46:12,756:INFO:Declaring metric variables
2025-04-19 19:46:12,756:INFO:Importing untrained model
2025-04-19 19:46:12,756:INFO:Declaring custom model
2025-04-19 19:46:12,757:INFO:Huber Regressor Imported successfully
2025-04-19 19:46:12,757:INFO:Starting cross validation
2025-04-19 19:46:12,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:13,891:INFO:Calculating mean and std
2025-04-19 19:46:13,891:INFO:Creating metrics dataframe
2025-04-19 19:46:13,893:INFO:Finalizing model
2025-04-19 19:46:14,115:INFO:Uploading results into container
2025-04-19 19:46:14,116:INFO:Uploading model into container now
2025-04-19 19:46:14,117:INFO:_master_model_container: 19
2025-04-19 19:46:14,117:INFO:_display_container: 3
2025-04-19 19:46:14,117:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 19:46:14,117:INFO:create_model() successfully completed......................................
2025-04-19 19:46:14,261:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:14,261:INFO:choose_better activated
2025-04-19 19:46:14,261:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:14,261:INFO:Initializing create_model()
2025-04-19 19:46:14,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:46:14,261:INFO:Checking exceptions
2025-04-19 19:46:14,262:INFO:Importing libraries
2025-04-19 19:46:14,262:INFO:Copying training dataset
2025-04-19 19:46:14,270:INFO:Defining folds
2025-04-19 19:46:14,270:INFO:Declaring metric variables
2025-04-19 19:46:14,270:INFO:Importing untrained model
2025-04-19 19:46:14,270:INFO:Declaring custom model
2025-04-19 19:46:14,271:INFO:Huber Regressor Imported successfully
2025-04-19 19:46:14,271:INFO:Starting cross validation
2025-04-19 19:46:14,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:15,464:INFO:Calculating mean and std
2025-04-19 19:46:15,465:INFO:Creating metrics dataframe
2025-04-19 19:46:15,469:INFO:Finalizing model
2025-04-19 19:46:15,643:INFO:Uploading results into container
2025-04-19 19:46:15,644:INFO:Uploading model into container now
2025-04-19 19:46:15,644:INFO:_master_model_container: 20
2025-04-19 19:46:15,644:INFO:_display_container: 4
2025-04-19 19:46:15,644:INFO:HuberRegressor()
2025-04-19 19:46:15,644:INFO:create_model() successfully completed......................................
2025-04-19 19:46:15,810:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:15,810:INFO:HuberRegressor() result for R2 is 0.0022
2025-04-19 19:46:15,811:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) result for R2 is 0.0022
2025-04-19 19:46:15,811:INFO:HuberRegressor() is best model
2025-04-19 19:46:15,811:INFO:choose_better completed
2025-04-19 19:46:15,811:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 19:46:15,821:INFO:_master_model_container: 20
2025-04-19 19:46:15,821:INFO:_display_container: 3
2025-04-19 19:46:15,821:INFO:HuberRegressor()
2025-04-19 19:46:15,821:INFO:tune_model() successfully completed......................................
2025-04-19 19:46:16,069:INFO:Initializing tune_model()
2025-04-19 19:46:16,069:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>)
2025-04-19 19:46:16,069:INFO:Checking exceptions
2025-04-19 19:46:16,073:INFO:Copying training dataset
2025-04-19 19:46:16,076:INFO:Checking base model
2025-04-19 19:46:16,076:INFO:Base model : Bayesian Ridge
2025-04-19 19:46:16,077:INFO:Declaring metric variables
2025-04-19 19:46:16,077:INFO:Defining Hyperparameters
2025-04-19 19:46:16,246:INFO:Tuning with n_jobs=-1
2025-04-19 19:46:16,246:INFO:Initializing RandomizedSearchCV
2025-04-19 19:46:26,800:INFO:best_params: {'actual_estimator__lambda_2': 0.05, 'actual_estimator__lambda_1': 0.0005, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': False, 'actual_estimator__alpha_2': 0.01, 'actual_estimator__alpha_1': 0.005}
2025-04-19 19:46:26,800:INFO:Hyperparameter search completed
2025-04-19 19:46:26,800:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:26,801:INFO:Initializing create_model()
2025-04-19 19:46:26,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A20005E0E0>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.05, 'lambda_1': 0.0005, 'fit_intercept': True, 'compute_score': False, 'alpha_2': 0.01, 'alpha_1': 0.005})
2025-04-19 19:46:26,801:INFO:Checking exceptions
2025-04-19 19:46:26,801:INFO:Importing libraries
2025-04-19 19:46:26,801:INFO:Copying training dataset
2025-04-19 19:46:26,805:INFO:Defining folds
2025-04-19 19:46:26,805:INFO:Declaring metric variables
2025-04-19 19:46:26,805:INFO:Importing untrained model
2025-04-19 19:46:26,805:INFO:Declaring custom model
2025-04-19 19:46:26,806:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:46:26,806:INFO:Starting cross validation
2025-04-19 19:46:26,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:27,686:INFO:Calculating mean and std
2025-04-19 19:46:27,687:INFO:Creating metrics dataframe
2025-04-19 19:46:27,689:INFO:Finalizing model
2025-04-19 19:46:27,854:INFO:Uploading results into container
2025-04-19 19:46:27,855:INFO:Uploading model into container now
2025-04-19 19:46:27,855:INFO:_master_model_container: 21
2025-04-19 19:46:27,855:INFO:_display_container: 4
2025-04-19 19:46:27,855:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)
2025-04-19 19:46:27,855:INFO:create_model() successfully completed......................................
2025-04-19 19:46:27,968:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:27,968:INFO:choose_better activated
2025-04-19 19:46:27,970:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:27,970:INFO:Initializing create_model()
2025-04-19 19:46:27,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:46:27,970:INFO:Checking exceptions
2025-04-19 19:46:27,971:INFO:Importing libraries
2025-04-19 19:46:27,971:INFO:Copying training dataset
2025-04-19 19:46:27,974:INFO:Defining folds
2025-04-19 19:46:27,974:INFO:Declaring metric variables
2025-04-19 19:46:27,974:INFO:Importing untrained model
2025-04-19 19:46:27,974:INFO:Declaring custom model
2025-04-19 19:46:27,975:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:46:27,975:INFO:Starting cross validation
2025-04-19 19:46:27,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:29,123:INFO:Calculating mean and std
2025-04-19 19:46:29,124:INFO:Creating metrics dataframe
2025-04-19 19:46:29,128:INFO:Finalizing model
2025-04-19 19:46:29,402:INFO:Uploading results into container
2025-04-19 19:46:29,402:INFO:Uploading model into container now
2025-04-19 19:46:29,403:INFO:_master_model_container: 22
2025-04-19 19:46:29,403:INFO:_display_container: 5
2025-04-19 19:46:29,403:INFO:BayesianRidge()
2025-04-19 19:46:29,403:INFO:create_model() successfully completed......................................
2025-04-19 19:46:29,540:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:29,541:INFO:BayesianRidge() result for R2 is -0.0027
2025-04-19 19:46:29,542:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05) result for R2 is -0.0026
2025-04-19 19:46:29,542:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05) is best model
2025-04-19 19:46:29,542:INFO:choose_better completed
2025-04-19 19:46:29,558:INFO:_master_model_container: 22
2025-04-19 19:46:29,559:INFO:_display_container: 4
2025-04-19 19:46:29,559:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)
2025-04-19 19:46:29,559:INFO:tune_model() successfully completed......................................
2025-04-19 19:46:29,823:INFO:Initializing tune_model()
2025-04-19 19:46:29,823:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>)
2025-04-19 19:46:29,823:INFO:Checking exceptions
2025-04-19 19:46:29,826:INFO:Copying training dataset
2025-04-19 19:46:29,827:INFO:Checking base model
2025-04-19 19:46:29,827:INFO:Base model : Linear Regression
2025-04-19 19:46:29,829:INFO:Declaring metric variables
2025-04-19 19:46:29,829:INFO:Defining Hyperparameters
2025-04-19 19:46:29,829:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 19:46:30,027:INFO:Tuning with n_jobs=-1
2025-04-19 19:46:30,027:INFO:Initializing GridSearchCV
2025-04-19 19:46:32,136:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 19:46:32,136:INFO:Hyperparameter search completed
2025-04-19 19:46:32,137:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:32,137:INFO:Initializing create_model()
2025-04-19 19:46:32,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A20005E950>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 19:46:32,137:INFO:Checking exceptions
2025-04-19 19:46:32,137:INFO:Importing libraries
2025-04-19 19:46:32,137:INFO:Copying training dataset
2025-04-19 19:46:32,141:INFO:Defining folds
2025-04-19 19:46:32,141:INFO:Declaring metric variables
2025-04-19 19:46:32,141:INFO:Importing untrained model
2025-04-19 19:46:32,141:INFO:Declaring custom model
2025-04-19 19:46:32,142:INFO:Linear Regression Imported successfully
2025-04-19 19:46:32,142:INFO:Starting cross validation
2025-04-19 19:46:32,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:33,056:INFO:Calculating mean and std
2025-04-19 19:46:33,057:INFO:Creating metrics dataframe
2025-04-19 19:46:33,060:INFO:Finalizing model
2025-04-19 19:46:33,377:INFO:Uploading results into container
2025-04-19 19:46:33,377:INFO:Uploading model into container now
2025-04-19 19:46:33,379:INFO:_master_model_container: 23
2025-04-19 19:46:33,379:INFO:_display_container: 5
2025-04-19 19:46:33,379:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:46:33,379:INFO:create_model() successfully completed......................................
2025-04-19 19:46:33,523:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:33,523:INFO:choose_better activated
2025-04-19 19:46:33,524:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:33,524:INFO:Initializing create_model()
2025-04-19 19:46:33,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:46:33,525:INFO:Checking exceptions
2025-04-19 19:46:33,525:INFO:Importing libraries
2025-04-19 19:46:33,525:INFO:Copying training dataset
2025-04-19 19:46:33,530:INFO:Defining folds
2025-04-19 19:46:33,530:INFO:Declaring metric variables
2025-04-19 19:46:33,530:INFO:Importing untrained model
2025-04-19 19:46:33,530:INFO:Declaring custom model
2025-04-19 19:46:33,530:INFO:Linear Regression Imported successfully
2025-04-19 19:46:33,531:INFO:Starting cross validation
2025-04-19 19:46:33,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:34,687:INFO:Calculating mean and std
2025-04-19 19:46:34,687:INFO:Creating metrics dataframe
2025-04-19 19:46:34,690:INFO:Finalizing model
2025-04-19 19:46:34,970:INFO:Uploading results into container
2025-04-19 19:46:34,971:INFO:Uploading model into container now
2025-04-19 19:46:34,972:INFO:_master_model_container: 24
2025-04-19 19:46:34,972:INFO:_display_container: 6
2025-04-19 19:46:34,972:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:46:34,972:INFO:create_model() successfully completed......................................
2025-04-19 19:46:35,117:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:35,118:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0028
2025-04-19 19:46:35,118:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0028
2025-04-19 19:46:35,118:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 19:46:35,118:INFO:choose_better completed
2025-04-19 19:46:35,119:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 19:46:35,141:INFO:_master_model_container: 24
2025-04-19 19:46:35,141:INFO:_display_container: 5
2025-04-19 19:46:35,141:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:46:35,142:INFO:tune_model() successfully completed......................................
2025-04-19 19:46:35,414:INFO:Initializing blend_models()
2025-04-19 19:46:35,414:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 19:46:35,414:INFO:Checking exceptions
2025-04-19 19:46:35,418:INFO:Importing libraries
2025-04-19 19:46:35,418:INFO:Copying training dataset
2025-04-19 19:46:35,419:INFO:Getting model names
2025-04-19 19:46:35,419:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:35,424:INFO:Initializing create_model()
2025-04-19 19:46:35,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A2600DD000>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:46:35,424:INFO:Checking exceptions
2025-04-19 19:46:35,424:INFO:Importing libraries
2025-04-19 19:46:35,424:INFO:Copying training dataset
2025-04-19 19:46:35,429:INFO:Defining folds
2025-04-19 19:46:35,430:INFO:Declaring metric variables
2025-04-19 19:46:35,430:INFO:Importing untrained model
2025-04-19 19:46:35,430:INFO:Declaring custom model
2025-04-19 19:46:35,431:INFO:Voting Regressor Imported successfully
2025-04-19 19:46:35,431:INFO:Starting cross validation
2025-04-19 19:46:35,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:36,872:INFO:Calculating mean and std
2025-04-19 19:46:36,872:INFO:Creating metrics dataframe
2025-04-19 19:46:36,876:INFO:Finalizing model
2025-04-19 19:46:37,271:INFO:Uploading results into container
2025-04-19 19:46:37,271:INFO:Uploading model into container now
2025-04-19 19:46:37,272:INFO:_master_model_container: 25
2025-04-19 19:46:37,272:INFO:_display_container: 6
2025-04-19 19:46:37,275:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 19:46:37,275:INFO:create_model() successfully completed......................................
2025-04-19 19:46:37,431:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:37,445:INFO:_master_model_container: 25
2025-04-19 19:46:37,445:INFO:_display_container: 6
2025-04-19 19:46:37,448:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 19:46:37,448:INFO:blend_models() successfully completed......................................
2025-04-19 19:46:37,595:INFO:Initializing stack_models()
2025-04-19 19:46:37,595:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 19:46:37,595:INFO:Checking exceptions
2025-04-19 19:46:37,597:INFO:Defining meta model
2025-04-19 19:46:37,599:INFO:Getting model names
2025-04-19 19:46:37,600:INFO:[('Huber Regressor', HuberRegressor()), ('Bayesian Ridge', BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 19:46:37,601:INFO:SubProcess create_model() called ==================================
2025-04-19 19:46:37,608:INFO:Initializing create_model()
2025-04-19 19:46:37,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A26007B580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:46:37,608:INFO:Checking exceptions
2025-04-19 19:46:37,608:INFO:Importing libraries
2025-04-19 19:46:37,608:INFO:Copying training dataset
2025-04-19 19:46:37,616:INFO:Defining folds
2025-04-19 19:46:37,616:INFO:Declaring metric variables
2025-04-19 19:46:37,617:INFO:Importing untrained model
2025-04-19 19:46:37,617:INFO:Declaring custom model
2025-04-19 19:46:37,622:INFO:Stacking Regressor Imported successfully
2025-04-19 19:46:37,622:INFO:Starting cross validation
2025-04-19 19:46:37,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:46:39,328:INFO:Calculating mean and std
2025-04-19 19:46:39,330:INFO:Creating metrics dataframe
2025-04-19 19:46:39,333:INFO:Finalizing model
2025-04-19 19:46:39,736:INFO:Uploading results into container
2025-04-19 19:46:39,737:INFO:Uploading model into container now
2025-04-19 19:46:39,737:INFO:_master_model_container: 26
2025-04-19 19:46:39,737:INFO:_display_container: 7
2025-04-19 19:46:39,741:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 19:46:39,741:INFO:create_model() successfully completed......................................
2025-04-19 19:46:39,882:INFO:SubProcess create_model() end ==================================
2025-04-19 19:46:39,899:INFO:_master_model_container: 26
2025-04-19 19:46:39,900:INFO:_display_container: 7
2025-04-19 19:46:39,904:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 19:46:39,904:INFO:stack_models() successfully completed......................................
2025-04-19 19:46:40,081:INFO:Initializing save_model()
2025-04-19 19:46:40,081:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:46:40,081:INFO:Adding model into prep_pipe
2025-04-19 19:46:40,174:INFO:models/model_1.pkl saved in current working directory
2025-04-19 19:46:40,208:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor()),
                                             ('Bayesian Ridge',
                                              BayesianRidge(alpha_1=0.005,
                                                            alpha_2=0.01,
                                                            lambda_1=0.0005,
                                                            lambda_2=0.05)),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 19:46:40,208:INFO:save_model() successfully completed......................................
2025-04-19 19:46:40,424:INFO:Initializing plot_model()
2025-04-19 19:46:40,425:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,425:INFO:Checking exceptions
2025-04-19 19:46:40,427:INFO:Initializing plot_model()
2025-04-19 19:46:40,427:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,427:INFO:Checking exceptions
2025-04-19 19:46:40,432:INFO:Initializing plot_model()
2025-04-19 19:46:40,432:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,432:INFO:Checking exceptions
2025-04-19 19:46:40,435:INFO:Initializing plot_model()
2025-04-19 19:46:40,435:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,435:INFO:Checking exceptions
2025-04-19 19:46:40,456:INFO:Initializing save_model()
2025-04-19 19:46:40,456:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:46:40,456:INFO:Adding model into prep_pipe
2025-04-19 19:46:40,532:INFO:models/model_2.pkl saved in current working directory
2025-04-19 19:46:40,559:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor()),
                                               ('Bayesian Ridge',
                                                BayesianRidge(alpha_1=0.005,
                                                              alpha_2=0.01,
                                                              lambda_1=0.0005,
                                                              lambda_2=0.05)),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 19:46:40,559:INFO:save_model() successfully completed......................................
2025-04-19 19:46:40,809:INFO:Initializing plot_model()
2025-04-19 19:46:40,810:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,810:INFO:Checking exceptions
2025-04-19 19:46:40,813:INFO:Initializing plot_model()
2025-04-19 19:46:40,813:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,813:INFO:Checking exceptions
2025-04-19 19:46:40,819:INFO:Initializing plot_model()
2025-04-19 19:46:40,819:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,819:INFO:Checking exceptions
2025-04-19 19:46:40,827:INFO:Initializing plot_model()
2025-04-19 19:46:40,827:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:40,827:INFO:Checking exceptions
2025-04-19 19:46:40,845:INFO:Initializing save_model()
2025-04-19 19:46:40,845:INFO:save_model(model=HuberRegressor(), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:46:40,845:INFO:Adding model into prep_pipe
2025-04-19 19:46:40,918:INFO:models/model_3.pkl saved in current working directory
2025-04-19 19:46:40,931:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor())])
2025-04-19 19:46:40,931:INFO:save_model() successfully completed......................................
2025-04-19 19:46:41,177:INFO:Initializing plot_model()
2025-04-19 19:46:41,177:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,177:INFO:Checking exceptions
2025-04-19 19:46:41,179:INFO:Initializing plot_model()
2025-04-19 19:46:41,179:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,179:INFO:Checking exceptions
2025-04-19 19:46:41,179:INFO:Initializing plot_model()
2025-04-19 19:46:41,180:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,180:INFO:Checking exceptions
2025-04-19 19:46:41,180:INFO:Initializing plot_model()
2025-04-19 19:46:41,181:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,181:INFO:Checking exceptions
2025-04-19 19:46:41,193:INFO:Initializing save_model()
2025-04-19 19:46:41,193:INFO:save_model(model=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:46:41,193:INFO:Adding model into prep_pipe
2025-04-19 19:46:41,272:INFO:models/model_4.pkl saved in current working directory
2025-04-19 19:46:41,289:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005,
                               lambda_2=0.05))])
2025-04-19 19:46:41,289:INFO:save_model() successfully completed......................................
2025-04-19 19:46:41,518:INFO:Initializing plot_model()
2025-04-19 19:46:41,518:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,518:INFO:Checking exceptions
2025-04-19 19:46:41,519:INFO:Initializing plot_model()
2025-04-19 19:46:41,519:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,519:INFO:Checking exceptions
2025-04-19 19:46:41,519:INFO:Initializing plot_model()
2025-04-19 19:46:41,520:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,520:INFO:Checking exceptions
2025-04-19 19:46:41,520:INFO:Initializing plot_model()
2025-04-19 19:46:41,520:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,520:INFO:Checking exceptions
2025-04-19 19:46:41,538:INFO:Initializing save_model()
2025-04-19 19:46:41,539:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:46:41,539:INFO:Adding model into prep_pipe
2025-04-19 19:46:41,624:INFO:models/model_5.pkl saved in current working directory
2025-04-19 19:46:41,644:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_19',
                                             'feature_49', 'feature_11',
                                             'feature_43'],
                                    transformer=Sim...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 19:46:41,644:INFO:save_model() successfully completed......................................
2025-04-19 19:46:41,891:INFO:Initializing plot_model()
2025-04-19 19:46:41,891:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,892:INFO:Checking exceptions
2025-04-19 19:46:41,892:INFO:Initializing plot_model()
2025-04-19 19:46:41,892:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,892:INFO:Checking exceptions
2025-04-19 19:46:41,892:INFO:Initializing plot_model()
2025-04-19 19:46:41,892:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,892:INFO:Checking exceptions
2025-04-19 19:46:41,893:INFO:Initializing plot_model()
2025-04-19 19:46:41,893:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A26BEBB220>, system=True)
2025-04-19 19:46:41,893:INFO:Checking exceptions
2025-04-19 19:56:45,605:WARNING:D:\College\agn\venv_py310\lib\site-packages\pydantic\_internal\_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

2025-04-19 19:56:45,722:WARNING:D:\College\agn\venv_py310\lib\site-packages\yellowbrick\style\colors.py:35: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  mpl_ge_150 = LooseVersion(mpl.__version__) >= "1.5.0"

2025-04-19 19:56:45,741:WARNING:D:\College\agn\venv_py310\lib\site-packages\setuptools\_distutils\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)

2025-04-19 19:56:45,744:WARNING:D:\College\agn\venv_py310\lib\site-packages\yellowbrick\style\rcmod.py:31: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  mpl_ge_150 = LooseVersion(mpl.__version__) >= "1.5.0"

2025-04-19 19:56:45,744:WARNING:D:\College\agn\venv_py310\lib\site-packages\setuptools\_distutils\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)

2025-04-19 19:56:46,054:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,056:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,056:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,057:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,057:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,058:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,059:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,060:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,060:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,060:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,061:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,061:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,062:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,063:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,063:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,064:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,064:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,065:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,065:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,067:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,068:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,069:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,069:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,071:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,072:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,072:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,073:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,073:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,074:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,074:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,075:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,075:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,076:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,076:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,077:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,077:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,078:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,078:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,079:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,080:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,080:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,081:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,081:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,082:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,083:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,083:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,084:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,087:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,089:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,089:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,090:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,091:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,092:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,092:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,093:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,093:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,094:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,094:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,094:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,095:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,095:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,097:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,097:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,098:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,098:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,099:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,100:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,100:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,100:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,101:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,101:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,102:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,103:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,105:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,106:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,106:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,107:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,108:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,108:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,109:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,109:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,109:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,109:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,111:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,112:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,112:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,113:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,114:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,115:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,115:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,116:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,116:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,117:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,117:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,117:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,118:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,119:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,119:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,120:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,121:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,122:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,122:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,123:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,123:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,123:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,123:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,124:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,124:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,125:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,125:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,126:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,127:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,127:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,127:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,128:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,128:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,129:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,130:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,131:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,131:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,132:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,132:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,133:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,133:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,134:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,134:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,135:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,135:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,136:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,137:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,137:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,138:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,138:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,139:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,139:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,139:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,140:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,140:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,141:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,141:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,141:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,142:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,143:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,143:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,144:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,144:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,145:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,145:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,146:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,146:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,147:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,147:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,148:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,148:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,149:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,149:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,150:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,150:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,151:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,151:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,152:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,153:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,153:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,154:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,154:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,154:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,156:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,156:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,157:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,157:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,157:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,158:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,159:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,159:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,159:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,160:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,160:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,161:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,161:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,163:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,163:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,164:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,165:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,166:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,166:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,167:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,167:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,168:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,169:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,172:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,173:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,175:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,176:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,177:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,178:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,179:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,179:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,181:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,181:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,182:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,182:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,185:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,185:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,186:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,187:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,188:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,189:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,191:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,191:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,192:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\utils\_dependencies.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ver = LooseVersion(dist.metadata["Version"])

2025-04-19 19:56:46,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:56:46,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:56:46,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:56:46,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:56:46,323:WARNING:D:\College\agn\venv_py310\lib\site-packages\scikitplot\plotters.py:33: DeprecationWarning: This module was deprecated in version 0.3.0 and its functions are spread throughout different modules. Please check the documentation and update your function calls as soon as possible. This module will be removed in 0.4.0
  warnings.warn("This module was deprecated in version 0.3.0 and its functions "

2025-04-19 19:56:47,490:INFO:PyCaret RegressionExperiment
2025-04-19 19:56:47,490:INFO:Logging name: agn_modeling
2025-04-19 19:56:47,490:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 19:56:47,490:INFO:version 3.0.4
2025-04-19 19:56:47,490:INFO:Initializing setup()
2025-04-19 19:56:47,490:INFO:self.USI: d0cb
2025-04-19 19:56:47,491:INFO:self._variable_keys: {'exp_id', 'y_test', 'log_plots_param', 'transform_target_param', 'USI', '_available_plots', 'target_param', 'exp_name_log', 'pipeline', 'X_train', 'gpu_param', 'n_jobs_param', 'y', 'memory', 'X', 'seed', 'logging_param', '_ml_usecase', 'data', 'y_train', 'fold_groups_param', 'idx', 'fold_generator', 'fold_shuffle_param', 'X_test', 'gpu_n_jobs_param', 'html_param'}
2025-04-19 19:56:47,491:INFO:Checking environment
2025-04-19 19:56:47,491:INFO:python_version: 3.10.9
2025-04-19 19:56:47,491:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 19:56:47,491:INFO:machine: AMD64
2025-04-19 19:56:47,504:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:56:47,508:INFO:Memory: svmem(total=16952647680, available=4245479424, percent=75.0, used=12707168256, free=4245479424)
2025-04-19 19:56:47,508:INFO:Physical Core: 4
2025-04-19 19:56:47,509:INFO:Logical Core: 8
2025-04-19 19:56:47,509:INFO:Checking libraries
2025-04-19 19:56:47,509:INFO:System:
2025-04-19 19:56:47,509:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 19:56:47,509:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 19:56:47,509:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:56:47,509:INFO:PyCaret required dependencies:
2025-04-19 19:56:47,538:INFO:                 pip: 25.0.1
2025-04-19 19:56:47,538:INFO:          setuptools: 65.5.0
2025-04-19 19:56:47,538:INFO:             pycaret: 3.0.4
2025-04-19 19:56:47,538:INFO:             IPython: 8.35.0
2025-04-19 19:56:47,538:INFO:          ipywidgets: 8.1.6
2025-04-19 19:56:47,538:INFO:                tqdm: 4.67.1
2025-04-19 19:56:47,538:INFO:               numpy: 1.23.5
2025-04-19 19:56:47,538:INFO:              pandas: 1.5.3
2025-04-19 19:56:47,538:INFO:              jinja2: 3.1.6
2025-04-19 19:56:47,538:INFO:               scipy: 1.10.1
2025-04-19 19:56:47,539:INFO:              joblib: 1.2.0
2025-04-19 19:56:47,539:INFO:             sklearn: 1.2.2
2025-04-19 19:56:47,539:INFO:                pyod: 2.0.4
2025-04-19 19:56:47,539:INFO:            imblearn: 0.12.4
2025-04-19 19:56:47,539:INFO:   category_encoders: 2.7.0
2025-04-19 19:56:47,539:INFO:            lightgbm: 4.6.0
2025-04-19 19:56:47,539:INFO:               numba: 0.60.0
2025-04-19 19:56:47,539:INFO:            requests: 2.32.3
2025-04-19 19:56:47,539:INFO:          matplotlib: 3.7.1
2025-04-19 19:56:47,539:INFO:          scikitplot: 0.3.7
2025-04-19 19:56:47,539:INFO:         yellowbrick: 1.5
2025-04-19 19:56:47,539:INFO:              plotly: 5.24.1
2025-04-19 19:56:47,539:INFO:    plotly-resampler: Not installed
2025-04-19 19:56:47,539:INFO:             kaleido: 0.2.1
2025-04-19 19:56:47,539:INFO:           schemdraw: 0.15
2025-04-19 19:56:47,539:INFO:         statsmodels: 0.14.4
2025-04-19 19:56:47,539:INFO:              sktime: 0.21.1
2025-04-19 19:56:47,539:INFO:               tbats: 1.1.3
2025-04-19 19:56:47,539:INFO:            pmdarima: 2.0.4
2025-04-19 19:56:47,539:INFO:              psutil: 7.0.0
2025-04-19 19:56:47,539:INFO:          markupsafe: 3.0.2
2025-04-19 19:56:47,539:INFO:             pickle5: Not installed
2025-04-19 19:56:47,539:INFO:         cloudpickle: 3.1.1
2025-04-19 19:56:47,539:INFO:         deprecation: 2.1.0
2025-04-19 19:56:47,539:INFO:              xxhash: 3.5.0
2025-04-19 19:56:47,539:INFO:           wurlitzer: Not installed
2025-04-19 19:56:47,539:INFO:PyCaret optional dependencies:
2025-04-19 19:56:47,881:INFO:                shap: Not installed
2025-04-19 19:56:47,881:INFO:           interpret: Not installed
2025-04-19 19:56:47,882:INFO:                umap: Not installed
2025-04-19 19:56:47,882:INFO:    pandas_profiling: Not installed
2025-04-19 19:56:47,882:INFO:  explainerdashboard: Not installed
2025-04-19 19:56:47,882:INFO:             autoviz: Not installed
2025-04-19 19:56:47,882:INFO:           fairlearn: Not installed
2025-04-19 19:56:47,882:INFO:          deepchecks: Not installed
2025-04-19 19:56:47,882:INFO:             xgboost: Not installed
2025-04-19 19:56:47,882:INFO:            catboost: Not installed
2025-04-19 19:56:47,882:INFO:              kmodes: Not installed
2025-04-19 19:56:47,882:INFO:             mlxtend: Not installed
2025-04-19 19:56:47,882:INFO:       statsforecast: Not installed
2025-04-19 19:56:47,882:INFO:        tune_sklearn: Not installed
2025-04-19 19:56:47,882:INFO:                 ray: Not installed
2025-04-19 19:56:47,882:INFO:            hyperopt: Not installed
2025-04-19 19:56:47,882:INFO:              optuna: Not installed
2025-04-19 19:56:47,882:INFO:               skopt: Not installed
2025-04-19 19:56:47,882:INFO:              mlflow: 2.21.3
2025-04-19 19:56:47,882:INFO:              gradio: Not installed
2025-04-19 19:56:47,882:INFO:             fastapi: 0.115.12
2025-04-19 19:56:47,883:INFO:             uvicorn: 0.34.2
2025-04-19 19:56:47,883:INFO:              m2cgen: Not installed
2025-04-19 19:56:47,883:INFO:           evidently: Not installed
2025-04-19 19:56:47,883:INFO:               fugue: Not installed
2025-04-19 19:56:47,883:INFO:           streamlit: Not installed
2025-04-19 19:56:47,883:INFO:             prophet: Not installed
2025-04-19 19:56:47,883:INFO:None
2025-04-19 19:56:47,883:INFO:Set up data.
2025-04-19 19:56:47,899:INFO:Set up train/test split.
2025-04-19 19:56:47,901:INFO:Set up index.
2025-04-19 19:56:47,901:INFO:Set up folding strategy.
2025-04-19 19:56:47,901:INFO:Assigning column types.
2025-04-19 19:56:47,905:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:56:47,905:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:56:47,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:56:47,914:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,063:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,070:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,075:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,190:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 19:56:48,194:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,200:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,336:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,443:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 19:56:48,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,576:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,677:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 19:56:48,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:56:48,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:48,901:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:56:48,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:49,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:56:49,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,103:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 19:56:49,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:49,384:INFO:Preparing preprocessing pipeline...
2025-04-19 19:56:49,384:INFO:Set up target transformation.
2025-04-19 19:56:49,384:INFO:Set up simple imputation.
2025-04-19 19:56:49,384:INFO:Set up removing multicollinearity.
2025-04-19 19:56:49,384:INFO:Set up removing outliers.
2025-04-19 19:56:49,384:INFO:Set up feature normalization.
2025-04-19 19:56:49,666:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:56:49,677:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 19:56:49,677:INFO:Creating final display dataframe.
2025-04-19 19:56:50,216:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape      (100, 4)
4        Transformed data shape       (96, 4)
5   Transformed train set shape       (66, 4)
6    Transformed test set shape       (30, 4)
7              Numeric features             3
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12     Remove multicollinearity          True
13  Multicollinearity threshold           0.9
14              Remove outliers          True
15           Outliers threshold          0.05
16                    Normalize          True
17             Normalize method        zscore
18             Transform target          True
19      Transform target method   yeo-johnson
20               Fold Generator         KFold
21                  Fold Number            10
22                     CPU Jobs            -1
23                      Use GPU         False
24               Log Experiment         False
25              Experiment Name  agn_modeling
26                          USI          d0cb
2025-04-19 19:56:50,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:50,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:50,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:50,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:56:50,411:INFO:setup() successfully completed in 3.04s...............
2025-04-19 19:56:50,411:INFO:Initializing compare_models()
2025-04-19 19:56:50,411:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 19:56:50,411:INFO:Checking exceptions
2025-04-19 19:56:50,413:INFO:Preparing display monitor
2025-04-19 19:56:50,416:INFO:Initializing Linear Regression
2025-04-19 19:56:50,417:INFO:Total runtime is 8.936723073323568e-06 minutes
2025-04-19 19:56:50,417:INFO:SubProcess create_model() called ==================================
2025-04-19 19:56:50,417:INFO:Initializing create_model()
2025-04-19 19:56:50,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:56:50,417:INFO:Checking exceptions
2025-04-19 19:56:50,417:INFO:Importing libraries
2025-04-19 19:56:50,417:INFO:Copying training dataset
2025-04-19 19:56:50,420:INFO:Defining folds
2025-04-19 19:56:50,420:INFO:Declaring metric variables
2025-04-19 19:56:50,421:INFO:Importing untrained model
2025-04-19 19:56:50,421:INFO:Linear Regression Imported successfully
2025-04-19 19:56:50,421:INFO:Starting cross validation
2025-04-19 19:56:50,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:56:54,985:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,026:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,089:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,100:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,117:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,156:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,218:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,402:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,792:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:55,804:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:56:56,272:INFO:Calculating mean and std
2025-04-19 19:56:56,273:INFO:Creating metrics dataframe
2025-04-19 19:56:56,386:INFO:Uploading results into container
2025-04-19 19:56:56,387:INFO:Uploading model into container now
2025-04-19 19:56:56,387:INFO:_master_model_container: 1
2025-04-19 19:56:56,387:INFO:_display_container: 2
2025-04-19 19:56:56,388:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:56:56,388:INFO:create_model() successfully completed......................................
2025-04-19 19:56:56,499:INFO:SubProcess create_model() end ==================================
2025-04-19 19:56:56,499:INFO:Creating metrics dataframe
2025-04-19 19:56:56,502:INFO:Initializing Lasso Regression
2025-04-19 19:56:56,502:INFO:Total runtime is 0.10143541892369588 minutes
2025-04-19 19:56:56,502:INFO:SubProcess create_model() called ==================================
2025-04-19 19:56:56,502:INFO:Initializing create_model()
2025-04-19 19:56:56,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:56:56,503:INFO:Checking exceptions
2025-04-19 19:56:56,503:INFO:Importing libraries
2025-04-19 19:56:56,503:INFO:Copying training dataset
2025-04-19 19:56:56,504:INFO:Defining folds
2025-04-19 19:56:56,504:INFO:Declaring metric variables
2025-04-19 19:56:56,506:INFO:Importing untrained model
2025-04-19 19:56:56,506:INFO:Lasso Regression Imported successfully
2025-04-19 19:56:56,506:INFO:Starting cross validation
2025-04-19 19:56:56,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:56:57,372:INFO:Calculating mean and std
2025-04-19 19:56:57,372:INFO:Creating metrics dataframe
2025-04-19 19:56:57,482:INFO:Uploading results into container
2025-04-19 19:56:57,483:INFO:Uploading model into container now
2025-04-19 19:56:57,483:INFO:_master_model_container: 2
2025-04-19 19:56:57,483:INFO:_display_container: 2
2025-04-19 19:56:57,484:INFO:Lasso(random_state=42)
2025-04-19 19:56:57,484:INFO:create_model() successfully completed......................................
2025-04-19 19:56:57,588:INFO:SubProcess create_model() end ==================================
2025-04-19 19:56:57,588:INFO:Creating metrics dataframe
2025-04-19 19:56:57,591:INFO:Initializing Ridge Regression
2025-04-19 19:56:57,591:INFO:Total runtime is 0.11959015925725301 minutes
2025-04-19 19:56:57,591:INFO:SubProcess create_model() called ==================================
2025-04-19 19:56:57,591:INFO:Initializing create_model()
2025-04-19 19:56:57,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:56:57,591:INFO:Checking exceptions
2025-04-19 19:56:57,591:INFO:Importing libraries
2025-04-19 19:56:57,591:INFO:Copying training dataset
2025-04-19 19:56:57,593:INFO:Defining folds
2025-04-19 19:56:57,593:INFO:Declaring metric variables
2025-04-19 19:56:57,593:INFO:Importing untrained model
2025-04-19 19:56:57,595:INFO:Ridge Regression Imported successfully
2025-04-19 19:56:57,595:INFO:Starting cross validation
2025-04-19 19:56:57,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:56:58,442:INFO:Calculating mean and std
2025-04-19 19:56:58,442:INFO:Creating metrics dataframe
2025-04-19 19:56:58,547:INFO:Uploading results into container
2025-04-19 19:56:58,548:INFO:Uploading model into container now
2025-04-19 19:56:58,548:INFO:_master_model_container: 3
2025-04-19 19:56:58,548:INFO:_display_container: 2
2025-04-19 19:56:58,549:INFO:Ridge(random_state=42)
2025-04-19 19:56:58,549:INFO:create_model() successfully completed......................................
2025-04-19 19:56:58,649:INFO:SubProcess create_model() end ==================================
2025-04-19 19:56:58,649:INFO:Creating metrics dataframe
2025-04-19 19:56:58,653:INFO:Initializing Elastic Net
2025-04-19 19:56:58,653:INFO:Total runtime is 0.13728763659795126 minutes
2025-04-19 19:56:58,653:INFO:SubProcess create_model() called ==================================
2025-04-19 19:56:58,654:INFO:Initializing create_model()
2025-04-19 19:56:58,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:56:58,654:INFO:Checking exceptions
2025-04-19 19:56:58,654:INFO:Importing libraries
2025-04-19 19:56:58,654:INFO:Copying training dataset
2025-04-19 19:56:58,667:INFO:Defining folds
2025-04-19 19:56:58,667:INFO:Declaring metric variables
2025-04-19 19:56:58,667:INFO:Importing untrained model
2025-04-19 19:56:58,667:INFO:Elastic Net Imported successfully
2025-04-19 19:56:58,667:INFO:Starting cross validation
2025-04-19 19:56:58,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:56:59,493:INFO:Calculating mean and std
2025-04-19 19:56:59,493:INFO:Creating metrics dataframe
2025-04-19 19:56:59,594:INFO:Uploading results into container
2025-04-19 19:56:59,594:INFO:Uploading model into container now
2025-04-19 19:56:59,595:INFO:_master_model_container: 4
2025-04-19 19:56:59,595:INFO:_display_container: 2
2025-04-19 19:56:59,595:INFO:ElasticNet(random_state=42)
2025-04-19 19:56:59,595:INFO:create_model() successfully completed......................................
2025-04-19 19:56:59,688:INFO:SubProcess create_model() end ==================================
2025-04-19 19:56:59,688:INFO:Creating metrics dataframe
2025-04-19 19:56:59,693:INFO:Initializing Least Angle Regression
2025-04-19 19:56:59,693:INFO:Total runtime is 0.15460811853408815 minutes
2025-04-19 19:56:59,694:INFO:SubProcess create_model() called ==================================
2025-04-19 19:56:59,694:INFO:Initializing create_model()
2025-04-19 19:56:59,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:56:59,694:INFO:Checking exceptions
2025-04-19 19:56:59,694:INFO:Importing libraries
2025-04-19 19:56:59,694:INFO:Copying training dataset
2025-04-19 19:56:59,696:INFO:Defining folds
2025-04-19 19:56:59,696:INFO:Declaring metric variables
2025-04-19 19:56:59,696:INFO:Importing untrained model
2025-04-19 19:56:59,696:INFO:Least Angle Regression Imported successfully
2025-04-19 19:56:59,696:INFO:Starting cross validation
2025-04-19 19:56:59,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:00,530:INFO:Calculating mean and std
2025-04-19 19:57:00,531:INFO:Creating metrics dataframe
2025-04-19 19:57:00,633:INFO:Uploading results into container
2025-04-19 19:57:00,633:INFO:Uploading model into container now
2025-04-19 19:57:00,634:INFO:_master_model_container: 5
2025-04-19 19:57:00,634:INFO:_display_container: 2
2025-04-19 19:57:00,634:INFO:Lars(random_state=42)
2025-04-19 19:57:00,634:INFO:create_model() successfully completed......................................
2025-04-19 19:57:00,727:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:00,727:INFO:Creating metrics dataframe
2025-04-19 19:57:00,731:INFO:Initializing Lasso Least Angle Regression
2025-04-19 19:57:00,731:INFO:Total runtime is 0.17192238966623943 minutes
2025-04-19 19:57:00,731:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:00,731:INFO:Initializing create_model()
2025-04-19 19:57:00,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:00,732:INFO:Checking exceptions
2025-04-19 19:57:00,732:INFO:Importing libraries
2025-04-19 19:57:00,732:INFO:Copying training dataset
2025-04-19 19:57:00,734:INFO:Defining folds
2025-04-19 19:57:00,734:INFO:Declaring metric variables
2025-04-19 19:57:00,734:INFO:Importing untrained model
2025-04-19 19:57:00,734:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 19:57:00,734:INFO:Starting cross validation
2025-04-19 19:57:00,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:01,547:INFO:Calculating mean and std
2025-04-19 19:57:01,547:INFO:Creating metrics dataframe
2025-04-19 19:57:01,648:INFO:Uploading results into container
2025-04-19 19:57:01,650:INFO:Uploading model into container now
2025-04-19 19:57:01,651:INFO:_master_model_container: 6
2025-04-19 19:57:01,651:INFO:_display_container: 2
2025-04-19 19:57:01,651:INFO:LassoLars(random_state=42)
2025-04-19 19:57:01,651:INFO:create_model() successfully completed......................................
2025-04-19 19:57:01,747:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:01,747:INFO:Creating metrics dataframe
2025-04-19 19:57:01,750:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 19:57:01,750:INFO:Total runtime is 0.18889731963475548 minutes
2025-04-19 19:57:01,751:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:01,751:INFO:Initializing create_model()
2025-04-19 19:57:01,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:01,751:INFO:Checking exceptions
2025-04-19 19:57:01,751:INFO:Importing libraries
2025-04-19 19:57:01,751:INFO:Copying training dataset
2025-04-19 19:57:01,753:INFO:Defining folds
2025-04-19 19:57:01,753:INFO:Declaring metric variables
2025-04-19 19:57:01,753:INFO:Importing untrained model
2025-04-19 19:57:01,754:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:57:01,754:INFO:Starting cross validation
2025-04-19 19:57:01,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:02,575:INFO:Calculating mean and std
2025-04-19 19:57:02,575:INFO:Creating metrics dataframe
2025-04-19 19:57:02,679:INFO:Uploading results into container
2025-04-19 19:57:02,679:INFO:Uploading model into container now
2025-04-19 19:57:02,679:INFO:_master_model_container: 7
2025-04-19 19:57:02,679:INFO:_display_container: 2
2025-04-19 19:57:02,679:INFO:OrthogonalMatchingPursuit()
2025-04-19 19:57:02,681:INFO:create_model() successfully completed......................................
2025-04-19 19:57:02,776:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:02,776:INFO:Creating metrics dataframe
2025-04-19 19:57:02,781:INFO:Initializing Bayesian Ridge
2025-04-19 19:57:02,781:INFO:Total runtime is 0.20607636769612633 minutes
2025-04-19 19:57:02,781:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:02,781:INFO:Initializing create_model()
2025-04-19 19:57:02,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:02,781:INFO:Checking exceptions
2025-04-19 19:57:02,781:INFO:Importing libraries
2025-04-19 19:57:02,781:INFO:Copying training dataset
2025-04-19 19:57:02,783:INFO:Defining folds
2025-04-19 19:57:02,783:INFO:Declaring metric variables
2025-04-19 19:57:02,783:INFO:Importing untrained model
2025-04-19 19:57:02,783:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:57:02,784:INFO:Starting cross validation
2025-04-19 19:57:02,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:03,619:INFO:Calculating mean and std
2025-04-19 19:57:03,620:INFO:Creating metrics dataframe
2025-04-19 19:57:03,727:INFO:Uploading results into container
2025-04-19 19:57:03,727:INFO:Uploading model into container now
2025-04-19 19:57:03,728:INFO:_master_model_container: 8
2025-04-19 19:57:03,728:INFO:_display_container: 2
2025-04-19 19:57:03,728:INFO:BayesianRidge()
2025-04-19 19:57:03,728:INFO:create_model() successfully completed......................................
2025-04-19 19:57:03,824:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:03,824:INFO:Creating metrics dataframe
2025-04-19 19:57:03,827:INFO:Initializing Passive Aggressive Regressor
2025-04-19 19:57:03,827:INFO:Total runtime is 0.2235134363174439 minutes
2025-04-19 19:57:03,828:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:03,828:INFO:Initializing create_model()
2025-04-19 19:57:03,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:03,828:INFO:Checking exceptions
2025-04-19 19:57:03,828:INFO:Importing libraries
2025-04-19 19:57:03,828:INFO:Copying training dataset
2025-04-19 19:57:03,830:INFO:Defining folds
2025-04-19 19:57:03,830:INFO:Declaring metric variables
2025-04-19 19:57:03,831:INFO:Importing untrained model
2025-04-19 19:57:03,831:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 19:57:03,831:INFO:Starting cross validation
2025-04-19 19:57:03,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:04,676:INFO:Calculating mean and std
2025-04-19 19:57:04,676:INFO:Creating metrics dataframe
2025-04-19 19:57:04,777:INFO:Uploading results into container
2025-04-19 19:57:04,778:INFO:Uploading model into container now
2025-04-19 19:57:04,778:INFO:_master_model_container: 9
2025-04-19 19:57:04,778:INFO:_display_container: 2
2025-04-19 19:57:04,778:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 19:57:04,778:INFO:create_model() successfully completed......................................
2025-04-19 19:57:04,874:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:04,874:INFO:Creating metrics dataframe
2025-04-19 19:57:04,879:INFO:Initializing Huber Regressor
2025-04-19 19:57:04,879:INFO:Total runtime is 0.24105054537455245 minutes
2025-04-19 19:57:04,879:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:04,879:INFO:Initializing create_model()
2025-04-19 19:57:04,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:04,879:INFO:Checking exceptions
2025-04-19 19:57:04,879:INFO:Importing libraries
2025-04-19 19:57:04,879:INFO:Copying training dataset
2025-04-19 19:57:04,883:INFO:Defining folds
2025-04-19 19:57:04,883:INFO:Declaring metric variables
2025-04-19 19:57:04,883:INFO:Importing untrained model
2025-04-19 19:57:04,883:INFO:Huber Regressor Imported successfully
2025-04-19 19:57:04,883:INFO:Starting cross validation
2025-04-19 19:57:04,890:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:05,799:INFO:Calculating mean and std
2025-04-19 19:57:05,799:INFO:Creating metrics dataframe
2025-04-19 19:57:05,920:INFO:Uploading results into container
2025-04-19 19:57:05,920:INFO:Uploading model into container now
2025-04-19 19:57:05,921:INFO:_master_model_container: 10
2025-04-19 19:57:05,921:INFO:_display_container: 2
2025-04-19 19:57:05,921:INFO:HuberRegressor()
2025-04-19 19:57:05,921:INFO:create_model() successfully completed......................................
2025-04-19 19:57:06,019:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:06,019:INFO:Creating metrics dataframe
2025-04-19 19:57:06,023:INFO:Initializing K Neighbors Regressor
2025-04-19 19:57:06,023:INFO:Total runtime is 0.2601223746935527 minutes
2025-04-19 19:57:06,023:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:06,024:INFO:Initializing create_model()
2025-04-19 19:57:06,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:06,024:INFO:Checking exceptions
2025-04-19 19:57:06,024:INFO:Importing libraries
2025-04-19 19:57:06,024:INFO:Copying training dataset
2025-04-19 19:57:06,027:INFO:Defining folds
2025-04-19 19:57:06,027:INFO:Declaring metric variables
2025-04-19 19:57:06,027:INFO:Importing untrained model
2025-04-19 19:57:06,027:INFO:K Neighbors Regressor Imported successfully
2025-04-19 19:57:06,027:INFO:Starting cross validation
2025-04-19 19:57:06,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:06,895:INFO:Calculating mean and std
2025-04-19 19:57:06,896:INFO:Creating metrics dataframe
2025-04-19 19:57:07,003:INFO:Uploading results into container
2025-04-19 19:57:07,004:INFO:Uploading model into container now
2025-04-19 19:57:07,004:INFO:_master_model_container: 11
2025-04-19 19:57:07,004:INFO:_display_container: 2
2025-04-19 19:57:07,004:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 19:57:07,004:INFO:create_model() successfully completed......................................
2025-04-19 19:57:07,098:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:07,098:INFO:Creating metrics dataframe
2025-04-19 19:57:07,102:INFO:Initializing Decision Tree Regressor
2025-04-19 19:57:07,102:INFO:Total runtime is 0.2780978957811992 minutes
2025-04-19 19:57:07,102:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:07,102:INFO:Initializing create_model()
2025-04-19 19:57:07,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:07,102:INFO:Checking exceptions
2025-04-19 19:57:07,102:INFO:Importing libraries
2025-04-19 19:57:07,102:INFO:Copying training dataset
2025-04-19 19:57:07,105:INFO:Defining folds
2025-04-19 19:57:07,105:INFO:Declaring metric variables
2025-04-19 19:57:07,105:INFO:Importing untrained model
2025-04-19 19:57:07,105:INFO:Decision Tree Regressor Imported successfully
2025-04-19 19:57:07,105:INFO:Starting cross validation
2025-04-19 19:57:07,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:07,973:INFO:Calculating mean and std
2025-04-19 19:57:07,973:INFO:Creating metrics dataframe
2025-04-19 19:57:08,086:INFO:Uploading results into container
2025-04-19 19:57:08,087:INFO:Uploading model into container now
2025-04-19 19:57:08,087:INFO:_master_model_container: 12
2025-04-19 19:57:08,087:INFO:_display_container: 2
2025-04-19 19:57:08,088:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 19:57:08,088:INFO:create_model() successfully completed......................................
2025-04-19 19:57:08,185:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:08,185:INFO:Creating metrics dataframe
2025-04-19 19:57:08,188:INFO:Initializing Random Forest Regressor
2025-04-19 19:57:08,188:INFO:Total runtime is 0.29620311657587695 minutes
2025-04-19 19:57:08,188:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:08,189:INFO:Initializing create_model()
2025-04-19 19:57:08,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:08,189:INFO:Checking exceptions
2025-04-19 19:57:08,189:INFO:Importing libraries
2025-04-19 19:57:08,189:INFO:Copying training dataset
2025-04-19 19:57:08,191:INFO:Defining folds
2025-04-19 19:57:08,191:INFO:Declaring metric variables
2025-04-19 19:57:08,191:INFO:Importing untrained model
2025-04-19 19:57:08,191:INFO:Random Forest Regressor Imported successfully
2025-04-19 19:57:08,192:INFO:Starting cross validation
2025-04-19 19:57:08,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:09,551:INFO:Calculating mean and std
2025-04-19 19:57:09,552:INFO:Creating metrics dataframe
2025-04-19 19:57:09,655:INFO:Uploading results into container
2025-04-19 19:57:09,655:INFO:Uploading model into container now
2025-04-19 19:57:09,655:INFO:_master_model_container: 13
2025-04-19 19:57:09,655:INFO:_display_container: 2
2025-04-19 19:57:09,655:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:57:09,655:INFO:create_model() successfully completed......................................
2025-04-19 19:57:09,751:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:09,751:INFO:Creating metrics dataframe
2025-04-19 19:57:09,755:INFO:Initializing Extra Trees Regressor
2025-04-19 19:57:09,756:INFO:Total runtime is 0.32233115037282317 minutes
2025-04-19 19:57:09,756:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:09,756:INFO:Initializing create_model()
2025-04-19 19:57:09,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:09,756:INFO:Checking exceptions
2025-04-19 19:57:09,756:INFO:Importing libraries
2025-04-19 19:57:09,756:INFO:Copying training dataset
2025-04-19 19:57:09,759:INFO:Defining folds
2025-04-19 19:57:09,759:INFO:Declaring metric variables
2025-04-19 19:57:09,759:INFO:Importing untrained model
2025-04-19 19:57:09,759:INFO:Extra Trees Regressor Imported successfully
2025-04-19 19:57:09,759:INFO:Starting cross validation
2025-04-19 19:57:09,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:11,074:INFO:Calculating mean and std
2025-04-19 19:57:11,074:INFO:Creating metrics dataframe
2025-04-19 19:57:11,197:INFO:Uploading results into container
2025-04-19 19:57:11,198:INFO:Uploading model into container now
2025-04-19 19:57:11,198:INFO:_master_model_container: 14
2025-04-19 19:57:11,198:INFO:_display_container: 2
2025-04-19 19:57:11,199:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:57:11,199:INFO:create_model() successfully completed......................................
2025-04-19 19:57:11,297:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:11,297:INFO:Creating metrics dataframe
2025-04-19 19:57:11,301:INFO:Initializing AdaBoost Regressor
2025-04-19 19:57:11,301:INFO:Total runtime is 0.34809019962946586 minutes
2025-04-19 19:57:11,301:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:11,302:INFO:Initializing create_model()
2025-04-19 19:57:11,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:11,302:INFO:Checking exceptions
2025-04-19 19:57:11,302:INFO:Importing libraries
2025-04-19 19:57:11,302:INFO:Copying training dataset
2025-04-19 19:57:11,304:INFO:Defining folds
2025-04-19 19:57:11,304:INFO:Declaring metric variables
2025-04-19 19:57:11,304:INFO:Importing untrained model
2025-04-19 19:57:11,304:INFO:AdaBoost Regressor Imported successfully
2025-04-19 19:57:11,304:INFO:Starting cross validation
2025-04-19 19:57:11,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:12,307:INFO:Calculating mean and std
2025-04-19 19:57:12,307:INFO:Creating metrics dataframe
2025-04-19 19:57:12,428:INFO:Uploading results into container
2025-04-19 19:57:12,429:INFO:Uploading model into container now
2025-04-19 19:57:12,429:INFO:_master_model_container: 15
2025-04-19 19:57:12,429:INFO:_display_container: 2
2025-04-19 19:57:12,429:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 19:57:12,429:INFO:create_model() successfully completed......................................
2025-04-19 19:57:12,523:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:12,523:INFO:Creating metrics dataframe
2025-04-19 19:57:12,527:INFO:Initializing Gradient Boosting Regressor
2025-04-19 19:57:12,536:INFO:Total runtime is 0.3686573942502341 minutes
2025-04-19 19:57:12,536:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:12,536:INFO:Initializing create_model()
2025-04-19 19:57:12,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:12,536:INFO:Checking exceptions
2025-04-19 19:57:12,536:INFO:Importing libraries
2025-04-19 19:57:12,536:INFO:Copying training dataset
2025-04-19 19:57:12,538:INFO:Defining folds
2025-04-19 19:57:12,538:INFO:Declaring metric variables
2025-04-19 19:57:12,538:INFO:Importing untrained model
2025-04-19 19:57:12,539:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 19:57:12,539:INFO:Starting cross validation
2025-04-19 19:57:12,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:13,567:INFO:Calculating mean and std
2025-04-19 19:57:13,568:INFO:Creating metrics dataframe
2025-04-19 19:57:13,686:INFO:Uploading results into container
2025-04-19 19:57:13,687:INFO:Uploading model into container now
2025-04-19 19:57:13,687:INFO:_master_model_container: 16
2025-04-19 19:57:13,687:INFO:_display_container: 2
2025-04-19 19:57:13,688:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 19:57:13,688:INFO:create_model() successfully completed......................................
2025-04-19 19:57:13,784:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:13,784:INFO:Creating metrics dataframe
2025-04-19 19:57:13,787:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:57:13,787:INFO:Total runtime is 0.3895114262898764 minutes
2025-04-19 19:57:13,788:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:13,788:INFO:Initializing create_model()
2025-04-19 19:57:13,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:13,788:INFO:Checking exceptions
2025-04-19 19:57:13,788:INFO:Importing libraries
2025-04-19 19:57:13,788:INFO:Copying training dataset
2025-04-19 19:57:13,790:INFO:Defining folds
2025-04-19 19:57:13,791:INFO:Declaring metric variables
2025-04-19 19:57:13,791:INFO:Importing untrained model
2025-04-19 19:57:13,791:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:57:13,791:INFO:Starting cross validation
2025-04-19 19:57:13,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:14,997:INFO:Calculating mean and std
2025-04-19 19:57:14,997:INFO:Creating metrics dataframe
2025-04-19 19:57:15,114:INFO:Uploading results into container
2025-04-19 19:57:15,114:INFO:Uploading model into container now
2025-04-19 19:57:15,114:INFO:_master_model_container: 17
2025-04-19 19:57:15,114:INFO:_display_container: 2
2025-04-19 19:57:15,116:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:57:15,116:INFO:create_model() successfully completed......................................
2025-04-19 19:57:15,216:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:15,216:INFO:Creating metrics dataframe
2025-04-19 19:57:15,219:INFO:Initializing Dummy Regressor
2025-04-19 19:57:15,219:INFO:Total runtime is 0.413379720846812 minutes
2025-04-19 19:57:15,219:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:15,220:INFO:Initializing create_model()
2025-04-19 19:57:15,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0783580>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:15,220:INFO:Checking exceptions
2025-04-19 19:57:15,220:INFO:Importing libraries
2025-04-19 19:57:15,220:INFO:Copying training dataset
2025-04-19 19:57:15,223:INFO:Defining folds
2025-04-19 19:57:15,223:INFO:Declaring metric variables
2025-04-19 19:57:15,223:INFO:Importing untrained model
2025-04-19 19:57:15,223:INFO:Dummy Regressor Imported successfully
2025-04-19 19:57:15,223:INFO:Starting cross validation
2025-04-19 19:57:15,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:16,196:INFO:Calculating mean and std
2025-04-19 19:57:16,197:INFO:Creating metrics dataframe
2025-04-19 19:57:16,312:INFO:Uploading results into container
2025-04-19 19:57:16,312:INFO:Uploading model into container now
2025-04-19 19:57:16,313:INFO:_master_model_container: 18
2025-04-19 19:57:16,313:INFO:_display_container: 2
2025-04-19 19:57:16,313:INFO:DummyRegressor()
2025-04-19 19:57:16,313:INFO:create_model() successfully completed......................................
2025-04-19 19:57:16,405:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:16,406:INFO:Creating metrics dataframe
2025-04-19 19:57:16,410:INFO:Initializing create_model()
2025-04-19 19:57:16,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=Lasso(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:16,410:INFO:Checking exceptions
2025-04-19 19:57:16,410:INFO:Importing libraries
2025-04-19 19:57:16,410:INFO:Copying training dataset
2025-04-19 19:57:16,412:INFO:Defining folds
2025-04-19 19:57:16,412:INFO:Declaring metric variables
2025-04-19 19:57:16,413:INFO:Importing untrained model
2025-04-19 19:57:16,413:INFO:Declaring custom model
2025-04-19 19:57:16,413:INFO:Lasso Regression Imported successfully
2025-04-19 19:57:16,419:INFO:Cross validation set to False
2025-04-19 19:57:16,419:INFO:Fitting Model
2025-04-19 19:57:16,542:INFO:Lasso(random_state=42)
2025-04-19 19:57:16,542:INFO:create_model() successfully completed......................................
2025-04-19 19:57:16,639:INFO:Initializing create_model()
2025-04-19 19:57:16,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=ElasticNet(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:16,639:INFO:Checking exceptions
2025-04-19 19:57:16,639:INFO:Importing libraries
2025-04-19 19:57:16,641:INFO:Copying training dataset
2025-04-19 19:57:16,643:INFO:Defining folds
2025-04-19 19:57:16,644:INFO:Declaring metric variables
2025-04-19 19:57:16,644:INFO:Importing untrained model
2025-04-19 19:57:16,644:INFO:Declaring custom model
2025-04-19 19:57:16,645:INFO:Elastic Net Imported successfully
2025-04-19 19:57:16,652:INFO:Cross validation set to False
2025-04-19 19:57:16,652:INFO:Fitting Model
2025-04-19 19:57:16,772:INFO:ElasticNet(random_state=42)
2025-04-19 19:57:16,772:INFO:create_model() successfully completed......................................
2025-04-19 19:57:16,873:INFO:Initializing create_model()
2025-04-19 19:57:16,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=DummyRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:16,873:INFO:Checking exceptions
2025-04-19 19:57:16,873:INFO:Importing libraries
2025-04-19 19:57:16,873:INFO:Copying training dataset
2025-04-19 19:57:16,876:INFO:Defining folds
2025-04-19 19:57:16,876:INFO:Declaring metric variables
2025-04-19 19:57:16,876:INFO:Importing untrained model
2025-04-19 19:57:16,876:INFO:Declaring custom model
2025-04-19 19:57:16,876:INFO:Dummy Regressor Imported successfully
2025-04-19 19:57:16,883:INFO:Cross validation set to False
2025-04-19 19:57:16,883:INFO:Fitting Model
2025-04-19 19:57:16,998:INFO:DummyRegressor()
2025-04-19 19:57:16,998:INFO:create_model() successfully completed......................................
2025-04-19 19:57:17,106:INFO:_master_model_container: 18
2025-04-19 19:57:17,106:INFO:_display_container: 2
2025-04-19 19:57:17,107:INFO:[Lasso(random_state=42), ElasticNet(random_state=42), DummyRegressor()]
2025-04-19 19:57:17,107:INFO:compare_models() successfully completed......................................
2025-04-19 19:57:17,107:INFO:Initializing tune_model()
2025-04-19 19:57:17,107:INFO:tune_model(estimator=Lasso(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>)
2025-04-19 19:57:17,107:INFO:Checking exceptions
2025-04-19 19:57:17,109:INFO:Copying training dataset
2025-04-19 19:57:17,110:INFO:Checking base model
2025-04-19 19:57:17,110:INFO:Base model : Lasso Regression
2025-04-19 19:57:17,110:INFO:Declaring metric variables
2025-04-19 19:57:17,110:INFO:Defining Hyperparameters
2025-04-19 19:57:17,212:INFO:Tuning with n_jobs=-1
2025-04-19 19:57:17,212:INFO:Initializing RandomizedSearchCV
2025-04-19 19:57:29,893:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 5.48}
2025-04-19 19:57:29,894:INFO:Hyperparameter search completed
2025-04-19 19:57:29,894:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:29,895:INFO:Initializing create_model()
2025-04-19 19:57:29,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=Lasso(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9A7D1330>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'alpha': 5.48})
2025-04-19 19:57:29,896:INFO:Checking exceptions
2025-04-19 19:57:29,896:INFO:Importing libraries
2025-04-19 19:57:29,896:INFO:Copying training dataset
2025-04-19 19:57:29,903:INFO:Defining folds
2025-04-19 19:57:29,903:INFO:Declaring metric variables
2025-04-19 19:57:29,903:INFO:Importing untrained model
2025-04-19 19:57:29,904:INFO:Declaring custom model
2025-04-19 19:57:29,904:INFO:Lasso Regression Imported successfully
2025-04-19 19:57:29,906:INFO:Starting cross validation
2025-04-19 19:57:29,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:31,758:INFO:Calculating mean and std
2025-04-19 19:57:31,759:INFO:Creating metrics dataframe
2025-04-19 19:57:31,765:INFO:Finalizing model
2025-04-19 19:57:32,173:INFO:Uploading results into container
2025-04-19 19:57:32,175:INFO:Uploading model into container now
2025-04-19 19:57:32,176:INFO:_master_model_container: 19
2025-04-19 19:57:32,176:INFO:_display_container: 3
2025-04-19 19:57:32,176:INFO:Lasso(alpha=5.48, fit_intercept=False, random_state=42)
2025-04-19 19:57:32,177:INFO:create_model() successfully completed......................................
2025-04-19 19:57:32,369:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:32,369:INFO:choose_better activated
2025-04-19 19:57:32,369:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:32,369:INFO:Initializing create_model()
2025-04-19 19:57:32,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=Lasso(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:32,369:INFO:Checking exceptions
2025-04-19 19:57:32,372:INFO:Importing libraries
2025-04-19 19:57:32,372:INFO:Copying training dataset
2025-04-19 19:57:32,378:INFO:Defining folds
2025-04-19 19:57:32,379:INFO:Declaring metric variables
2025-04-19 19:57:32,379:INFO:Importing untrained model
2025-04-19 19:57:32,379:INFO:Declaring custom model
2025-04-19 19:57:32,380:INFO:Lasso Regression Imported successfully
2025-04-19 19:57:32,380:INFO:Starting cross validation
2025-04-19 19:57:32,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:34,087:INFO:Calculating mean and std
2025-04-19 19:57:34,088:INFO:Creating metrics dataframe
2025-04-19 19:57:34,093:INFO:Finalizing model
2025-04-19 19:57:34,472:INFO:Uploading results into container
2025-04-19 19:57:34,473:INFO:Uploading model into container now
2025-04-19 19:57:34,474:INFO:_master_model_container: 20
2025-04-19 19:57:34,474:INFO:_display_container: 4
2025-04-19 19:57:34,474:INFO:Lasso(random_state=42)
2025-04-19 19:57:34,474:INFO:create_model() successfully completed......................................
2025-04-19 19:57:34,616:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:34,617:INFO:Lasso(random_state=42) result for R2 is -0.4117
2025-04-19 19:57:34,618:INFO:Lasso(alpha=5.48, fit_intercept=False, random_state=42) result for R2 is -0.3924
2025-04-19 19:57:34,618:INFO:Lasso(alpha=5.48, fit_intercept=False, random_state=42) is best model
2025-04-19 19:57:34,618:INFO:choose_better completed
2025-04-19 19:57:34,626:INFO:_master_model_container: 20
2025-04-19 19:57:34,626:INFO:_display_container: 3
2025-04-19 19:57:34,626:INFO:Lasso(alpha=5.48, fit_intercept=False, random_state=42)
2025-04-19 19:57:34,627:INFO:tune_model() successfully completed......................................
2025-04-19 19:57:34,920:INFO:Initializing tune_model()
2025-04-19 19:57:34,920:INFO:tune_model(estimator=ElasticNet(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>)
2025-04-19 19:57:34,920:INFO:Checking exceptions
2025-04-19 19:57:34,922:INFO:Copying training dataset
2025-04-19 19:57:34,924:INFO:Checking base model
2025-04-19 19:57:34,924:INFO:Base model : Elastic Net
2025-04-19 19:57:34,924:INFO:Declaring metric variables
2025-04-19 19:57:34,924:INFO:Defining Hyperparameters
2025-04-19 19:57:35,088:INFO:Tuning with n_jobs=-1
2025-04-19 19:57:35,088:INFO:Initializing RandomizedSearchCV
2025-04-19 19:57:54,315:INFO:best_params: {'actual_estimator__l1_ratio': 0.842999999999999, 'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 8.55}
2025-04-19 19:57:54,316:INFO:Hyperparameter search completed
2025-04-19 19:57:54,316:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:54,316:INFO:Initializing create_model()
2025-04-19 19:57:54,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=ElasticNet(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA09D87C0>, model_only=True, return_train_score=False, kwargs={'l1_ratio': 0.842999999999999, 'fit_intercept': False, 'alpha': 8.55})
2025-04-19 19:57:54,317:INFO:Checking exceptions
2025-04-19 19:57:54,317:INFO:Importing libraries
2025-04-19 19:57:54,317:INFO:Copying training dataset
2025-04-19 19:57:54,321:INFO:Defining folds
2025-04-19 19:57:54,321:INFO:Declaring metric variables
2025-04-19 19:57:54,321:INFO:Importing untrained model
2025-04-19 19:57:54,321:INFO:Declaring custom model
2025-04-19 19:57:54,322:INFO:Elastic Net Imported successfully
2025-04-19 19:57:54,323:INFO:Starting cross validation
2025-04-19 19:57:54,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:56,170:INFO:Calculating mean and std
2025-04-19 19:57:56,170:INFO:Creating metrics dataframe
2025-04-19 19:57:56,173:INFO:Finalizing model
2025-04-19 19:57:56,571:INFO:Uploading results into container
2025-04-19 19:57:56,572:INFO:Uploading model into container now
2025-04-19 19:57:56,573:INFO:_master_model_container: 21
2025-04-19 19:57:56,574:INFO:_display_container: 4
2025-04-19 19:57:56,575:INFO:ElasticNet(alpha=8.55, fit_intercept=False, l1_ratio=0.842999999999999,
           random_state=42)
2025-04-19 19:57:56,575:INFO:create_model() successfully completed......................................
2025-04-19 19:57:56,763:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:56,763:INFO:choose_better activated
2025-04-19 19:57:56,764:INFO:SubProcess create_model() called ==================================
2025-04-19 19:57:56,764:INFO:Initializing create_model()
2025-04-19 19:57:56,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>, estimator=ElasticNet(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:57:56,764:INFO:Checking exceptions
2025-04-19 19:57:56,766:INFO:Importing libraries
2025-04-19 19:57:56,766:INFO:Copying training dataset
2025-04-19 19:57:56,769:INFO:Defining folds
2025-04-19 19:57:56,769:INFO:Declaring metric variables
2025-04-19 19:57:56,769:INFO:Importing untrained model
2025-04-19 19:57:56,769:INFO:Declaring custom model
2025-04-19 19:57:56,770:INFO:Elastic Net Imported successfully
2025-04-19 19:57:56,770:INFO:Starting cross validation
2025-04-19 19:57:56,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:57:58,483:INFO:Calculating mean and std
2025-04-19 19:57:58,484:INFO:Creating metrics dataframe
2025-04-19 19:57:58,487:INFO:Finalizing model
2025-04-19 19:57:58,884:INFO:Uploading results into container
2025-04-19 19:57:58,886:INFO:Uploading model into container now
2025-04-19 19:57:58,886:INFO:_master_model_container: 22
2025-04-19 19:57:58,887:INFO:_display_container: 5
2025-04-19 19:57:58,887:INFO:ElasticNet(random_state=42)
2025-04-19 19:57:58,887:INFO:create_model() successfully completed......................................
2025-04-19 19:57:59,055:INFO:SubProcess create_model() end ==================================
2025-04-19 19:57:59,056:INFO:ElasticNet(random_state=42) result for R2 is -0.4117
2025-04-19 19:57:59,059:INFO:ElasticNet(alpha=8.55, fit_intercept=False, l1_ratio=0.842999999999999,
           random_state=42) result for R2 is -0.3924
2025-04-19 19:57:59,060:INFO:ElasticNet(alpha=8.55, fit_intercept=False, l1_ratio=0.842999999999999,
           random_state=42) is best model
2025-04-19 19:57:59,060:INFO:choose_better completed
2025-04-19 19:57:59,085:INFO:_master_model_container: 22
2025-04-19 19:57:59,086:INFO:_display_container: 4
2025-04-19 19:57:59,086:INFO:ElasticNet(alpha=8.55, fit_intercept=False, l1_ratio=0.842999999999999,
           random_state=42)
2025-04-19 19:57:59,086:INFO:tune_model() successfully completed......................................
2025-04-19 19:57:59,440:INFO:Initializing tune_model()
2025-04-19 19:57:59,440:INFO:tune_model(estimator=DummyRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9EA686A0>)
2025-04-19 19:57:59,440:INFO:Checking exceptions
2025-04-19 19:57:59,444:INFO:Copying training dataset
2025-04-19 19:57:59,447:INFO:Checking base model
2025-04-19 19:57:59,448:INFO:Base model : Dummy Regressor
2025-04-19 19:57:59,448:INFO:Declaring metric variables
2025-04-19 19:57:59,449:INFO:Defining Hyperparameters
2025-04-19 19:57:59,449:INFO:10 is bigger than total combinations 1, setting search algorithm to grid
2025-04-19 19:58:13,295:INFO:PyCaret RegressionExperiment
2025-04-19 19:58:13,295:INFO:Logging name: agn_modeling
2025-04-19 19:58:13,295:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 19:58:13,297:INFO:version 3.0.4
2025-04-19 19:58:13,297:INFO:Initializing setup()
2025-04-19 19:58:13,297:INFO:self.USI: e151
2025-04-19 19:58:13,297:INFO:self._variable_keys: {'exp_id', 'y_test', 'log_plots_param', 'transform_target_param', 'USI', '_available_plots', 'target_param', 'exp_name_log', 'pipeline', 'X_train', 'gpu_param', 'n_jobs_param', 'y', 'memory', 'X', 'seed', 'logging_param', '_ml_usecase', 'data', 'y_train', 'fold_groups_param', 'idx', 'fold_generator', 'fold_shuffle_param', 'X_test', 'gpu_n_jobs_param', 'html_param'}
2025-04-19 19:58:13,297:INFO:Checking environment
2025-04-19 19:58:13,297:INFO:python_version: 3.10.9
2025-04-19 19:58:13,297:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 19:58:13,297:INFO:machine: AMD64
2025-04-19 19:58:13,297:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:58:13,304:INFO:Memory: svmem(total=16952647680, available=3148140544, percent=81.4, used=13804507136, free=3148140544)
2025-04-19 19:58:13,305:INFO:Physical Core: 4
2025-04-19 19:58:13,305:INFO:Logical Core: 8
2025-04-19 19:58:13,305:INFO:Checking libraries
2025-04-19 19:58:13,305:INFO:System:
2025-04-19 19:58:13,305:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 19:58:13,305:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 19:58:13,305:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:58:13,305:INFO:PyCaret required dependencies:
2025-04-19 19:58:13,305:INFO:                 pip: 25.0.1
2025-04-19 19:58:13,305:INFO:          setuptools: 65.5.0
2025-04-19 19:58:13,305:INFO:             pycaret: 3.0.4
2025-04-19 19:58:13,305:INFO:             IPython: 8.35.0
2025-04-19 19:58:13,305:INFO:          ipywidgets: 8.1.6
2025-04-19 19:58:13,305:INFO:                tqdm: 4.67.1
2025-04-19 19:58:13,305:INFO:               numpy: 1.23.5
2025-04-19 19:58:13,305:INFO:              pandas: 1.5.3
2025-04-19 19:58:13,306:INFO:              jinja2: 3.1.6
2025-04-19 19:58:13,306:INFO:               scipy: 1.10.1
2025-04-19 19:58:13,306:INFO:              joblib: 1.2.0
2025-04-19 19:58:13,306:INFO:             sklearn: 1.2.2
2025-04-19 19:58:13,306:INFO:                pyod: 2.0.4
2025-04-19 19:58:13,306:INFO:            imblearn: 0.12.4
2025-04-19 19:58:13,306:INFO:   category_encoders: 2.7.0
2025-04-19 19:58:13,306:INFO:            lightgbm: 4.6.0
2025-04-19 19:58:13,306:INFO:               numba: 0.60.0
2025-04-19 19:58:13,306:INFO:            requests: 2.32.3
2025-04-19 19:58:13,306:INFO:          matplotlib: 3.7.1
2025-04-19 19:58:13,306:INFO:          scikitplot: 0.3.7
2025-04-19 19:58:13,306:INFO:         yellowbrick: 1.5
2025-04-19 19:58:13,306:INFO:              plotly: 5.24.1
2025-04-19 19:58:13,306:INFO:    plotly-resampler: Not installed
2025-04-19 19:58:13,306:INFO:             kaleido: 0.2.1
2025-04-19 19:58:13,306:INFO:           schemdraw: 0.15
2025-04-19 19:58:13,306:INFO:         statsmodels: 0.14.4
2025-04-19 19:58:13,306:INFO:              sktime: 0.21.1
2025-04-19 19:58:13,307:INFO:               tbats: 1.1.3
2025-04-19 19:58:13,307:INFO:            pmdarima: 2.0.4
2025-04-19 19:58:13,307:INFO:              psutil: 7.0.0
2025-04-19 19:58:13,307:INFO:          markupsafe: 3.0.2
2025-04-19 19:58:13,307:INFO:             pickle5: Not installed
2025-04-19 19:58:13,307:INFO:         cloudpickle: 3.1.1
2025-04-19 19:58:13,307:INFO:         deprecation: 2.1.0
2025-04-19 19:58:13,307:INFO:              xxhash: 3.5.0
2025-04-19 19:58:13,307:INFO:           wurlitzer: Not installed
2025-04-19 19:58:13,307:INFO:PyCaret optional dependencies:
2025-04-19 19:58:13,307:INFO:                shap: Not installed
2025-04-19 19:58:13,307:INFO:           interpret: Not installed
2025-04-19 19:58:13,307:INFO:                umap: Not installed
2025-04-19 19:58:13,307:INFO:    pandas_profiling: Not installed
2025-04-19 19:58:13,307:INFO:  explainerdashboard: Not installed
2025-04-19 19:58:13,307:INFO:             autoviz: Not installed
2025-04-19 19:58:13,307:INFO:           fairlearn: Not installed
2025-04-19 19:58:13,307:INFO:          deepchecks: Not installed
2025-04-19 19:58:13,308:INFO:             xgboost: Not installed
2025-04-19 19:58:13,308:INFO:            catboost: Not installed
2025-04-19 19:58:13,308:INFO:              kmodes: Not installed
2025-04-19 19:58:13,308:INFO:             mlxtend: Not installed
2025-04-19 19:58:13,308:INFO:       statsforecast: Not installed
2025-04-19 19:58:13,308:INFO:        tune_sklearn: Not installed
2025-04-19 19:58:13,308:INFO:                 ray: Not installed
2025-04-19 19:58:13,308:INFO:            hyperopt: Not installed
2025-04-19 19:58:13,308:INFO:              optuna: Not installed
2025-04-19 19:58:13,308:INFO:               skopt: Not installed
2025-04-19 19:58:13,308:INFO:              mlflow: 2.21.3
2025-04-19 19:58:13,308:INFO:              gradio: Not installed
2025-04-19 19:58:13,308:INFO:             fastapi: 0.115.12
2025-04-19 19:58:13,308:INFO:             uvicorn: 0.34.2
2025-04-19 19:58:13,308:INFO:              m2cgen: Not installed
2025-04-19 19:58:13,308:INFO:           evidently: Not installed
2025-04-19 19:58:13,309:INFO:               fugue: Not installed
2025-04-19 19:58:13,309:INFO:           streamlit: Not installed
2025-04-19 19:58:13,309:INFO:             prophet: Not installed
2025-04-19 19:58:13,309:INFO:None
2025-04-19 19:58:13,309:INFO:Set up data.
2025-04-19 19:58:13,318:INFO:Set up train/test split.
2025-04-19 19:58:13,324:INFO:Set up index.
2025-04-19 19:58:13,326:INFO:Set up folding strategy.
2025-04-19 19:58:13,326:INFO:Assigning column types.
2025-04-19 19:58:13,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:58:13,336:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,349:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,356:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:13,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:13,533:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,541:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:13,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:13,809:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 19:58:13,818:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:13,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,082:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,091:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,321:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 19:58:14,330:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,719:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:14,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:14,799:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 19:58:15,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,554:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:58:15,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 19:58:15,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:15,931:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 19:58:16,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:16,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:16,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:16,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:16,372:INFO:Preparing preprocessing pipeline...
2025-04-19 19:58:16,372:INFO:Set up target transformation.
2025-04-19 19:58:16,372:INFO:Set up simple imputation.
2025-04-19 19:58:16,372:INFO:Set up removing multicollinearity.
2025-04-19 19:58:16,373:INFO:Set up removing outliers.
2025-04-19 19:58:16,373:INFO:Set up feature normalization.
2025-04-19 19:58:16,861:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:58:16,878:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 19:58:16,878:INFO:Creating final display dataframe.
2025-04-19 19:58:17,990:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape       (80, 4)
4        Transformed data shape       (77, 4)
5   Transformed train set shape       (53, 4)
6    Transformed test set shape       (24, 4)
7              Numeric features             3
8                    Preprocess          True
9               Imputation type        simple
10           Numeric imputation          mean
11       Categorical imputation          mode
12     Remove multicollinearity          True
13  Multicollinearity threshold           0.9
14              Remove outliers          True
15           Outliers threshold          0.05
16                    Normalize          True
17             Normalize method        zscore
18             Transform target          True
19      Transform target method   yeo-johnson
20               Fold Generator         KFold
21                  Fold Number            10
22                     CPU Jobs            -1
23                      Use GPU         False
24               Log Experiment         False
25              Experiment Name  agn_modeling
26                          USI          e151
2025-04-19 19:58:18,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:18,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:18,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:18,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:58:18,410:INFO:setup() successfully completed in 5.28s...............
2025-04-19 19:58:18,410:INFO:Initializing compare_models()
2025-04-19 19:58:18,410:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 19:58:18,410:INFO:Checking exceptions
2025-04-19 19:58:18,412:INFO:Preparing display monitor
2025-04-19 19:58:18,417:INFO:Initializing Linear Regression
2025-04-19 19:58:18,417:INFO:Total runtime is 1.6955534617106118e-05 minutes
2025-04-19 19:58:18,417:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:18,417:INFO:Initializing create_model()
2025-04-19 19:58:18,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:18,417:INFO:Checking exceptions
2025-04-19 19:58:18,418:INFO:Importing libraries
2025-04-19 19:58:18,418:INFO:Copying training dataset
2025-04-19 19:58:18,424:INFO:Defining folds
2025-04-19 19:58:18,424:INFO:Declaring metric variables
2025-04-19 19:58:18,424:INFO:Importing untrained model
2025-04-19 19:58:18,424:INFO:Linear Regression Imported successfully
2025-04-19 19:58:18,426:INFO:Starting cross validation
2025-04-19 19:58:18,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:18,762:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,772:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,805:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,816:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,817:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,849:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,874:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:18,885:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:19,558:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:19,621:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 19:58:20,776:INFO:Calculating mean and std
2025-04-19 19:58:20,777:INFO:Creating metrics dataframe
2025-04-19 19:58:21,067:INFO:Uploading results into container
2025-04-19 19:58:21,068:INFO:Uploading model into container now
2025-04-19 19:58:21,068:INFO:_master_model_container: 1
2025-04-19 19:58:21,068:INFO:_display_container: 2
2025-04-19 19:58:21,069:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:58:21,069:INFO:create_model() successfully completed......................................
2025-04-19 19:58:21,340:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:21,340:INFO:Creating metrics dataframe
2025-04-19 19:58:21,347:INFO:Initializing Lasso Regression
2025-04-19 19:58:21,347:INFO:Total runtime is 0.04885043303171794 minutes
2025-04-19 19:58:21,348:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:21,348:INFO:Initializing create_model()
2025-04-19 19:58:21,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:21,348:INFO:Checking exceptions
2025-04-19 19:58:21,348:INFO:Importing libraries
2025-04-19 19:58:21,348:INFO:Copying training dataset
2025-04-19 19:58:21,351:INFO:Defining folds
2025-04-19 19:58:21,352:INFO:Declaring metric variables
2025-04-19 19:58:21,352:INFO:Importing untrained model
2025-04-19 19:58:21,352:INFO:Lasso Regression Imported successfully
2025-04-19 19:58:21,352:INFO:Starting cross validation
2025-04-19 19:58:21,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:23,303:INFO:Calculating mean and std
2025-04-19 19:58:23,304:INFO:Creating metrics dataframe
2025-04-19 19:58:23,593:INFO:Uploading results into container
2025-04-19 19:58:23,594:INFO:Uploading model into container now
2025-04-19 19:58:23,594:INFO:_master_model_container: 2
2025-04-19 19:58:23,594:INFO:_display_container: 2
2025-04-19 19:58:23,594:INFO:Lasso(random_state=42)
2025-04-19 19:58:23,594:INFO:create_model() successfully completed......................................
2025-04-19 19:58:23,784:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:23,784:INFO:Creating metrics dataframe
2025-04-19 19:58:23,797:INFO:Initializing Ridge Regression
2025-04-19 19:58:23,798:INFO:Total runtime is 0.08970298369725546 minutes
2025-04-19 19:58:23,798:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:23,799:INFO:Initializing create_model()
2025-04-19 19:58:23,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:23,799:INFO:Checking exceptions
2025-04-19 19:58:23,799:INFO:Importing libraries
2025-04-19 19:58:23,799:INFO:Copying training dataset
2025-04-19 19:58:23,810:INFO:Defining folds
2025-04-19 19:58:23,810:INFO:Declaring metric variables
2025-04-19 19:58:23,811:INFO:Importing untrained model
2025-04-19 19:58:23,812:INFO:Ridge Regression Imported successfully
2025-04-19 19:58:23,813:INFO:Starting cross validation
2025-04-19 19:58:23,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:25,602:INFO:Calculating mean and std
2025-04-19 19:58:25,603:INFO:Creating metrics dataframe
2025-04-19 19:58:25,871:INFO:Uploading results into container
2025-04-19 19:58:25,872:INFO:Uploading model into container now
2025-04-19 19:58:25,872:INFO:_master_model_container: 3
2025-04-19 19:58:25,873:INFO:_display_container: 2
2025-04-19 19:58:25,873:INFO:Ridge(random_state=42)
2025-04-19 19:58:25,873:INFO:create_model() successfully completed......................................
2025-04-19 19:58:26,052:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:26,052:INFO:Creating metrics dataframe
2025-04-19 19:58:26,064:INFO:Initializing Elastic Net
2025-04-19 19:58:26,064:INFO:Total runtime is 0.12748183806737265 minutes
2025-04-19 19:58:26,064:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:26,066:INFO:Initializing create_model()
2025-04-19 19:58:26,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:26,066:INFO:Checking exceptions
2025-04-19 19:58:26,066:INFO:Importing libraries
2025-04-19 19:58:26,067:INFO:Copying training dataset
2025-04-19 19:58:26,074:INFO:Defining folds
2025-04-19 19:58:26,074:INFO:Declaring metric variables
2025-04-19 19:58:26,075:INFO:Importing untrained model
2025-04-19 19:58:26,076:INFO:Elastic Net Imported successfully
2025-04-19 19:58:26,076:INFO:Starting cross validation
2025-04-19 19:58:26,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:28,013:INFO:Calculating mean and std
2025-04-19 19:58:28,014:INFO:Creating metrics dataframe
2025-04-19 19:58:28,278:INFO:Uploading results into container
2025-04-19 19:58:28,279:INFO:Uploading model into container now
2025-04-19 19:58:28,280:INFO:_master_model_container: 4
2025-04-19 19:58:28,280:INFO:_display_container: 2
2025-04-19 19:58:28,281:INFO:ElasticNet(random_state=42)
2025-04-19 19:58:28,281:INFO:create_model() successfully completed......................................
2025-04-19 19:58:28,432:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:28,433:INFO:Creating metrics dataframe
2025-04-19 19:58:28,439:INFO:Initializing Least Angle Regression
2025-04-19 19:58:28,440:INFO:Total runtime is 0.1670810659726461 minutes
2025-04-19 19:58:28,440:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:28,441:INFO:Initializing create_model()
2025-04-19 19:58:28,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:28,441:INFO:Checking exceptions
2025-04-19 19:58:28,441:INFO:Importing libraries
2025-04-19 19:58:28,441:INFO:Copying training dataset
2025-04-19 19:58:28,446:INFO:Defining folds
2025-04-19 19:58:28,446:INFO:Declaring metric variables
2025-04-19 19:58:28,446:INFO:Importing untrained model
2025-04-19 19:58:28,447:INFO:Least Angle Regression Imported successfully
2025-04-19 19:58:28,447:INFO:Starting cross validation
2025-04-19 19:58:28,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:30,226:INFO:Calculating mean and std
2025-04-19 19:58:30,227:INFO:Creating metrics dataframe
2025-04-19 19:58:30,516:INFO:Uploading results into container
2025-04-19 19:58:30,518:INFO:Uploading model into container now
2025-04-19 19:58:30,519:INFO:_master_model_container: 5
2025-04-19 19:58:30,519:INFO:_display_container: 2
2025-04-19 19:58:30,519:INFO:Lars(random_state=42)
2025-04-19 19:58:30,519:INFO:create_model() successfully completed......................................
2025-04-19 19:58:30,678:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:30,678:INFO:Creating metrics dataframe
2025-04-19 19:58:30,689:INFO:Initializing Lasso Least Angle Regression
2025-04-19 19:58:30,689:INFO:Total runtime is 0.20455476442972823 minutes
2025-04-19 19:58:30,690:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:30,690:INFO:Initializing create_model()
2025-04-19 19:58:30,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:30,690:INFO:Checking exceptions
2025-04-19 19:58:30,690:INFO:Importing libraries
2025-04-19 19:58:30,690:INFO:Copying training dataset
2025-04-19 19:58:30,696:INFO:Defining folds
2025-04-19 19:58:30,696:INFO:Declaring metric variables
2025-04-19 19:58:30,697:INFO:Importing untrained model
2025-04-19 19:58:30,698:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 19:58:30,699:INFO:Starting cross validation
2025-04-19 19:58:30,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:32,500:INFO:Calculating mean and std
2025-04-19 19:58:32,501:INFO:Creating metrics dataframe
2025-04-19 19:58:32,727:INFO:Uploading results into container
2025-04-19 19:58:32,728:INFO:Uploading model into container now
2025-04-19 19:58:32,729:INFO:_master_model_container: 6
2025-04-19 19:58:32,729:INFO:_display_container: 2
2025-04-19 19:58:32,730:INFO:LassoLars(random_state=42)
2025-04-19 19:58:32,731:INFO:create_model() successfully completed......................................
2025-04-19 19:58:32,899:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:32,899:INFO:Creating metrics dataframe
2025-04-19 19:58:32,906:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 19:58:32,907:INFO:Total runtime is 0.2415043393770854 minutes
2025-04-19 19:58:32,907:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:32,907:INFO:Initializing create_model()
2025-04-19 19:58:32,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:32,907:INFO:Checking exceptions
2025-04-19 19:58:32,908:INFO:Importing libraries
2025-04-19 19:58:32,908:INFO:Copying training dataset
2025-04-19 19:58:32,911:INFO:Defining folds
2025-04-19 19:58:32,911:INFO:Declaring metric variables
2025-04-19 19:58:32,912:INFO:Importing untrained model
2025-04-19 19:58:32,912:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:58:32,913:INFO:Starting cross validation
2025-04-19 19:58:32,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:34,692:INFO:Calculating mean and std
2025-04-19 19:58:34,693:INFO:Creating metrics dataframe
2025-04-19 19:58:34,980:INFO:Uploading results into container
2025-04-19 19:58:34,981:INFO:Uploading model into container now
2025-04-19 19:58:34,981:INFO:_master_model_container: 7
2025-04-19 19:58:34,982:INFO:_display_container: 2
2025-04-19 19:58:34,982:INFO:OrthogonalMatchingPursuit()
2025-04-19 19:58:34,982:INFO:create_model() successfully completed......................................
2025-04-19 19:58:35,131:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:35,131:INFO:Creating metrics dataframe
2025-04-19 19:58:35,139:INFO:Initializing Bayesian Ridge
2025-04-19 19:58:35,139:INFO:Total runtime is 0.27871711651484177 minutes
2025-04-19 19:58:35,139:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:35,140:INFO:Initializing create_model()
2025-04-19 19:58:35,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:35,140:INFO:Checking exceptions
2025-04-19 19:58:35,140:INFO:Importing libraries
2025-04-19 19:58:35,140:INFO:Copying training dataset
2025-04-19 19:58:35,144:INFO:Defining folds
2025-04-19 19:58:35,144:INFO:Declaring metric variables
2025-04-19 19:58:35,144:INFO:Importing untrained model
2025-04-19 19:58:35,147:INFO:Bayesian Ridge Imported successfully
2025-04-19 19:58:35,147:INFO:Starting cross validation
2025-04-19 19:58:35,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:36,948:INFO:Calculating mean and std
2025-04-19 19:58:36,949:INFO:Creating metrics dataframe
2025-04-19 19:58:37,236:INFO:Uploading results into container
2025-04-19 19:58:37,238:INFO:Uploading model into container now
2025-04-19 19:58:37,239:INFO:_master_model_container: 8
2025-04-19 19:58:37,239:INFO:_display_container: 2
2025-04-19 19:58:37,239:INFO:BayesianRidge()
2025-04-19 19:58:37,239:INFO:create_model() successfully completed......................................
2025-04-19 19:58:37,389:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:37,389:INFO:Creating metrics dataframe
2025-04-19 19:58:37,396:INFO:Initializing Passive Aggressive Regressor
2025-04-19 19:58:37,396:INFO:Total runtime is 0.3163488666216533 minutes
2025-04-19 19:58:37,396:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:37,398:INFO:Initializing create_model()
2025-04-19 19:58:37,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:37,398:INFO:Checking exceptions
2025-04-19 19:58:37,398:INFO:Importing libraries
2025-04-19 19:58:37,398:INFO:Copying training dataset
2025-04-19 19:58:37,401:INFO:Defining folds
2025-04-19 19:58:37,401:INFO:Declaring metric variables
2025-04-19 19:58:37,401:INFO:Importing untrained model
2025-04-19 19:58:37,401:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 19:58:37,401:INFO:Starting cross validation
2025-04-19 19:58:37,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:39,009:INFO:Calculating mean and std
2025-04-19 19:58:39,010:INFO:Creating metrics dataframe
2025-04-19 19:58:39,328:INFO:Uploading results into container
2025-04-19 19:58:39,329:INFO:Uploading model into container now
2025-04-19 19:58:39,329:INFO:_master_model_container: 9
2025-04-19 19:58:39,329:INFO:_display_container: 2
2025-04-19 19:58:39,329:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 19:58:39,329:INFO:create_model() successfully completed......................................
2025-04-19 19:58:39,503:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:39,504:INFO:Creating metrics dataframe
2025-04-19 19:58:39,520:INFO:Initializing Huber Regressor
2025-04-19 19:58:39,520:INFO:Total runtime is 0.35174815654754643 minutes
2025-04-19 19:58:39,521:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:39,521:INFO:Initializing create_model()
2025-04-19 19:58:39,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:39,522:INFO:Checking exceptions
2025-04-19 19:58:39,522:INFO:Importing libraries
2025-04-19 19:58:39,522:INFO:Copying training dataset
2025-04-19 19:58:39,531:INFO:Defining folds
2025-04-19 19:58:39,531:INFO:Declaring metric variables
2025-04-19 19:58:39,531:INFO:Importing untrained model
2025-04-19 19:58:39,532:INFO:Huber Regressor Imported successfully
2025-04-19 19:58:39,533:INFO:Starting cross validation
2025-04-19 19:58:39,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:41,265:INFO:Calculating mean and std
2025-04-19 19:58:41,268:INFO:Creating metrics dataframe
2025-04-19 19:58:41,573:INFO:Uploading results into container
2025-04-19 19:58:41,575:INFO:Uploading model into container now
2025-04-19 19:58:41,577:INFO:_master_model_container: 10
2025-04-19 19:58:41,577:INFO:_display_container: 2
2025-04-19 19:58:41,577:INFO:HuberRegressor()
2025-04-19 19:58:41,577:INFO:create_model() successfully completed......................................
2025-04-19 19:58:41,759:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:41,759:INFO:Creating metrics dataframe
2025-04-19 19:58:41,771:INFO:Initializing K Neighbors Regressor
2025-04-19 19:58:41,771:INFO:Total runtime is 0.38925676743189497 minutes
2025-04-19 19:58:41,771:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:41,772:INFO:Initializing create_model()
2025-04-19 19:58:41,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:41,772:INFO:Checking exceptions
2025-04-19 19:58:41,772:INFO:Importing libraries
2025-04-19 19:58:41,772:INFO:Copying training dataset
2025-04-19 19:58:41,777:INFO:Defining folds
2025-04-19 19:58:41,777:INFO:Declaring metric variables
2025-04-19 19:58:41,777:INFO:Importing untrained model
2025-04-19 19:58:41,778:INFO:K Neighbors Regressor Imported successfully
2025-04-19 19:58:41,778:INFO:Starting cross validation
2025-04-19 19:58:41,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:43,578:INFO:Calculating mean and std
2025-04-19 19:58:43,579:INFO:Creating metrics dataframe
2025-04-19 19:58:43,877:INFO:Uploading results into container
2025-04-19 19:58:43,878:INFO:Uploading model into container now
2025-04-19 19:58:43,879:INFO:_master_model_container: 11
2025-04-19 19:58:43,879:INFO:_display_container: 2
2025-04-19 19:58:43,879:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 19:58:43,879:INFO:create_model() successfully completed......................................
2025-04-19 19:58:44,038:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:44,038:INFO:Creating metrics dataframe
2025-04-19 19:58:44,052:INFO:Initializing Decision Tree Regressor
2025-04-19 19:58:44,052:INFO:Total runtime is 0.4272794365882874 minutes
2025-04-19 19:58:44,053:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:44,053:INFO:Initializing create_model()
2025-04-19 19:58:44,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:44,054:INFO:Checking exceptions
2025-04-19 19:58:44,054:INFO:Importing libraries
2025-04-19 19:58:44,054:INFO:Copying training dataset
2025-04-19 19:58:44,061:INFO:Defining folds
2025-04-19 19:58:44,061:INFO:Declaring metric variables
2025-04-19 19:58:44,062:INFO:Importing untrained model
2025-04-19 19:58:44,062:INFO:Decision Tree Regressor Imported successfully
2025-04-19 19:58:44,062:INFO:Starting cross validation
2025-04-19 19:58:44,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:45,878:INFO:Calculating mean and std
2025-04-19 19:58:45,878:INFO:Creating metrics dataframe
2025-04-19 19:58:46,129:INFO:Uploading results into container
2025-04-19 19:58:46,132:INFO:Uploading model into container now
2025-04-19 19:58:46,133:INFO:_master_model_container: 12
2025-04-19 19:58:46,133:INFO:_display_container: 2
2025-04-19 19:58:46,134:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 19:58:46,134:INFO:create_model() successfully completed......................................
2025-04-19 19:58:46,288:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:46,288:INFO:Creating metrics dataframe
2025-04-19 19:58:46,294:INFO:Initializing Random Forest Regressor
2025-04-19 19:58:46,294:INFO:Total runtime is 0.46463956832885744 minutes
2025-04-19 19:58:46,295:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:46,295:INFO:Initializing create_model()
2025-04-19 19:58:46,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:46,295:INFO:Checking exceptions
2025-04-19 19:58:46,295:INFO:Importing libraries
2025-04-19 19:58:46,295:INFO:Copying training dataset
2025-04-19 19:58:46,299:INFO:Defining folds
2025-04-19 19:58:46,300:INFO:Declaring metric variables
2025-04-19 19:58:46,300:INFO:Importing untrained model
2025-04-19 19:58:46,301:INFO:Random Forest Regressor Imported successfully
2025-04-19 19:58:46,301:INFO:Starting cross validation
2025-04-19 19:58:46,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:48,510:INFO:Calculating mean and std
2025-04-19 19:58:48,511:INFO:Creating metrics dataframe
2025-04-19 19:58:48,733:INFO:Uploading results into container
2025-04-19 19:58:48,734:INFO:Uploading model into container now
2025-04-19 19:58:48,734:INFO:_master_model_container: 13
2025-04-19 19:58:48,734:INFO:_display_container: 2
2025-04-19 19:58:48,736:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:58:48,736:INFO:create_model() successfully completed......................................
2025-04-19 19:58:48,896:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:48,896:INFO:Creating metrics dataframe
2025-04-19 19:58:48,903:INFO:Initializing Extra Trees Regressor
2025-04-19 19:58:48,903:INFO:Total runtime is 0.5081275780995687 minutes
2025-04-19 19:58:48,904:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:48,904:INFO:Initializing create_model()
2025-04-19 19:58:48,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:48,904:INFO:Checking exceptions
2025-04-19 19:58:48,904:INFO:Importing libraries
2025-04-19 19:58:48,904:INFO:Copying training dataset
2025-04-19 19:58:48,909:INFO:Defining folds
2025-04-19 19:58:48,909:INFO:Declaring metric variables
2025-04-19 19:58:48,909:INFO:Importing untrained model
2025-04-19 19:58:48,909:INFO:Extra Trees Regressor Imported successfully
2025-04-19 19:58:48,910:INFO:Starting cross validation
2025-04-19 19:58:48,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:51,252:INFO:Calculating mean and std
2025-04-19 19:58:51,253:INFO:Creating metrics dataframe
2025-04-19 19:58:51,572:INFO:Uploading results into container
2025-04-19 19:58:51,574:INFO:Uploading model into container now
2025-04-19 19:58:51,574:INFO:_master_model_container: 14
2025-04-19 19:58:51,576:INFO:_display_container: 2
2025-04-19 19:58:51,576:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:58:51,576:INFO:create_model() successfully completed......................................
2025-04-19 19:58:51,731:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:51,731:INFO:Creating metrics dataframe
2025-04-19 19:58:51,737:INFO:Initializing AdaBoost Regressor
2025-04-19 19:58:51,737:INFO:Total runtime is 0.5553517818450927 minutes
2025-04-19 19:58:51,738:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:51,738:INFO:Initializing create_model()
2025-04-19 19:58:51,738:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:51,738:INFO:Checking exceptions
2025-04-19 19:58:51,738:INFO:Importing libraries
2025-04-19 19:58:51,738:INFO:Copying training dataset
2025-04-19 19:58:51,742:INFO:Defining folds
2025-04-19 19:58:51,743:INFO:Declaring metric variables
2025-04-19 19:58:51,743:INFO:Importing untrained model
2025-04-19 19:58:51,744:INFO:AdaBoost Regressor Imported successfully
2025-04-19 19:58:51,744:INFO:Starting cross validation
2025-04-19 19:58:51,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:53,683:INFO:Calculating mean and std
2025-04-19 19:58:53,683:INFO:Creating metrics dataframe
2025-04-19 19:58:54,046:INFO:Uploading results into container
2025-04-19 19:58:54,048:INFO:Uploading model into container now
2025-04-19 19:58:54,049:INFO:_master_model_container: 15
2025-04-19 19:58:54,049:INFO:_display_container: 2
2025-04-19 19:58:54,049:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 19:58:54,049:INFO:create_model() successfully completed......................................
2025-04-19 19:58:54,175:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:54,175:INFO:Creating metrics dataframe
2025-04-19 19:58:54,188:INFO:Initializing Gradient Boosting Regressor
2025-04-19 19:58:54,188:INFO:Total runtime is 0.5962149302164713 minutes
2025-04-19 19:58:54,188:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:54,190:INFO:Initializing create_model()
2025-04-19 19:58:54,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:54,190:INFO:Checking exceptions
2025-04-19 19:58:54,190:INFO:Importing libraries
2025-04-19 19:58:54,190:INFO:Copying training dataset
2025-04-19 19:58:54,195:INFO:Defining folds
2025-04-19 19:58:54,195:INFO:Declaring metric variables
2025-04-19 19:58:54,196:INFO:Importing untrained model
2025-04-19 19:58:54,197:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 19:58:54,197:INFO:Starting cross validation
2025-04-19 19:58:54,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:56,038:INFO:Calculating mean and std
2025-04-19 19:58:56,039:INFO:Creating metrics dataframe
2025-04-19 19:58:56,338:INFO:Uploading results into container
2025-04-19 19:58:56,340:INFO:Uploading model into container now
2025-04-19 19:58:56,341:INFO:_master_model_container: 16
2025-04-19 19:58:56,342:INFO:_display_container: 2
2025-04-19 19:58:56,342:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 19:58:56,342:INFO:create_model() successfully completed......................................
2025-04-19 19:58:56,502:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:56,502:INFO:Creating metrics dataframe
2025-04-19 19:58:56,513:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:58:56,513:INFO:Total runtime is 0.6349568009376525 minutes
2025-04-19 19:58:56,513:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:56,514:INFO:Initializing create_model()
2025-04-19 19:58:56,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:56,514:INFO:Checking exceptions
2025-04-19 19:58:56,514:INFO:Importing libraries
2025-04-19 19:58:56,514:INFO:Copying training dataset
2025-04-19 19:58:56,518:INFO:Defining folds
2025-04-19 19:58:56,518:INFO:Declaring metric variables
2025-04-19 19:58:56,520:INFO:Importing untrained model
2025-04-19 19:58:56,520:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:58:56,520:INFO:Starting cross validation
2025-04-19 19:58:56,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:58:58,746:INFO:Calculating mean and std
2025-04-19 19:58:58,746:INFO:Creating metrics dataframe
2025-04-19 19:58:59,044:INFO:Uploading results into container
2025-04-19 19:58:59,045:INFO:Uploading model into container now
2025-04-19 19:58:59,045:INFO:_master_model_container: 17
2025-04-19 19:58:59,046:INFO:_display_container: 2
2025-04-19 19:58:59,047:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 19:58:59,047:INFO:create_model() successfully completed......................................
2025-04-19 19:58:59,235:INFO:SubProcess create_model() end ==================================
2025-04-19 19:58:59,235:INFO:Creating metrics dataframe
2025-04-19 19:58:59,243:INFO:Initializing Dummy Regressor
2025-04-19 19:58:59,243:INFO:Total runtime is 0.6804616610209147 minutes
2025-04-19 19:58:59,244:INFO:SubProcess create_model() called ==================================
2025-04-19 19:58:59,244:INFO:Initializing create_model()
2025-04-19 19:58:59,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E110340>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:58:59,244:INFO:Checking exceptions
2025-04-19 19:58:59,244:INFO:Importing libraries
2025-04-19 19:58:59,244:INFO:Copying training dataset
2025-04-19 19:58:59,251:INFO:Defining folds
2025-04-19 19:58:59,252:INFO:Declaring metric variables
2025-04-19 19:58:59,252:INFO:Importing untrained model
2025-04-19 19:58:59,252:INFO:Dummy Regressor Imported successfully
2025-04-19 19:58:59,253:INFO:Starting cross validation
2025-04-19 19:58:59,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:01,058:INFO:Calculating mean and std
2025-04-19 19:59:01,059:INFO:Creating metrics dataframe
2025-04-19 19:59:01,360:INFO:Uploading results into container
2025-04-19 19:59:01,362:INFO:Uploading model into container now
2025-04-19 19:59:01,363:INFO:_master_model_container: 18
2025-04-19 19:59:01,364:INFO:_display_container: 2
2025-04-19 19:59:01,364:INFO:DummyRegressor()
2025-04-19 19:59:01,364:INFO:create_model() successfully completed......................................
2025-04-19 19:59:01,504:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:01,504:INFO:Creating metrics dataframe
2025-04-19 19:59:01,515:INFO:Initializing create_model()
2025-04-19 19:59:01,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:01,515:INFO:Checking exceptions
2025-04-19 19:59:01,516:INFO:Importing libraries
2025-04-19 19:59:01,516:INFO:Copying training dataset
2025-04-19 19:59:01,520:INFO:Defining folds
2025-04-19 19:59:01,520:INFO:Declaring metric variables
2025-04-19 19:59:01,520:INFO:Importing untrained model
2025-04-19 19:59:01,521:INFO:Declaring custom model
2025-04-19 19:59:01,521:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:59:01,542:INFO:Cross validation set to False
2025-04-19 19:59:01,542:INFO:Fitting Model
2025-04-19 19:59:01,766:INFO:OrthogonalMatchingPursuit()
2025-04-19 19:59:01,766:INFO:create_model() successfully completed......................................
2025-04-19 19:59:01,888:INFO:Initializing create_model()
2025-04-19 19:59:01,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:01,888:INFO:Checking exceptions
2025-04-19 19:59:01,888:INFO:Importing libraries
2025-04-19 19:59:01,888:INFO:Copying training dataset
2025-04-19 19:59:01,890:INFO:Defining folds
2025-04-19 19:59:01,890:INFO:Declaring metric variables
2025-04-19 19:59:01,891:INFO:Importing untrained model
2025-04-19 19:59:01,891:INFO:Declaring custom model
2025-04-19 19:59:01,891:INFO:Ridge Regression Imported successfully
2025-04-19 19:59:01,902:INFO:Cross validation set to False
2025-04-19 19:59:01,902:INFO:Fitting Model
2025-04-19 19:59:02,121:INFO:Ridge(random_state=42)
2025-04-19 19:59:02,121:INFO:create_model() successfully completed......................................
2025-04-19 19:59:02,252:INFO:Initializing create_model()
2025-04-19 19:59:02,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:02,252:INFO:Checking exceptions
2025-04-19 19:59:02,253:INFO:Importing libraries
2025-04-19 19:59:02,253:INFO:Copying training dataset
2025-04-19 19:59:02,256:INFO:Defining folds
2025-04-19 19:59:02,256:INFO:Declaring metric variables
2025-04-19 19:59:02,256:INFO:Importing untrained model
2025-04-19 19:59:02,256:INFO:Declaring custom model
2025-04-19 19:59:02,256:INFO:Linear Regression Imported successfully
2025-04-19 19:59:02,264:INFO:Cross validation set to False
2025-04-19 19:59:02,264:INFO:Fitting Model
2025-04-19 19:59:02,506:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:59:02,506:INFO:create_model() successfully completed......................................
2025-04-19 19:59:02,649:INFO:_master_model_container: 18
2025-04-19 19:59:02,649:INFO:_display_container: 2
2025-04-19 19:59:02,650:INFO:[OrthogonalMatchingPursuit(), Ridge(random_state=42), LinearRegression(n_jobs=-1)]
2025-04-19 19:59:02,650:INFO:compare_models() successfully completed......................................
2025-04-19 19:59:02,651:INFO:Initializing tune_model()
2025-04-19 19:59:02,651:INFO:tune_model(estimator=OrthogonalMatchingPursuit(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>)
2025-04-19 19:59:02,651:INFO:Checking exceptions
2025-04-19 19:59:02,654:INFO:Copying training dataset
2025-04-19 19:59:02,658:INFO:Checking base model
2025-04-19 19:59:02,659:INFO:Base model : Orthogonal Matching Pursuit
2025-04-19 19:59:02,659:INFO:Declaring metric variables
2025-04-19 19:59:02,659:INFO:Defining Hyperparameters
2025-04-19 19:59:02,659:INFO:10 is bigger than total combinations 6, setting search algorithm to grid
2025-04-19 19:59:02,801:INFO:Tuning with n_jobs=-1
2025-04-19 19:59:02,801:INFO:Initializing GridSearchCV
2025-04-19 19:59:13,817:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__n_nonzero_coefs': 1}
2025-04-19 19:59:13,818:INFO:Hyperparameter search completed
2025-04-19 19:59:13,818:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:13,818:INFO:Initializing create_model()
2025-04-19 19:59:13,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0C43760>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'n_nonzero_coefs': 1})
2025-04-19 19:59:13,818:INFO:Checking exceptions
2025-04-19 19:59:13,818:INFO:Importing libraries
2025-04-19 19:59:13,818:INFO:Copying training dataset
2025-04-19 19:59:13,824:INFO:Defining folds
2025-04-19 19:59:13,826:INFO:Declaring metric variables
2025-04-19 19:59:13,826:INFO:Importing untrained model
2025-04-19 19:59:13,826:INFO:Declaring custom model
2025-04-19 19:59:13,826:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:59:13,826:INFO:Starting cross validation
2025-04-19 19:59:13,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:15,313:INFO:Calculating mean and std
2025-04-19 19:59:15,314:INFO:Creating metrics dataframe
2025-04-19 19:59:15,316:INFO:Finalizing model
2025-04-19 19:59:15,708:INFO:Uploading results into container
2025-04-19 19:59:15,710:INFO:Uploading model into container now
2025-04-19 19:59:15,711:INFO:_master_model_container: 19
2025-04-19 19:59:15,711:INFO:_display_container: 3
2025-04-19 19:59:15,711:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)
2025-04-19 19:59:15,711:INFO:create_model() successfully completed......................................
2025-04-19 19:59:15,850:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:15,850:INFO:choose_better activated
2025-04-19 19:59:15,851:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:15,851:INFO:Initializing create_model()
2025-04-19 19:59:15,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:15,851:INFO:Checking exceptions
2025-04-19 19:59:15,852:INFO:Importing libraries
2025-04-19 19:59:15,852:INFO:Copying training dataset
2025-04-19 19:59:15,854:INFO:Defining folds
2025-04-19 19:59:15,854:INFO:Declaring metric variables
2025-04-19 19:59:15,854:INFO:Importing untrained model
2025-04-19 19:59:15,854:INFO:Declaring custom model
2025-04-19 19:59:15,855:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 19:59:15,855:INFO:Starting cross validation
2025-04-19 19:59:15,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:17,442:INFO:Calculating mean and std
2025-04-19 19:59:17,443:INFO:Creating metrics dataframe
2025-04-19 19:59:17,445:INFO:Finalizing model
2025-04-19 19:59:17,855:INFO:Uploading results into container
2025-04-19 19:59:17,856:INFO:Uploading model into container now
2025-04-19 19:59:17,857:INFO:_master_model_container: 20
2025-04-19 19:59:17,857:INFO:_display_container: 4
2025-04-19 19:59:17,857:INFO:OrthogonalMatchingPursuit()
2025-04-19 19:59:17,857:INFO:create_model() successfully completed......................................
2025-04-19 19:59:17,978:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:17,979:INFO:OrthogonalMatchingPursuit() result for R2 is -0.5964
2025-04-19 19:59:17,979:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1) result for R2 is -0.5921
2025-04-19 19:59:17,980:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1) is best model
2025-04-19 19:59:17,980:INFO:choose_better completed
2025-04-19 19:59:17,996:INFO:_master_model_container: 20
2025-04-19 19:59:17,996:INFO:_display_container: 3
2025-04-19 19:59:17,996:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)
2025-04-19 19:59:17,996:INFO:tune_model() successfully completed......................................
2025-04-19 19:59:18,252:INFO:Initializing tune_model()
2025-04-19 19:59:18,252:INFO:tune_model(estimator=Ridge(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>)
2025-04-19 19:59:18,252:INFO:Checking exceptions
2025-04-19 19:59:18,254:INFO:Copying training dataset
2025-04-19 19:59:18,257:INFO:Checking base model
2025-04-19 19:59:18,257:INFO:Base model : Ridge Regression
2025-04-19 19:59:18,257:INFO:Declaring metric variables
2025-04-19 19:59:18,257:INFO:Defining Hyperparameters
2025-04-19 19:59:18,401:INFO:Tuning with n_jobs=-1
2025-04-19 19:59:18,401:INFO:Initializing RandomizedSearchCV
2025-04-19 19:59:37,815:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.3}
2025-04-19 19:59:37,815:INFO:Hyperparameter search completed
2025-04-19 19:59:37,815:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:37,817:INFO:Initializing create_model()
2025-04-19 19:59:37,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ADA0BBD9F0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'alpha': 7.3})
2025-04-19 19:59:37,817:INFO:Checking exceptions
2025-04-19 19:59:37,817:INFO:Importing libraries
2025-04-19 19:59:37,817:INFO:Copying training dataset
2025-04-19 19:59:37,822:INFO:Defining folds
2025-04-19 19:59:37,822:INFO:Declaring metric variables
2025-04-19 19:59:37,823:INFO:Importing untrained model
2025-04-19 19:59:37,823:INFO:Declaring custom model
2025-04-19 19:59:37,824:INFO:Ridge Regression Imported successfully
2025-04-19 19:59:37,824:INFO:Starting cross validation
2025-04-19 19:59:37,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:39,444:INFO:Calculating mean and std
2025-04-19 19:59:39,444:INFO:Creating metrics dataframe
2025-04-19 19:59:39,447:INFO:Finalizing model
2025-04-19 19:59:39,816:INFO:Uploading results into container
2025-04-19 19:59:39,817:INFO:Uploading model into container now
2025-04-19 19:59:39,817:INFO:_master_model_container: 21
2025-04-19 19:59:39,817:INFO:_display_container: 4
2025-04-19 19:59:39,818:INFO:Ridge(alpha=7.3, fit_intercept=False, random_state=42)
2025-04-19 19:59:39,818:INFO:create_model() successfully completed......................................
2025-04-19 19:59:39,938:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:39,940:INFO:choose_better activated
2025-04-19 19:59:39,940:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:39,941:INFO:Initializing create_model()
2025-04-19 19:59:39,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:39,941:INFO:Checking exceptions
2025-04-19 19:59:39,942:INFO:Importing libraries
2025-04-19 19:59:39,942:INFO:Copying training dataset
2025-04-19 19:59:39,944:INFO:Defining folds
2025-04-19 19:59:39,944:INFO:Declaring metric variables
2025-04-19 19:59:39,945:INFO:Importing untrained model
2025-04-19 19:59:39,945:INFO:Declaring custom model
2025-04-19 19:59:39,945:INFO:Ridge Regression Imported successfully
2025-04-19 19:59:39,945:INFO:Starting cross validation
2025-04-19 19:59:39,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:41,465:INFO:Calculating mean and std
2025-04-19 19:59:41,465:INFO:Creating metrics dataframe
2025-04-19 19:59:41,467:INFO:Finalizing model
2025-04-19 19:59:41,904:INFO:Uploading results into container
2025-04-19 19:59:41,906:INFO:Uploading model into container now
2025-04-19 19:59:41,907:INFO:_master_model_container: 22
2025-04-19 19:59:41,907:INFO:_display_container: 5
2025-04-19 19:59:41,907:INFO:Ridge(random_state=42)
2025-04-19 19:59:41,907:INFO:create_model() successfully completed......................................
2025-04-19 19:59:42,031:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:42,032:INFO:Ridge(random_state=42) result for R2 is -0.6814
2025-04-19 19:59:42,033:INFO:Ridge(alpha=7.3, fit_intercept=False, random_state=42) result for R2 is -0.6517
2025-04-19 19:59:42,033:INFO:Ridge(alpha=7.3, fit_intercept=False, random_state=42) is best model
2025-04-19 19:59:42,033:INFO:choose_better completed
2025-04-19 19:59:42,042:INFO:_master_model_container: 22
2025-04-19 19:59:42,042:INFO:_display_container: 4
2025-04-19 19:59:42,042:INFO:Ridge(alpha=7.3, fit_intercept=False, random_state=42)
2025-04-19 19:59:42,043:INFO:tune_model() successfully completed......................................
2025-04-19 19:59:42,310:INFO:Initializing tune_model()
2025-04-19 19:59:42,310:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>)
2025-04-19 19:59:42,310:INFO:Checking exceptions
2025-04-19 19:59:42,317:INFO:Copying training dataset
2025-04-19 19:59:42,322:INFO:Checking base model
2025-04-19 19:59:42,322:INFO:Base model : Linear Regression
2025-04-19 19:59:42,323:INFO:Declaring metric variables
2025-04-19 19:59:42,323:INFO:Defining Hyperparameters
2025-04-19 19:59:42,323:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 19:59:42,493:INFO:Tuning with n_jobs=-1
2025-04-19 19:59:42,493:INFO:Initializing GridSearchCV
2025-04-19 19:59:45,895:INFO:best_params: {'actual_estimator__fit_intercept': False}
2025-04-19 19:59:45,896:INFO:Hyperparameter search completed
2025-04-19 19:59:45,896:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:45,896:INFO:Initializing create_model()
2025-04-19 19:59:45,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9E057460>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False})
2025-04-19 19:59:45,897:INFO:Checking exceptions
2025-04-19 19:59:45,897:INFO:Importing libraries
2025-04-19 19:59:45,897:INFO:Copying training dataset
2025-04-19 19:59:45,901:INFO:Defining folds
2025-04-19 19:59:45,902:INFO:Declaring metric variables
2025-04-19 19:59:45,902:INFO:Importing untrained model
2025-04-19 19:59:45,903:INFO:Declaring custom model
2025-04-19 19:59:45,903:INFO:Linear Regression Imported successfully
2025-04-19 19:59:45,904:INFO:Starting cross validation
2025-04-19 19:59:45,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:47,414:INFO:Calculating mean and std
2025-04-19 19:59:47,416:INFO:Creating metrics dataframe
2025-04-19 19:59:47,418:INFO:Finalizing model
2025-04-19 19:59:47,794:INFO:Uploading results into container
2025-04-19 19:59:47,797:INFO:Uploading model into container now
2025-04-19 19:59:47,797:INFO:_master_model_container: 23
2025-04-19 19:59:47,798:INFO:_display_container: 5
2025-04-19 19:59:47,798:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2025-04-19 19:59:47,798:INFO:create_model() successfully completed......................................
2025-04-19 19:59:47,923:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:47,923:INFO:choose_better activated
2025-04-19 19:59:47,924:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:47,924:INFO:Initializing create_model()
2025-04-19 19:59:47,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:47,924:INFO:Checking exceptions
2025-04-19 19:59:47,925:INFO:Importing libraries
2025-04-19 19:59:47,925:INFO:Copying training dataset
2025-04-19 19:59:47,927:INFO:Defining folds
2025-04-19 19:59:47,928:INFO:Declaring metric variables
2025-04-19 19:59:47,928:INFO:Importing untrained model
2025-04-19 19:59:47,928:INFO:Declaring custom model
2025-04-19 19:59:47,928:INFO:Linear Regression Imported successfully
2025-04-19 19:59:47,928:INFO:Starting cross validation
2025-04-19 19:59:47,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:49,361:INFO:Calculating mean and std
2025-04-19 19:59:49,362:INFO:Creating metrics dataframe
2025-04-19 19:59:49,365:INFO:Finalizing model
2025-04-19 19:59:49,723:INFO:Uploading results into container
2025-04-19 19:59:49,724:INFO:Uploading model into container now
2025-04-19 19:59:49,724:INFO:_master_model_container: 24
2025-04-19 19:59:49,724:INFO:_display_container: 6
2025-04-19 19:59:49,725:INFO:LinearRegression(n_jobs=-1)
2025-04-19 19:59:49,725:INFO:create_model() successfully completed......................................
2025-04-19 19:59:49,846:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:49,848:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.6847
2025-04-19 19:59:49,849:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) result for R2 is -0.6716
2025-04-19 19:59:49,849:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) is best model
2025-04-19 19:59:49,849:INFO:choose_better completed
2025-04-19 19:59:49,866:INFO:_master_model_container: 24
2025-04-19 19:59:49,867:INFO:_display_container: 5
2025-04-19 19:59:49,867:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2025-04-19 19:59:49,867:INFO:tune_model() successfully completed......................................
2025-04-19 19:59:50,089:INFO:Initializing blend_models()
2025-04-19 19:59:50,089:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator_list=[OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), Ridge(alpha=7.3, fit_intercept=False, random_state=42), LinearRegression(fit_intercept=False, n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 19:59:50,089:INFO:Checking exceptions
2025-04-19 19:59:50,092:INFO:Importing libraries
2025-04-19 19:59:50,092:INFO:Copying training dataset
2025-04-19 19:59:50,092:INFO:Getting model names
2025-04-19 19:59:50,092:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:50,097:INFO:Initializing create_model()
2025-04-19 19:59:50,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9B2556F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:50,098:INFO:Checking exceptions
2025-04-19 19:59:50,098:INFO:Importing libraries
2025-04-19 19:59:50,098:INFO:Copying training dataset
2025-04-19 19:59:50,103:INFO:Defining folds
2025-04-19 19:59:50,103:INFO:Declaring metric variables
2025-04-19 19:59:50,104:INFO:Importing untrained model
2025-04-19 19:59:50,104:INFO:Declaring custom model
2025-04-19 19:59:50,106:INFO:Voting Regressor Imported successfully
2025-04-19 19:59:50,107:INFO:Starting cross validation
2025-04-19 19:59:50,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:51,756:INFO:Calculating mean and std
2025-04-19 19:59:51,757:INFO:Creating metrics dataframe
2025-04-19 19:59:51,758:INFO:Finalizing model
2025-04-19 19:59:52,119:INFO:Uploading results into container
2025-04-19 19:59:52,120:INFO:Uploading model into container now
2025-04-19 19:59:52,121:INFO:_master_model_container: 25
2025-04-19 19:59:52,121:INFO:_display_container: 6
2025-04-19 19:59:52,126:INFO:VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1)
2025-04-19 19:59:52,126:INFO:create_model() successfully completed......................................
2025-04-19 19:59:52,256:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:52,270:INFO:_master_model_container: 25
2025-04-19 19:59:52,272:INFO:_display_container: 6
2025-04-19 19:59:52,276:INFO:VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1)
2025-04-19 19:59:52,276:INFO:blend_models() successfully completed......................................
2025-04-19 19:59:52,398:INFO:Initializing stack_models()
2025-04-19 19:59:52,398:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator_list=[OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), Ridge(alpha=7.3, fit_intercept=False, random_state=42), LinearRegression(fit_intercept=False, n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 19:59:52,398:INFO:Checking exceptions
2025-04-19 19:59:52,399:INFO:Defining meta model
2025-04-19 19:59:52,401:INFO:Getting model names
2025-04-19 19:59:52,402:INFO:[('Orthogonal Matching Pursuit', OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)), ('Ridge Regression', Ridge(alpha=7.3, fit_intercept=False, random_state=42)), ('Linear Regression', LinearRegression(fit_intercept=False, n_jobs=-1))]
2025-04-19 19:59:52,402:INFO:SubProcess create_model() called ==================================
2025-04-19 19:59:52,405:INFO:Initializing create_model()
2025-04-19 19:59:52,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, estimator=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002AD9F353AF0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:59:52,405:INFO:Checking exceptions
2025-04-19 19:59:52,405:INFO:Importing libraries
2025-04-19 19:59:52,405:INFO:Copying training dataset
2025-04-19 19:59:52,408:INFO:Defining folds
2025-04-19 19:59:52,408:INFO:Declaring metric variables
2025-04-19 19:59:52,408:INFO:Importing untrained model
2025-04-19 19:59:52,408:INFO:Declaring custom model
2025-04-19 19:59:52,410:INFO:Stacking Regressor Imported successfully
2025-04-19 19:59:52,411:INFO:Starting cross validation
2025-04-19 19:59:52,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:59:54,167:INFO:Calculating mean and std
2025-04-19 19:59:54,168:INFO:Creating metrics dataframe
2025-04-19 19:59:54,170:INFO:Finalizing model
2025-04-19 19:59:54,576:INFO:Uploading results into container
2025-04-19 19:59:54,577:INFO:Uploading model into container now
2025-04-19 19:59:54,577:INFO:_master_model_container: 26
2025-04-19 19:59:54,577:INFO:_display_container: 7
2025-04-19 19:59:54,583:INFO:StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 19:59:54,583:INFO:create_model() successfully completed......................................
2025-04-19 19:59:54,725:INFO:SubProcess create_model() end ==================================
2025-04-19 19:59:54,736:INFO:_master_model_container: 26
2025-04-19 19:59:54,736:INFO:_display_container: 7
2025-04-19 19:59:54,742:INFO:StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 19:59:54,742:INFO:stack_models() successfully completed......................................
2025-04-19 19:59:54,884:INFO:Initializing save_model()
2025-04-19 19:59:54,884:INFO:save_model(model=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:59:54,884:INFO:Adding model into prep_pipe
2025-04-19 19:59:54,948:INFO:models/model_1.pkl saved in current working directory
2025-04-19 19:59:54,964:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                                              OrthogonalMatchingPursuit(fit_intercept=False,
                                                                        n_nonzero_coefs=1)),
                                             ('Ridge Regression',
                                              Ridge(alpha=7.3,
                                                    fit_intercept=False,
                                                    random_state=42)),
                                             ('Linear Regression',
                                              LinearRegression(fit_intercept=False,
                                                               n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 19:59:54,964:INFO:save_model() successfully completed......................................
2025-04-19 19:59:55,208:INFO:Initializing plot_model()
2025-04-19 19:59:55,208:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,208:INFO:Checking exceptions
2025-04-19 19:59:55,213:INFO:Initializing plot_model()
2025-04-19 19:59:55,213:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,213:INFO:Checking exceptions
2025-04-19 19:59:55,221:INFO:Initializing plot_model()
2025-04-19 19:59:55,221:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,221:INFO:Checking exceptions
2025-04-19 19:59:55,226:INFO:Initializing plot_model()
2025-04-19 19:59:55,226:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=1)),
                            ('Ridge Regression',
                             Ridge(alpha=7.3, fit_intercept=False,
                                   random_state=42)),
                            ('Linear Regression',
                             LinearRegression(fit_intercept=False, n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,226:INFO:Checking exceptions
2025-04-19 19:59:55,244:INFO:Initializing save_model()
2025-04-19 19:59:55,244:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:59:55,244:INFO:Adding model into prep_pipe
2025-04-19 19:59:55,327:INFO:models/model_2.pkl saved in current working directory
2025-04-19 19:59:55,344:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Orthogonal Matching Pursuit',
                                                OrthogonalMatchingPursuit(fit_intercept=False,
                                                                          n_nonzero_coefs=1)),
                                               ('Ridge Regression',
                                                Ridge(alpha=7.3,
                                                      fit_intercept=False,
                                                      random_state=42)),
                                               ('Linear Regression',
                                                LinearRegression(fit_intercept=False,
                                                                 n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 19:59:55,344:INFO:save_model() successfully completed......................................
2025-04-19 19:59:55,696:INFO:Initializing plot_model()
2025-04-19 19:59:55,697:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,697:INFO:Checking exceptions
2025-04-19 19:59:55,702:INFO:Initializing plot_model()
2025-04-19 19:59:55,703:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,703:INFO:Checking exceptions
2025-04-19 19:59:55,706:INFO:Initializing plot_model()
2025-04-19 19:59:55,706:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,706:INFO:Checking exceptions
2025-04-19 19:59:55,710:INFO:Initializing plot_model()
2025-04-19 19:59:55,710:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Orthogonal Matching Pursuit',
                               OrthogonalMatchingPursuit(fit_intercept=False,
                                                         n_nonzero_coefs=1)),
                              ('Ridge Regression',
                               Ridge(alpha=7.3, fit_intercept=False,
                                     random_state=42)),
                              ('Linear Regression',
                               LinearRegression(fit_intercept=False,
                                                n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:55,710:INFO:Checking exceptions
2025-04-19 19:59:55,722:INFO:Initializing save_model()
2025-04-19 19:59:55,722:INFO:save_model(model=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:59:55,722:INFO:Adding model into prep_pipe
2025-04-19 19:59:55,775:INFO:models/model_3.pkl saved in current working directory
2025-04-19 19:59:55,794:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))])
2025-04-19 19:59:55,794:INFO:save_model() successfully completed......................................
2025-04-19 19:59:56,038:INFO:Initializing plot_model()
2025-04-19 19:59:56,040:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,040:INFO:Checking exceptions
2025-04-19 19:59:56,040:INFO:Initializing plot_model()
2025-04-19 19:59:56,040:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,040:INFO:Checking exceptions
2025-04-19 19:59:56,040:INFO:Initializing plot_model()
2025-04-19 19:59:56,040:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,040:INFO:Checking exceptions
2025-04-19 19:59:56,041:INFO:Initializing plot_model()
2025-04-19 19:59:56,041:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,041:INFO:Checking exceptions
2025-04-19 19:59:56,053:INFO:Initializing save_model()
2025-04-19 19:59:56,053:INFO:save_model(model=Ridge(alpha=7.3, fit_intercept=False, random_state=42), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:59:56,053:INFO:Adding model into prep_pipe
2025-04-19 19:59:56,120:INFO:models/model_4.pkl saved in current working directory
2025-04-19 19:59:56,132:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 Ridge(alpha=7.3, fit_intercept=False, random_state=42))])
2025-04-19 19:59:56,132:INFO:save_model() successfully completed......................................
2025-04-19 19:59:56,390:INFO:Initializing plot_model()
2025-04-19 19:59:56,390:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=Ridge(alpha=7.3, fit_intercept=False, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,390:INFO:Checking exceptions
2025-04-19 19:59:56,390:INFO:Initializing plot_model()
2025-04-19 19:59:56,390:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=Ridge(alpha=7.3, fit_intercept=False, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,390:INFO:Checking exceptions
2025-04-19 19:59:56,391:INFO:Initializing plot_model()
2025-04-19 19:59:56,391:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=Ridge(alpha=7.3, fit_intercept=False, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,391:INFO:Checking exceptions
2025-04-19 19:59:56,391:INFO:Initializing plot_model()
2025-04-19 19:59:56,392:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=Ridge(alpha=7.3, fit_intercept=False, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,392:INFO:Checking exceptions
2025-04-19 19:59:56,412:INFO:Initializing save_model()
2025-04-19 19:59:56,412:INFO:save_model(model=LinearRegression(fit_intercept=False, n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 19:59:56,412:INFO:Adding model into prep_pipe
2025-04-19 19:59:56,477:INFO:models/model_5.pkl saved in current working directory
2025-04-19 19:59:56,495:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_1', 'feature_2',
                                             'feature_3'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 LinearRegression(fit_intercept=False, n_jobs=-1))])
2025-04-19 19:59:56,496:INFO:save_model() successfully completed......................................
2025-04-19 19:59:56,743:INFO:Initializing plot_model()
2025-04-19 19:59:56,743:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(fit_intercept=False, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,743:INFO:Checking exceptions
2025-04-19 19:59:56,743:INFO:Initializing plot_model()
2025-04-19 19:59:56,743:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(fit_intercept=False, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,743:INFO:Checking exceptions
2025-04-19 19:59:56,743:INFO:Initializing plot_model()
2025-04-19 19:59:56,743:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(fit_intercept=False, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,744:INFO:Checking exceptions
2025-04-19 19:59:56,744:INFO:Initializing plot_model()
2025-04-19 19:59:56,744:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(fit_intercept=False, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002AD9DF46E00>, system=True)
2025-04-19 19:59:56,744:INFO:Checking exceptions
2025-04-19 20:02:57,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:02:57,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:02:57,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:02:57,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:03:52,167:INFO:PyCaret RegressionExperiment
2025-04-19 20:03:52,167:INFO:Logging name: agn_modeling
2025-04-19 20:03:52,167:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:03:52,167:INFO:version 3.0.4
2025-04-19 20:03:52,167:INFO:Initializing setup()
2025-04-19 20:03:52,167:INFO:self.USI: 4697
2025-04-19 20:03:52,167:INFO:self._variable_keys: {'n_jobs_param', 'idx', 'fold_groups_param', 'exp_id', 'X_train', 'transform_target_param', 'logging_param', 'X_test', 'html_param', 'y_train', 'memory', 'USI', 'gpu_param', 'fold_generator', 'X', 'log_plots_param', '_available_plots', 'target_param', 'data', 'pipeline', '_ml_usecase', 'y_test', 'exp_name_log', 'seed', 'y', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2025-04-19 20:03:52,167:INFO:Checking environment
2025-04-19 20:03:52,167:INFO:python_version: 3.10.9
2025-04-19 20:03:52,167:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:03:52,167:INFO:machine: AMD64
2025-04-19 20:03:52,167:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:03:52,184:INFO:Memory: svmem(total=16952647680, available=4135411712, percent=75.6, used=12817235968, free=4135411712)
2025-04-19 20:03:52,184:INFO:Physical Core: 4
2025-04-19 20:03:52,184:INFO:Logical Core: 8
2025-04-19 20:03:52,184:INFO:Checking libraries
2025-04-19 20:03:52,184:INFO:System:
2025-04-19 20:03:52,184:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:03:52,185:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:03:52,185:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:03:52,185:INFO:PyCaret required dependencies:
2025-04-19 20:03:52,216:INFO:                 pip: 25.0.1
2025-04-19 20:03:52,217:INFO:          setuptools: 65.5.0
2025-04-19 20:03:52,217:INFO:             pycaret: 3.0.4
2025-04-19 20:03:52,217:INFO:             IPython: 8.35.0
2025-04-19 20:03:52,217:INFO:          ipywidgets: 8.1.6
2025-04-19 20:03:52,217:INFO:                tqdm: 4.67.1
2025-04-19 20:03:52,217:INFO:               numpy: 1.23.5
2025-04-19 20:03:52,217:INFO:              pandas: 1.5.3
2025-04-19 20:03:52,217:INFO:              jinja2: 3.1.6
2025-04-19 20:03:52,217:INFO:               scipy: 1.10.1
2025-04-19 20:03:52,217:INFO:              joblib: 1.2.0
2025-04-19 20:03:52,218:INFO:             sklearn: 1.2.2
2025-04-19 20:03:52,218:INFO:                pyod: 2.0.4
2025-04-19 20:03:52,218:INFO:            imblearn: 0.12.4
2025-04-19 20:03:52,218:INFO:   category_encoders: 2.7.0
2025-04-19 20:03:52,218:INFO:            lightgbm: 4.6.0
2025-04-19 20:03:52,218:INFO:               numba: 0.60.0
2025-04-19 20:03:52,218:INFO:            requests: 2.32.3
2025-04-19 20:03:52,218:INFO:          matplotlib: 3.7.1
2025-04-19 20:03:52,218:INFO:          scikitplot: 0.3.7
2025-04-19 20:03:52,218:INFO:         yellowbrick: 1.5
2025-04-19 20:03:52,218:INFO:              plotly: 5.24.1
2025-04-19 20:03:52,218:INFO:    plotly-resampler: Not installed
2025-04-19 20:03:52,218:INFO:             kaleido: 0.2.1
2025-04-19 20:03:52,218:INFO:           schemdraw: 0.15
2025-04-19 20:03:52,218:INFO:         statsmodels: 0.14.4
2025-04-19 20:03:52,218:INFO:              sktime: 0.21.1
2025-04-19 20:03:52,218:INFO:               tbats: 1.1.3
2025-04-19 20:03:52,218:INFO:            pmdarima: 2.0.4
2025-04-19 20:03:52,218:INFO:              psutil: 7.0.0
2025-04-19 20:03:52,218:INFO:          markupsafe: 3.0.2
2025-04-19 20:03:52,218:INFO:             pickle5: Not installed
2025-04-19 20:03:52,218:INFO:         cloudpickle: 3.1.1
2025-04-19 20:03:52,218:INFO:         deprecation: 2.1.0
2025-04-19 20:03:52,219:INFO:              xxhash: 3.5.0
2025-04-19 20:03:52,219:INFO:           wurlitzer: Not installed
2025-04-19 20:03:52,219:INFO:PyCaret optional dependencies:
2025-04-19 20:03:52,594:INFO:                shap: Not installed
2025-04-19 20:03:52,594:INFO:           interpret: Not installed
2025-04-19 20:03:52,594:INFO:                umap: Not installed
2025-04-19 20:03:52,594:INFO:    pandas_profiling: Not installed
2025-04-19 20:03:52,594:INFO:  explainerdashboard: Not installed
2025-04-19 20:03:52,594:INFO:             autoviz: Not installed
2025-04-19 20:03:52,594:INFO:           fairlearn: Not installed
2025-04-19 20:03:52,594:INFO:          deepchecks: Not installed
2025-04-19 20:03:52,594:INFO:             xgboost: Not installed
2025-04-19 20:03:52,594:INFO:            catboost: Not installed
2025-04-19 20:03:52,594:INFO:              kmodes: Not installed
2025-04-19 20:03:52,594:INFO:             mlxtend: Not installed
2025-04-19 20:03:52,595:INFO:       statsforecast: Not installed
2025-04-19 20:03:52,595:INFO:        tune_sklearn: Not installed
2025-04-19 20:03:52,595:INFO:                 ray: Not installed
2025-04-19 20:03:52,595:INFO:            hyperopt: Not installed
2025-04-19 20:03:52,595:INFO:              optuna: Not installed
2025-04-19 20:03:52,595:INFO:               skopt: Not installed
2025-04-19 20:03:52,595:INFO:              mlflow: 2.21.3
2025-04-19 20:03:52,595:INFO:              gradio: Not installed
2025-04-19 20:03:52,595:INFO:             fastapi: 0.115.12
2025-04-19 20:03:52,595:INFO:             uvicorn: 0.34.2
2025-04-19 20:03:52,595:INFO:              m2cgen: Not installed
2025-04-19 20:03:52,595:INFO:           evidently: Not installed
2025-04-19 20:03:52,595:INFO:               fugue: Not installed
2025-04-19 20:03:52,595:INFO:           streamlit: Not installed
2025-04-19 20:03:52,595:INFO:             prophet: Not installed
2025-04-19 20:03:52,595:INFO:None
2025-04-19 20:03:52,595:INFO:Set up data.
2025-04-19 20:03:52,603:INFO:Set up train/test split.
2025-04-19 20:03:52,607:INFO:Set up index.
2025-04-19 20:03:52,607:INFO:Set up folding strategy.
2025-04-19 20:03:52,608:INFO:Assigning column types.
2025-04-19 20:03:52,610:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:03:52,610:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,616:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,621:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,718:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,718:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,818:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:03:52,818:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,818:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:52,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:52,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,041:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:03:53,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,273:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:03:53,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,435:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,465:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:03:53,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:03:53,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,646:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:03:53,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:53,852:INFO:Preparing preprocessing pipeline...
2025-04-19 20:03:53,852:INFO:Set up target transformation.
2025-04-19 20:03:53,852:INFO:Set up simple imputation.
2025-04-19 20:03:53,852:INFO:Set up removing multicollinearity.
2025-04-19 20:03:53,852:INFO:Set up removing outliers.
2025-04-19 20:03:53,852:INFO:Set up feature normalization.
2025-04-19 20:03:54,038:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:03:54,365:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:03:54,375:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:03:54,375:INFO:Creating final display dataframe.
2025-04-19 20:03:54,589:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:03:55,166:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 7)
4        Transformed data shape     (7719, 7)
5   Transformed train set shape     (5319, 7)
6    Transformed test set shape     (2400, 7)
7              Numeric features             6
8      Rows with missing values         11.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          4697
2025-04-19 20:03:55,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:55,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:55,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:55,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:03:55,367:INFO:setup() successfully completed in 3.3s...............
2025-04-19 20:03:55,367:INFO:Initializing compare_models()
2025-04-19 20:03:55,367:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 20:03:55,367:INFO:Checking exceptions
2025-04-19 20:03:55,367:INFO:Preparing display monitor
2025-04-19 20:03:55,367:INFO:Initializing Linear Regression
2025-04-19 20:03:55,367:INFO:Total runtime is 0.0 minutes
2025-04-19 20:03:55,367:INFO:SubProcess create_model() called ==================================
2025-04-19 20:03:55,367:INFO:Initializing create_model()
2025-04-19 20:03:55,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:03:55,367:INFO:Checking exceptions
2025-04-19 20:03:55,367:INFO:Importing libraries
2025-04-19 20:03:55,367:INFO:Copying training dataset
2025-04-19 20:03:55,367:INFO:Defining folds
2025-04-19 20:03:55,367:INFO:Declaring metric variables
2025-04-19 20:03:55,367:INFO:Importing untrained model
2025-04-19 20:03:55,367:INFO:Linear Regression Imported successfully
2025-04-19 20:03:55,367:INFO:Starting cross validation
2025-04-19 20:03:55,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:00,214:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,220:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,236:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,343:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,359:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,363:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,474:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:00,488:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:01,427:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:01,471:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:04:02,029:INFO:Calculating mean and std
2025-04-19 20:04:02,029:INFO:Creating metrics dataframe
2025-04-19 20:04:02,179:INFO:Uploading results into container
2025-04-19 20:04:02,179:INFO:Uploading model into container now
2025-04-19 20:04:02,179:INFO:_master_model_container: 1
2025-04-19 20:04:02,179:INFO:_display_container: 2
2025-04-19 20:04:02,179:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:04:02,179:INFO:create_model() successfully completed......................................
2025-04-19 20:04:02,342:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:02,342:INFO:Creating metrics dataframe
2025-04-19 20:04:02,346:INFO:Initializing Lasso Regression
2025-04-19 20:04:02,346:INFO:Total runtime is 0.11632699569066365 minutes
2025-04-19 20:04:02,346:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:02,346:INFO:Initializing create_model()
2025-04-19 20:04:02,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:02,346:INFO:Checking exceptions
2025-04-19 20:04:02,346:INFO:Importing libraries
2025-04-19 20:04:02,346:INFO:Copying training dataset
2025-04-19 20:04:02,348:INFO:Defining folds
2025-04-19 20:04:02,348:INFO:Declaring metric variables
2025-04-19 20:04:02,348:INFO:Importing untrained model
2025-04-19 20:04:02,348:INFO:Lasso Regression Imported successfully
2025-04-19 20:04:02,348:INFO:Starting cross validation
2025-04-19 20:04:02,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:03,432:INFO:Calculating mean and std
2025-04-19 20:04:03,432:INFO:Creating metrics dataframe
2025-04-19 20:04:03,571:INFO:Uploading results into container
2025-04-19 20:04:03,571:INFO:Uploading model into container now
2025-04-19 20:04:03,572:INFO:_master_model_container: 2
2025-04-19 20:04:03,572:INFO:_display_container: 2
2025-04-19 20:04:03,572:INFO:Lasso(random_state=42)
2025-04-19 20:04:03,572:INFO:create_model() successfully completed......................................
2025-04-19 20:04:03,779:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:03,779:INFO:Creating metrics dataframe
2025-04-19 20:04:03,782:INFO:Initializing Ridge Regression
2025-04-19 20:04:03,784:INFO:Total runtime is 0.14028347730636598 minutes
2025-04-19 20:04:03,784:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:03,784:INFO:Initializing create_model()
2025-04-19 20:04:03,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:03,784:INFO:Checking exceptions
2025-04-19 20:04:03,784:INFO:Importing libraries
2025-04-19 20:04:03,784:INFO:Copying training dataset
2025-04-19 20:04:03,784:INFO:Defining folds
2025-04-19 20:04:03,784:INFO:Declaring metric variables
2025-04-19 20:04:03,784:INFO:Importing untrained model
2025-04-19 20:04:03,784:INFO:Ridge Regression Imported successfully
2025-04-19 20:04:03,784:INFO:Starting cross validation
2025-04-19 20:04:03,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:04,866:INFO:Calculating mean and std
2025-04-19 20:04:04,866:INFO:Creating metrics dataframe
2025-04-19 20:04:05,013:INFO:Uploading results into container
2025-04-19 20:04:05,013:INFO:Uploading model into container now
2025-04-19 20:04:05,013:INFO:_master_model_container: 3
2025-04-19 20:04:05,013:INFO:_display_container: 2
2025-04-19 20:04:05,013:INFO:Ridge(random_state=42)
2025-04-19 20:04:05,013:INFO:create_model() successfully completed......................................
2025-04-19 20:04:05,109:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:05,109:INFO:Creating metrics dataframe
2025-04-19 20:04:05,115:INFO:Initializing Elastic Net
2025-04-19 20:04:05,116:INFO:Total runtime is 0.1624899427096049 minutes
2025-04-19 20:04:05,116:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:05,116:INFO:Initializing create_model()
2025-04-19 20:04:05,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:05,117:INFO:Checking exceptions
2025-04-19 20:04:05,117:INFO:Importing libraries
2025-04-19 20:04:05,117:INFO:Copying training dataset
2025-04-19 20:04:05,120:INFO:Defining folds
2025-04-19 20:04:05,120:INFO:Declaring metric variables
2025-04-19 20:04:05,120:INFO:Importing untrained model
2025-04-19 20:04:05,120:INFO:Elastic Net Imported successfully
2025-04-19 20:04:05,120:INFO:Starting cross validation
2025-04-19 20:04:05,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:06,161:INFO:Calculating mean and std
2025-04-19 20:04:06,177:INFO:Creating metrics dataframe
2025-04-19 20:04:06,316:INFO:Uploading results into container
2025-04-19 20:04:06,316:INFO:Uploading model into container now
2025-04-19 20:04:06,316:INFO:_master_model_container: 4
2025-04-19 20:04:06,316:INFO:_display_container: 2
2025-04-19 20:04:06,316:INFO:ElasticNet(random_state=42)
2025-04-19 20:04:06,316:INFO:create_model() successfully completed......................................
2025-04-19 20:04:06,410:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:06,410:INFO:Creating metrics dataframe
2025-04-19 20:04:06,415:INFO:Initializing Least Angle Regression
2025-04-19 20:04:06,415:INFO:Total runtime is 0.18413679997126262 minutes
2025-04-19 20:04:06,415:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:06,415:INFO:Initializing create_model()
2025-04-19 20:04:06,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:06,415:INFO:Checking exceptions
2025-04-19 20:04:06,415:INFO:Importing libraries
2025-04-19 20:04:06,415:INFO:Copying training dataset
2025-04-19 20:04:06,417:INFO:Defining folds
2025-04-19 20:04:06,417:INFO:Declaring metric variables
2025-04-19 20:04:06,417:INFO:Importing untrained model
2025-04-19 20:04:06,417:INFO:Least Angle Regression Imported successfully
2025-04-19 20:04:06,417:INFO:Starting cross validation
2025-04-19 20:04:06,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:07,506:INFO:Calculating mean and std
2025-04-19 20:04:07,506:INFO:Creating metrics dataframe
2025-04-19 20:04:07,649:INFO:Uploading results into container
2025-04-19 20:04:07,649:INFO:Uploading model into container now
2025-04-19 20:04:07,649:INFO:_master_model_container: 5
2025-04-19 20:04:07,649:INFO:_display_container: 2
2025-04-19 20:04:07,649:INFO:Lars(random_state=42)
2025-04-19 20:04:07,649:INFO:create_model() successfully completed......................................
2025-04-19 20:04:07,751:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:07,751:INFO:Creating metrics dataframe
2025-04-19 20:04:07,751:INFO:Initializing Lasso Least Angle Regression
2025-04-19 20:04:07,751:INFO:Total runtime is 0.206407097975413 minutes
2025-04-19 20:04:07,751:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:07,751:INFO:Initializing create_model()
2025-04-19 20:04:07,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:07,751:INFO:Checking exceptions
2025-04-19 20:04:07,751:INFO:Importing libraries
2025-04-19 20:04:07,751:INFO:Copying training dataset
2025-04-19 20:04:07,751:INFO:Defining folds
2025-04-19 20:04:07,751:INFO:Declaring metric variables
2025-04-19 20:04:07,751:INFO:Importing untrained model
2025-04-19 20:04:07,751:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 20:04:07,751:INFO:Starting cross validation
2025-04-19 20:04:07,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:08,875:INFO:Calculating mean and std
2025-04-19 20:04:08,875:INFO:Creating metrics dataframe
2025-04-19 20:04:09,014:INFO:Uploading results into container
2025-04-19 20:04:09,014:INFO:Uploading model into container now
2025-04-19 20:04:09,014:INFO:_master_model_container: 6
2025-04-19 20:04:09,014:INFO:_display_container: 2
2025-04-19 20:04:09,014:INFO:LassoLars(random_state=42)
2025-04-19 20:04:09,014:INFO:create_model() successfully completed......................................
2025-04-19 20:04:09,103:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:09,103:INFO:Creating metrics dataframe
2025-04-19 20:04:09,103:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 20:04:09,103:INFO:Total runtime is 0.22893290917078654 minutes
2025-04-19 20:04:09,103:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:09,103:INFO:Initializing create_model()
2025-04-19 20:04:09,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:09,103:INFO:Checking exceptions
2025-04-19 20:04:09,103:INFO:Importing libraries
2025-04-19 20:04:09,103:INFO:Copying training dataset
2025-04-19 20:04:09,115:INFO:Defining folds
2025-04-19 20:04:09,115:INFO:Declaring metric variables
2025-04-19 20:04:09,115:INFO:Importing untrained model
2025-04-19 20:04:09,115:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 20:04:09,115:INFO:Starting cross validation
2025-04-19 20:04:09,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:10,204:INFO:Calculating mean and std
2025-04-19 20:04:10,204:INFO:Creating metrics dataframe
2025-04-19 20:04:10,348:INFO:Uploading results into container
2025-04-19 20:04:10,348:INFO:Uploading model into container now
2025-04-19 20:04:10,348:INFO:_master_model_container: 7
2025-04-19 20:04:10,348:INFO:_display_container: 2
2025-04-19 20:04:10,357:INFO:OrthogonalMatchingPursuit()
2025-04-19 20:04:10,357:INFO:create_model() successfully completed......................................
2025-04-19 20:04:10,452:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:10,452:INFO:Creating metrics dataframe
2025-04-19 20:04:10,456:INFO:Initializing Bayesian Ridge
2025-04-19 20:04:10,456:INFO:Total runtime is 0.2514942208925883 minutes
2025-04-19 20:04:10,456:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:10,457:INFO:Initializing create_model()
2025-04-19 20:04:10,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:10,457:INFO:Checking exceptions
2025-04-19 20:04:10,457:INFO:Importing libraries
2025-04-19 20:04:10,457:INFO:Copying training dataset
2025-04-19 20:04:10,460:INFO:Defining folds
2025-04-19 20:04:10,460:INFO:Declaring metric variables
2025-04-19 20:04:10,461:INFO:Importing untrained model
2025-04-19 20:04:10,461:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:04:10,461:INFO:Starting cross validation
2025-04-19 20:04:10,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:11,527:INFO:Calculating mean and std
2025-04-19 20:04:11,527:INFO:Creating metrics dataframe
2025-04-19 20:04:11,679:INFO:Uploading results into container
2025-04-19 20:04:11,679:INFO:Uploading model into container now
2025-04-19 20:04:11,681:INFO:_master_model_container: 8
2025-04-19 20:04:11,681:INFO:_display_container: 2
2025-04-19 20:04:11,682:INFO:BayesianRidge()
2025-04-19 20:04:11,682:INFO:create_model() successfully completed......................................
2025-04-19 20:04:11,765:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:11,765:INFO:Creating metrics dataframe
2025-04-19 20:04:11,765:INFO:Initializing Passive Aggressive Regressor
2025-04-19 20:04:11,765:INFO:Total runtime is 0.27331218719482425 minutes
2025-04-19 20:04:11,765:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:11,765:INFO:Initializing create_model()
2025-04-19 20:04:11,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:11,765:INFO:Checking exceptions
2025-04-19 20:04:11,765:INFO:Importing libraries
2025-04-19 20:04:11,765:INFO:Copying training dataset
2025-04-19 20:04:11,781:INFO:Defining folds
2025-04-19 20:04:11,781:INFO:Declaring metric variables
2025-04-19 20:04:11,781:INFO:Importing untrained model
2025-04-19 20:04:11,781:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 20:04:11,781:INFO:Starting cross validation
2025-04-19 20:04:11,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:12,875:INFO:Calculating mean and std
2025-04-19 20:04:12,875:INFO:Creating metrics dataframe
2025-04-19 20:04:13,012:INFO:Uploading results into container
2025-04-19 20:04:13,012:INFO:Uploading model into container now
2025-04-19 20:04:13,012:INFO:_master_model_container: 9
2025-04-19 20:04:13,012:INFO:_display_container: 2
2025-04-19 20:04:13,012:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 20:04:13,012:INFO:create_model() successfully completed......................................
2025-04-19 20:04:13,109:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:13,109:INFO:Creating metrics dataframe
2025-04-19 20:04:13,114:INFO:Initializing Huber Regressor
2025-04-19 20:04:13,114:INFO:Total runtime is 0.2957910418510437 minutes
2025-04-19 20:04:13,114:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:13,114:INFO:Initializing create_model()
2025-04-19 20:04:13,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:13,114:INFO:Checking exceptions
2025-04-19 20:04:13,114:INFO:Importing libraries
2025-04-19 20:04:13,114:INFO:Copying training dataset
2025-04-19 20:04:13,118:INFO:Defining folds
2025-04-19 20:04:13,118:INFO:Declaring metric variables
2025-04-19 20:04:13,121:INFO:Importing untrained model
2025-04-19 20:04:13,121:INFO:Huber Regressor Imported successfully
2025-04-19 20:04:13,121:INFO:Starting cross validation
2025-04-19 20:04:13,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:14,309:INFO:Calculating mean and std
2025-04-19 20:04:14,311:INFO:Creating metrics dataframe
2025-04-19 20:04:14,451:INFO:Uploading results into container
2025-04-19 20:04:14,451:INFO:Uploading model into container now
2025-04-19 20:04:14,451:INFO:_master_model_container: 10
2025-04-19 20:04:14,451:INFO:_display_container: 2
2025-04-19 20:04:14,451:INFO:HuberRegressor()
2025-04-19 20:04:14,451:INFO:create_model() successfully completed......................................
2025-04-19 20:04:14,545:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:14,545:INFO:Creating metrics dataframe
2025-04-19 20:04:14,548:INFO:Initializing K Neighbors Regressor
2025-04-19 20:04:14,549:INFO:Total runtime is 0.31970237890879316 minutes
2025-04-19 20:04:14,549:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:14,549:INFO:Initializing create_model()
2025-04-19 20:04:14,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:14,549:INFO:Checking exceptions
2025-04-19 20:04:14,549:INFO:Importing libraries
2025-04-19 20:04:14,549:INFO:Copying training dataset
2025-04-19 20:04:14,549:INFO:Defining folds
2025-04-19 20:04:14,549:INFO:Declaring metric variables
2025-04-19 20:04:14,549:INFO:Importing untrained model
2025-04-19 20:04:14,549:INFO:K Neighbors Regressor Imported successfully
2025-04-19 20:04:14,549:INFO:Starting cross validation
2025-04-19 20:04:14,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:15,653:INFO:Calculating mean and std
2025-04-19 20:04:15,655:INFO:Creating metrics dataframe
2025-04-19 20:04:15,823:INFO:Uploading results into container
2025-04-19 20:04:15,823:INFO:Uploading model into container now
2025-04-19 20:04:15,823:INFO:_master_model_container: 11
2025-04-19 20:04:15,825:INFO:_display_container: 2
2025-04-19 20:04:15,825:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 20:04:15,825:INFO:create_model() successfully completed......................................
2025-04-19 20:04:15,935:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:15,935:INFO:Creating metrics dataframe
2025-04-19 20:04:15,940:INFO:Initializing Decision Tree Regressor
2025-04-19 20:04:15,940:INFO:Total runtime is 0.34288920958836877 minutes
2025-04-19 20:04:15,940:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:15,940:INFO:Initializing create_model()
2025-04-19 20:04:15,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:15,941:INFO:Checking exceptions
2025-04-19 20:04:15,941:INFO:Importing libraries
2025-04-19 20:04:15,941:INFO:Copying training dataset
2025-04-19 20:04:15,944:INFO:Defining folds
2025-04-19 20:04:15,944:INFO:Declaring metric variables
2025-04-19 20:04:15,944:INFO:Importing untrained model
2025-04-19 20:04:15,945:INFO:Decision Tree Regressor Imported successfully
2025-04-19 20:04:15,945:INFO:Starting cross validation
2025-04-19 20:04:15,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:17,203:INFO:Calculating mean and std
2025-04-19 20:04:17,203:INFO:Creating metrics dataframe
2025-04-19 20:04:17,363:INFO:Uploading results into container
2025-04-19 20:04:17,363:INFO:Uploading model into container now
2025-04-19 20:04:17,363:INFO:_master_model_container: 12
2025-04-19 20:04:17,363:INFO:_display_container: 2
2025-04-19 20:04:17,363:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 20:04:17,363:INFO:create_model() successfully completed......................................
2025-04-19 20:04:17,463:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:17,464:INFO:Creating metrics dataframe
2025-04-19 20:04:17,468:INFO:Initializing Random Forest Regressor
2025-04-19 20:04:17,468:INFO:Total runtime is 0.3683547894159953 minutes
2025-04-19 20:04:17,468:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:17,469:INFO:Initializing create_model()
2025-04-19 20:04:17,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:17,469:INFO:Checking exceptions
2025-04-19 20:04:17,469:INFO:Importing libraries
2025-04-19 20:04:17,469:INFO:Copying training dataset
2025-04-19 20:04:17,469:INFO:Defining folds
2025-04-19 20:04:17,469:INFO:Declaring metric variables
2025-04-19 20:04:17,469:INFO:Importing untrained model
2025-04-19 20:04:17,469:INFO:Random Forest Regressor Imported successfully
2025-04-19 20:04:17,469:INFO:Starting cross validation
2025-04-19 20:04:17,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:22,334:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:04:22,858:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:04:23,647:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:04:23,832:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 20:04:26,430:INFO:Calculating mean and std
2025-04-19 20:04:26,431:INFO:Creating metrics dataframe
2025-04-19 20:04:26,617:INFO:Uploading results into container
2025-04-19 20:04:26,617:INFO:Uploading model into container now
2025-04-19 20:04:26,617:INFO:_master_model_container: 13
2025-04-19 20:04:26,617:INFO:_display_container: 2
2025-04-19 20:04:26,617:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:04:26,617:INFO:create_model() successfully completed......................................
2025-04-19 20:04:26,724:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:26,724:INFO:Creating metrics dataframe
2025-04-19 20:04:26,728:INFO:Initializing Extra Trees Regressor
2025-04-19 20:04:26,736:INFO:Total runtime is 0.5228294094403585 minutes
2025-04-19 20:04:26,737:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:26,737:INFO:Initializing create_model()
2025-04-19 20:04:26,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:26,737:INFO:Checking exceptions
2025-04-19 20:04:26,737:INFO:Importing libraries
2025-04-19 20:04:26,737:INFO:Copying training dataset
2025-04-19 20:04:26,737:INFO:Defining folds
2025-04-19 20:04:26,737:INFO:Declaring metric variables
2025-04-19 20:04:26,737:INFO:Importing untrained model
2025-04-19 20:04:26,737:INFO:Extra Trees Regressor Imported successfully
2025-04-19 20:04:26,737:INFO:Starting cross validation
2025-04-19 20:04:26,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:30,554:INFO:Calculating mean and std
2025-04-19 20:04:30,555:INFO:Creating metrics dataframe
2025-04-19 20:04:30,718:INFO:Uploading results into container
2025-04-19 20:04:30,719:INFO:Uploading model into container now
2025-04-19 20:04:30,719:INFO:_master_model_container: 14
2025-04-19 20:04:30,719:INFO:_display_container: 2
2025-04-19 20:04:30,720:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:04:30,720:INFO:create_model() successfully completed......................................
2025-04-19 20:04:30,827:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:30,828:INFO:Creating metrics dataframe
2025-04-19 20:04:30,832:INFO:Initializing AdaBoost Regressor
2025-04-19 20:04:30,832:INFO:Total runtime is 0.5910951018333435 minutes
2025-04-19 20:04:30,832:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:30,832:INFO:Initializing create_model()
2025-04-19 20:04:30,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:30,832:INFO:Checking exceptions
2025-04-19 20:04:30,832:INFO:Importing libraries
2025-04-19 20:04:30,832:INFO:Copying training dataset
2025-04-19 20:04:30,836:INFO:Defining folds
2025-04-19 20:04:30,836:INFO:Declaring metric variables
2025-04-19 20:04:30,836:INFO:Importing untrained model
2025-04-19 20:04:30,837:INFO:AdaBoost Regressor Imported successfully
2025-04-19 20:04:30,837:INFO:Starting cross validation
2025-04-19 20:04:30,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:32,274:INFO:Calculating mean and std
2025-04-19 20:04:32,274:INFO:Creating metrics dataframe
2025-04-19 20:04:32,436:INFO:Uploading results into container
2025-04-19 20:04:32,436:INFO:Uploading model into container now
2025-04-19 20:04:32,436:INFO:_master_model_container: 15
2025-04-19 20:04:32,436:INFO:_display_container: 2
2025-04-19 20:04:32,436:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 20:04:32,436:INFO:create_model() successfully completed......................................
2025-04-19 20:04:32,516:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:32,516:INFO:Creating metrics dataframe
2025-04-19 20:04:32,516:INFO:Initializing Gradient Boosting Regressor
2025-04-19 20:04:32,516:INFO:Total runtime is 0.6191580931345622 minutes
2025-04-19 20:04:32,516:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:32,516:INFO:Initializing create_model()
2025-04-19 20:04:32,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:32,516:INFO:Checking exceptions
2025-04-19 20:04:32,516:INFO:Importing libraries
2025-04-19 20:04:32,516:INFO:Copying training dataset
2025-04-19 20:04:32,532:INFO:Defining folds
2025-04-19 20:04:32,532:INFO:Declaring metric variables
2025-04-19 20:04:32,532:INFO:Importing untrained model
2025-04-19 20:04:32,536:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 20:04:32,536:INFO:Starting cross validation
2025-04-19 20:04:32,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:35,193:INFO:Calculating mean and std
2025-04-19 20:04:35,193:INFO:Creating metrics dataframe
2025-04-19 20:04:35,349:INFO:Uploading results into container
2025-04-19 20:04:35,349:INFO:Uploading model into container now
2025-04-19 20:04:35,349:INFO:_master_model_container: 16
2025-04-19 20:04:35,349:INFO:_display_container: 2
2025-04-19 20:04:35,349:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 20:04:35,349:INFO:create_model() successfully completed......................................
2025-04-19 20:04:35,465:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:35,465:INFO:Creating metrics dataframe
2025-04-19 20:04:35,467:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 20:04:35,467:INFO:Total runtime is 0.6683476249376933 minutes
2025-04-19 20:04:35,467:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:35,467:INFO:Initializing create_model()
2025-04-19 20:04:35,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:35,467:INFO:Checking exceptions
2025-04-19 20:04:35,467:INFO:Importing libraries
2025-04-19 20:04:35,467:INFO:Copying training dataset
2025-04-19 20:04:35,467:INFO:Defining folds
2025-04-19 20:04:35,467:INFO:Declaring metric variables
2025-04-19 20:04:35,467:INFO:Importing untrained model
2025-04-19 20:04:35,467:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:04:35,467:INFO:Starting cross validation
2025-04-19 20:04:35,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:37,474:INFO:Calculating mean and std
2025-04-19 20:04:37,474:INFO:Creating metrics dataframe
2025-04-19 20:04:37,640:INFO:Uploading results into container
2025-04-19 20:04:37,641:INFO:Uploading model into container now
2025-04-19 20:04:37,641:INFO:_master_model_container: 17
2025-04-19 20:04:37,641:INFO:_display_container: 2
2025-04-19 20:04:37,641:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:04:37,641:INFO:create_model() successfully completed......................................
2025-04-19 20:04:37,732:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:37,732:INFO:Creating metrics dataframe
2025-04-19 20:04:37,732:INFO:Initializing Dummy Regressor
2025-04-19 20:04:37,732:INFO:Total runtime is 0.706092623869578 minutes
2025-04-19 20:04:37,732:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:37,732:INFO:Initializing create_model()
2025-04-19 20:04:37,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80D263E50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:37,732:INFO:Checking exceptions
2025-04-19 20:04:37,732:INFO:Importing libraries
2025-04-19 20:04:37,732:INFO:Copying training dataset
2025-04-19 20:04:37,741:INFO:Defining folds
2025-04-19 20:04:37,741:INFO:Declaring metric variables
2025-04-19 20:04:37,741:INFO:Importing untrained model
2025-04-19 20:04:37,741:INFO:Dummy Regressor Imported successfully
2025-04-19 20:04:37,741:INFO:Starting cross validation
2025-04-19 20:04:37,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:38,907:INFO:Calculating mean and std
2025-04-19 20:04:38,909:INFO:Creating metrics dataframe
2025-04-19 20:04:39,059:INFO:Uploading results into container
2025-04-19 20:04:39,059:INFO:Uploading model into container now
2025-04-19 20:04:39,059:INFO:_master_model_container: 18
2025-04-19 20:04:39,059:INFO:_display_container: 2
2025-04-19 20:04:39,059:INFO:DummyRegressor()
2025-04-19 20:04:39,059:INFO:create_model() successfully completed......................................
2025-04-19 20:04:39,154:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:39,154:INFO:Creating metrics dataframe
2025-04-19 20:04:39,164:INFO:Initializing create_model()
2025-04-19 20:04:39,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:39,164:INFO:Checking exceptions
2025-04-19 20:04:39,164:INFO:Importing libraries
2025-04-19 20:04:39,164:INFO:Copying training dataset
2025-04-19 20:04:39,164:INFO:Defining folds
2025-04-19 20:04:39,164:INFO:Declaring metric variables
2025-04-19 20:04:39,164:INFO:Importing untrained model
2025-04-19 20:04:39,164:INFO:Declaring custom model
2025-04-19 20:04:39,164:INFO:Huber Regressor Imported successfully
2025-04-19 20:04:39,174:INFO:Cross validation set to False
2025-04-19 20:04:39,174:INFO:Fitting Model
2025-04-19 20:04:39,345:INFO:HuberRegressor()
2025-04-19 20:04:39,345:INFO:create_model() successfully completed......................................
2025-04-19 20:04:39,441:INFO:Initializing create_model()
2025-04-19 20:04:39,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:39,441:INFO:Checking exceptions
2025-04-19 20:04:39,441:INFO:Importing libraries
2025-04-19 20:04:39,441:INFO:Copying training dataset
2025-04-19 20:04:39,443:INFO:Defining folds
2025-04-19 20:04:39,443:INFO:Declaring metric variables
2025-04-19 20:04:39,443:INFO:Importing untrained model
2025-04-19 20:04:39,443:INFO:Declaring custom model
2025-04-19 20:04:39,443:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:04:39,443:INFO:Cross validation set to False
2025-04-19 20:04:39,443:INFO:Fitting Model
2025-04-19 20:04:39,593:INFO:BayesianRidge()
2025-04-19 20:04:39,593:INFO:create_model() successfully completed......................................
2025-04-19 20:04:39,673:INFO:Initializing create_model()
2025-04-19 20:04:39,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:39,673:INFO:Checking exceptions
2025-04-19 20:04:39,673:INFO:Importing libraries
2025-04-19 20:04:39,673:INFO:Copying training dataset
2025-04-19 20:04:39,689:INFO:Defining folds
2025-04-19 20:04:39,689:INFO:Declaring metric variables
2025-04-19 20:04:39,689:INFO:Importing untrained model
2025-04-19 20:04:39,689:INFO:Declaring custom model
2025-04-19 20:04:39,689:INFO:Linear Regression Imported successfully
2025-04-19 20:04:39,689:INFO:Cross validation set to False
2025-04-19 20:04:39,689:INFO:Fitting Model
2025-04-19 20:04:39,844:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:04:39,844:INFO:create_model() successfully completed......................................
2025-04-19 20:04:39,945:INFO:_master_model_container: 18
2025-04-19 20:04:39,945:INFO:_display_container: 2
2025-04-19 20:04:39,945:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 20:04:39,945:INFO:compare_models() successfully completed......................................
2025-04-19 20:04:39,945:INFO:Initializing tune_model()
2025-04-19 20:04:39,945:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>)
2025-04-19 20:04:39,945:INFO:Checking exceptions
2025-04-19 20:04:39,945:INFO:Copying training dataset
2025-04-19 20:04:39,945:INFO:Checking base model
2025-04-19 20:04:39,945:INFO:Base model : Huber Regressor
2025-04-19 20:04:39,945:INFO:Declaring metric variables
2025-04-19 20:04:39,945:INFO:Defining Hyperparameters
2025-04-19 20:04:40,066:INFO:Tuning with n_jobs=-1
2025-04-19 20:04:40,066:INFO:Initializing RandomizedSearchCV
2025-04-19 20:04:53,768:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.3, 'actual_estimator__alpha': 0.3}
2025-04-19 20:04:53,781:INFO:Hyperparameter search completed
2025-04-19 20:04:53,781:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:53,781:INFO:Initializing create_model()
2025-04-19 20:04:53,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C806FDD300>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.3, 'alpha': 0.3})
2025-04-19 20:04:53,781:INFO:Checking exceptions
2025-04-19 20:04:53,781:INFO:Importing libraries
2025-04-19 20:04:53,781:INFO:Copying training dataset
2025-04-19 20:04:53,785:INFO:Defining folds
2025-04-19 20:04:53,785:INFO:Declaring metric variables
2025-04-19 20:04:53,785:INFO:Importing untrained model
2025-04-19 20:04:53,785:INFO:Declaring custom model
2025-04-19 20:04:53,785:INFO:Huber Regressor Imported successfully
2025-04-19 20:04:53,785:INFO:Starting cross validation
2025-04-19 20:04:53,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:54,987:INFO:Calculating mean and std
2025-04-19 20:04:54,988:INFO:Creating metrics dataframe
2025-04-19 20:04:54,990:INFO:Finalizing model
2025-04-19 20:04:55,224:INFO:Uploading results into container
2025-04-19 20:04:55,225:INFO:Uploading model into container now
2025-04-19 20:04:55,225:INFO:_master_model_container: 19
2025-04-19 20:04:55,225:INFO:_display_container: 3
2025-04-19 20:04:55,225:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:04:55,225:INFO:create_model() successfully completed......................................
2025-04-19 20:04:55,332:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:55,332:INFO:choose_better activated
2025-04-19 20:04:55,333:INFO:SubProcess create_model() called ==================================
2025-04-19 20:04:55,333:INFO:Initializing create_model()
2025-04-19 20:04:55,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:04:55,333:INFO:Checking exceptions
2025-04-19 20:04:55,334:INFO:Importing libraries
2025-04-19 20:04:55,334:INFO:Copying training dataset
2025-04-19 20:04:55,338:INFO:Defining folds
2025-04-19 20:04:55,338:INFO:Declaring metric variables
2025-04-19 20:04:55,338:INFO:Importing untrained model
2025-04-19 20:04:55,338:INFO:Declaring custom model
2025-04-19 20:04:55,340:INFO:Huber Regressor Imported successfully
2025-04-19 20:04:55,340:INFO:Starting cross validation
2025-04-19 20:04:55,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:04:56,574:INFO:Calculating mean and std
2025-04-19 20:04:56,574:INFO:Creating metrics dataframe
2025-04-19 20:04:56,574:INFO:Finalizing model
2025-04-19 20:04:56,782:INFO:Uploading results into container
2025-04-19 20:04:56,782:INFO:Uploading model into container now
2025-04-19 20:04:56,782:INFO:_master_model_container: 20
2025-04-19 20:04:56,782:INFO:_display_container: 4
2025-04-19 20:04:56,782:INFO:HuberRegressor()
2025-04-19 20:04:56,782:INFO:create_model() successfully completed......................................
2025-04-19 20:04:56,868:INFO:SubProcess create_model() end ==================================
2025-04-19 20:04:56,868:INFO:HuberRegressor() result for R2 is 0.002
2025-04-19 20:04:56,869:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) result for R2 is 0.0019
2025-04-19 20:04:56,869:INFO:HuberRegressor() is best model
2025-04-19 20:04:56,869:INFO:choose_better completed
2025-04-19 20:04:56,869:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:04:56,876:INFO:_master_model_container: 20
2025-04-19 20:04:56,876:INFO:_display_container: 3
2025-04-19 20:04:56,876:INFO:HuberRegressor()
2025-04-19 20:04:56,876:INFO:tune_model() successfully completed......................................
2025-04-19 20:04:57,079:INFO:Initializing tune_model()
2025-04-19 20:04:57,079:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>)
2025-04-19 20:04:57,079:INFO:Checking exceptions
2025-04-19 20:04:57,079:INFO:Copying training dataset
2025-04-19 20:04:57,079:INFO:Checking base model
2025-04-19 20:04:57,079:INFO:Base model : Bayesian Ridge
2025-04-19 20:04:57,079:INFO:Declaring metric variables
2025-04-19 20:04:57,079:INFO:Defining Hyperparameters
2025-04-19 20:04:57,181:INFO:Tuning with n_jobs=-1
2025-04-19 20:04:57,181:INFO:Initializing RandomizedSearchCV
2025-04-19 20:05:10,343:INFO:best_params: {'actual_estimator__lambda_2': 0.005, 'actual_estimator__lambda_1': 1e-06, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': True, 'actual_estimator__alpha_2': 0.3, 'actual_estimator__alpha_1': 0.3}
2025-04-19 20:05:10,344:INFO:Hyperparameter search completed
2025-04-19 20:05:10,344:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:10,344:INFO:Initializing create_model()
2025-04-19 20:05:10,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C806FDC070>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.005, 'lambda_1': 1e-06, 'fit_intercept': True, 'compute_score': True, 'alpha_2': 0.3, 'alpha_1': 0.3})
2025-04-19 20:05:10,345:INFO:Checking exceptions
2025-04-19 20:05:10,345:INFO:Importing libraries
2025-04-19 20:05:10,345:INFO:Copying training dataset
2025-04-19 20:05:10,349:INFO:Defining folds
2025-04-19 20:05:10,349:INFO:Declaring metric variables
2025-04-19 20:05:10,349:INFO:Importing untrained model
2025-04-19 20:05:10,349:INFO:Declaring custom model
2025-04-19 20:05:10,350:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:05:10,350:INFO:Starting cross validation
2025-04-19 20:05:10,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:11,951:INFO:Calculating mean and std
2025-04-19 20:05:11,952:INFO:Creating metrics dataframe
2025-04-19 20:05:11,955:INFO:Finalizing model
2025-04-19 20:05:12,196:INFO:Uploading results into container
2025-04-19 20:05:12,197:INFO:Uploading model into container now
2025-04-19 20:05:12,198:INFO:_master_model_container: 21
2025-04-19 20:05:12,198:INFO:_display_container: 4
2025-04-19 20:05:12,198:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 20:05:12,198:INFO:create_model() successfully completed......................................
2025-04-19 20:05:12,311:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:12,311:INFO:choose_better activated
2025-04-19 20:05:12,311:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:12,312:INFO:Initializing create_model()
2025-04-19 20:05:12,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:05:12,312:INFO:Checking exceptions
2025-04-19 20:05:12,313:INFO:Importing libraries
2025-04-19 20:05:12,313:INFO:Copying training dataset
2025-04-19 20:05:12,317:INFO:Defining folds
2025-04-19 20:05:12,317:INFO:Declaring metric variables
2025-04-19 20:05:12,317:INFO:Importing untrained model
2025-04-19 20:05:12,317:INFO:Declaring custom model
2025-04-19 20:05:12,318:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:05:12,318:INFO:Starting cross validation
2025-04-19 20:05:12,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:13,550:INFO:Calculating mean and std
2025-04-19 20:05:13,551:INFO:Creating metrics dataframe
2025-04-19 20:05:13,552:INFO:Finalizing model
2025-04-19 20:05:13,779:INFO:Uploading results into container
2025-04-19 20:05:13,779:INFO:Uploading model into container now
2025-04-19 20:05:13,779:INFO:_master_model_container: 22
2025-04-19 20:05:13,779:INFO:_display_container: 5
2025-04-19 20:05:13,781:INFO:BayesianRidge()
2025-04-19 20:05:13,781:INFO:create_model() successfully completed......................................
2025-04-19 20:05:13,864:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:13,864:INFO:BayesianRidge() result for R2 is -0.0031
2025-04-19 20:05:13,864:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) result for R2 is -0.0031
2025-04-19 20:05:13,864:INFO:BayesianRidge() is best model
2025-04-19 20:05:13,864:INFO:choose_better completed
2025-04-19 20:05:13,864:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:05:13,886:INFO:_master_model_container: 22
2025-04-19 20:05:13,886:INFO:_display_container: 4
2025-04-19 20:05:13,886:INFO:BayesianRidge()
2025-04-19 20:05:13,886:INFO:tune_model() successfully completed......................................
2025-04-19 20:05:14,131:INFO:Initializing tune_model()
2025-04-19 20:05:14,132:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>)
2025-04-19 20:05:14,132:INFO:Checking exceptions
2025-04-19 20:05:14,132:INFO:Copying training dataset
2025-04-19 20:05:14,132:INFO:Checking base model
2025-04-19 20:05:14,132:INFO:Base model : Linear Regression
2025-04-19 20:05:14,132:INFO:Declaring metric variables
2025-04-19 20:05:14,132:INFO:Defining Hyperparameters
2025-04-19 20:05:14,132:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 20:05:14,249:INFO:Tuning with n_jobs=-1
2025-04-19 20:05:14,249:INFO:Initializing GridSearchCV
2025-04-19 20:05:17,082:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 20:05:17,082:INFO:Hyperparameter search completed
2025-04-19 20:05:17,082:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:17,082:INFO:Initializing create_model()
2025-04-19 20:05:17,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C80E6671F0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 20:05:17,082:INFO:Checking exceptions
2025-04-19 20:05:17,082:INFO:Importing libraries
2025-04-19 20:05:17,082:INFO:Copying training dataset
2025-04-19 20:05:17,087:INFO:Defining folds
2025-04-19 20:05:17,087:INFO:Declaring metric variables
2025-04-19 20:05:17,087:INFO:Importing untrained model
2025-04-19 20:05:17,087:INFO:Declaring custom model
2025-04-19 20:05:17,087:INFO:Linear Regression Imported successfully
2025-04-19 20:05:17,087:INFO:Starting cross validation
2025-04-19 20:05:17,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:18,285:INFO:Calculating mean and std
2025-04-19 20:05:18,286:INFO:Creating metrics dataframe
2025-04-19 20:05:18,290:INFO:Finalizing model
2025-04-19 20:05:18,503:INFO:Uploading results into container
2025-04-19 20:05:18,503:INFO:Uploading model into container now
2025-04-19 20:05:18,504:INFO:_master_model_container: 23
2025-04-19 20:05:18,504:INFO:_display_container: 5
2025-04-19 20:05:18,504:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:05:18,504:INFO:create_model() successfully completed......................................
2025-04-19 20:05:18,601:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:18,601:INFO:choose_better activated
2025-04-19 20:05:18,601:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:18,602:INFO:Initializing create_model()
2025-04-19 20:05:18,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:05:18,602:INFO:Checking exceptions
2025-04-19 20:05:18,603:INFO:Importing libraries
2025-04-19 20:05:18,603:INFO:Copying training dataset
2025-04-19 20:05:18,605:INFO:Defining folds
2025-04-19 20:05:18,606:INFO:Declaring metric variables
2025-04-19 20:05:18,606:INFO:Importing untrained model
2025-04-19 20:05:18,606:INFO:Declaring custom model
2025-04-19 20:05:18,606:INFO:Linear Regression Imported successfully
2025-04-19 20:05:18,606:INFO:Starting cross validation
2025-04-19 20:05:18,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:19,837:INFO:Calculating mean and std
2025-04-19 20:05:19,837:INFO:Creating metrics dataframe
2025-04-19 20:05:19,838:INFO:Finalizing model
2025-04-19 20:05:20,045:INFO:Uploading results into container
2025-04-19 20:05:20,046:INFO:Uploading model into container now
2025-04-19 20:05:20,046:INFO:_master_model_container: 24
2025-04-19 20:05:20,046:INFO:_display_container: 6
2025-04-19 20:05:20,047:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:05:20,047:INFO:create_model() successfully completed......................................
2025-04-19 20:05:20,131:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:20,131:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0032
2025-04-19 20:05:20,131:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0032
2025-04-19 20:05:20,131:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 20:05:20,131:INFO:choose_better completed
2025-04-19 20:05:20,131:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:05:20,131:INFO:_master_model_container: 24
2025-04-19 20:05:20,131:INFO:_display_container: 5
2025-04-19 20:05:20,141:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:05:20,141:INFO:tune_model() successfully completed......................................
2025-04-19 20:05:20,345:INFO:Initializing blend_models()
2025-04-19 20:05:20,345:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator_list=[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:05:20,345:INFO:Checking exceptions
2025-04-19 20:05:20,345:INFO:Importing libraries
2025-04-19 20:05:20,345:INFO:Copying training dataset
2025-04-19 20:05:20,345:INFO:Getting model names
2025-04-19 20:05:20,345:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:20,359:INFO:Initializing create_model()
2025-04-19 20:05:20,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C803A35BD0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:05:20,359:INFO:Checking exceptions
2025-04-19 20:05:20,359:INFO:Importing libraries
2025-04-19 20:05:20,359:INFO:Copying training dataset
2025-04-19 20:05:20,361:INFO:Defining folds
2025-04-19 20:05:20,361:INFO:Declaring metric variables
2025-04-19 20:05:20,361:INFO:Importing untrained model
2025-04-19 20:05:20,361:INFO:Declaring custom model
2025-04-19 20:05:20,363:INFO:Voting Regressor Imported successfully
2025-04-19 20:05:20,363:INFO:Starting cross validation
2025-04-19 20:05:20,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:21,739:INFO:Calculating mean and std
2025-04-19 20:05:21,739:INFO:Creating metrics dataframe
2025-04-19 20:05:21,739:INFO:Finalizing model
2025-04-19 20:05:22,012:INFO:Uploading results into container
2025-04-19 20:05:22,013:INFO:Uploading model into container now
2025-04-19 20:05:22,015:INFO:_master_model_container: 25
2025-04-19 20:05:22,015:INFO:_display_container: 6
2025-04-19 20:05:22,017:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:05:22,017:INFO:create_model() successfully completed......................................
2025-04-19 20:05:22,115:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:22,122:INFO:_master_model_container: 25
2025-04-19 20:05:22,122:INFO:_display_container: 6
2025-04-19 20:05:22,123:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:05:22,124:INFO:blend_models() successfully completed......................................
2025-04-19 20:05:22,279:INFO:Initializing stack_models()
2025-04-19 20:05:22,279:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator_list=[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:05:22,279:INFO:Checking exceptions
2025-04-19 20:05:22,279:INFO:Defining meta model
2025-04-19 20:05:22,279:INFO:Getting model names
2025-04-19 20:05:22,283:INFO:[('Huber Regressor', HuberRegressor()), ('Bayesian Ridge', BayesianRidge()), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 20:05:22,283:INFO:SubProcess create_model() called ==================================
2025-04-19 20:05:22,283:INFO:Initializing create_model()
2025-04-19 20:05:22,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C803975810>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:05:22,283:INFO:Checking exceptions
2025-04-19 20:05:22,283:INFO:Importing libraries
2025-04-19 20:05:22,283:INFO:Copying training dataset
2025-04-19 20:05:22,283:INFO:Defining folds
2025-04-19 20:05:22,283:INFO:Declaring metric variables
2025-04-19 20:05:22,283:INFO:Importing untrained model
2025-04-19 20:05:22,283:INFO:Declaring custom model
2025-04-19 20:05:22,283:INFO:Stacking Regressor Imported successfully
2025-04-19 20:05:22,283:INFO:Starting cross validation
2025-04-19 20:05:22,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:05:24,005:INFO:Calculating mean and std
2025-04-19 20:05:24,006:INFO:Creating metrics dataframe
2025-04-19 20:05:24,007:INFO:Finalizing model
2025-04-19 20:05:24,354:INFO:Uploading results into container
2025-04-19 20:05:24,355:INFO:Uploading model into container now
2025-04-19 20:05:24,355:INFO:_master_model_container: 26
2025-04-19 20:05:24,355:INFO:_display_container: 7
2025-04-19 20:05:24,356:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:05:24,356:INFO:create_model() successfully completed......................................
2025-04-19 20:05:24,465:INFO:SubProcess create_model() end ==================================
2025-04-19 20:05:24,472:INFO:_master_model_container: 26
2025-04-19 20:05:24,472:INFO:_display_container: 7
2025-04-19 20:05:24,474:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:05:24,474:INFO:stack_models() successfully completed......................................
2025-04-19 20:05:24,600:INFO:Initializing save_model()
2025-04-19 20:05:24,600:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:05:24,600:INFO:Adding model into prep_pipe
2025-04-19 20:05:24,638:INFO:models/model_1.pkl saved in current working directory
2025-04-19 20:05:24,654:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor()),
                                             ('Bayesian Ridge',
                                              BayesianRidge()),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 20:05:24,654:INFO:save_model() successfully completed......................................
2025-04-19 20:05:24,861:INFO:Initializing plot_model()
2025-04-19 20:05:24,861:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:24,861:INFO:Checking exceptions
2025-04-19 20:05:24,863:INFO:Initializing plot_model()
2025-04-19 20:05:24,864:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:24,864:INFO:Checking exceptions
2025-04-19 20:05:24,866:INFO:Initializing plot_model()
2025-04-19 20:05:24,866:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:24,866:INFO:Checking exceptions
2025-04-19 20:05:24,868:INFO:Initializing plot_model()
2025-04-19 20:05:24,868:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:24,868:INFO:Checking exceptions
2025-04-19 20:05:24,873:INFO:Initializing save_model()
2025-04-19 20:05:24,873:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:05:24,873:INFO:Adding model into prep_pipe
2025-04-19 20:05:24,921:INFO:models/model_2.pkl saved in current working directory
2025-04-19 20:05:24,937:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor()),
                                               ('Bayesian Ridge',
                                                BayesianRidge()),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 20:05:24,937:INFO:save_model() successfully completed......................................
2025-04-19 20:05:25,147:INFO:Initializing plot_model()
2025-04-19 20:05:25,147:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,147:INFO:Checking exceptions
2025-04-19 20:05:25,147:INFO:Initializing plot_model()
2025-04-19 20:05:25,147:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,147:INFO:Checking exceptions
2025-04-19 20:05:25,147:INFO:Initializing plot_model()
2025-04-19 20:05:25,147:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,147:INFO:Checking exceptions
2025-04-19 20:05:25,147:INFO:Initializing plot_model()
2025-04-19 20:05:25,147:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,147:INFO:Checking exceptions
2025-04-19 20:05:25,168:INFO:Initializing save_model()
2025-04-19 20:05:25,168:INFO:save_model(model=HuberRegressor(), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:05:25,168:INFO:Adding model into prep_pipe
2025-04-19 20:05:25,202:INFO:models/model_3.pkl saved in current working directory
2025-04-19 20:05:25,217:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor())])
2025-04-19 20:05:25,217:INFO:save_model() successfully completed......................................
2025-04-19 20:05:25,430:INFO:Initializing plot_model()
2025-04-19 20:05:25,430:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,430:INFO:Checking exceptions
2025-04-19 20:05:25,430:INFO:Initializing plot_model()
2025-04-19 20:05:25,430:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,430:INFO:Checking exceptions
2025-04-19 20:05:25,430:INFO:Initializing plot_model()
2025-04-19 20:05:25,430:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,430:INFO:Checking exceptions
2025-04-19 20:05:25,430:INFO:Initializing plot_model()
2025-04-19 20:05:25,430:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,430:INFO:Checking exceptions
2025-04-19 20:05:25,446:INFO:Initializing save_model()
2025-04-19 20:05:25,447:INFO:save_model(model=BayesianRidge(), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:05:25,447:INFO:Adding model into prep_pipe
2025-04-19 20:05:25,501:INFO:models/model_4.pkl saved in current working directory
2025-04-19 20:05:25,515:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', BayesianRidge())])
2025-04-19 20:05:25,515:INFO:save_model() successfully completed......................................
2025-04-19 20:05:25,872:INFO:Initializing plot_model()
2025-04-19 20:05:25,872:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,872:INFO:Checking exceptions
2025-04-19 20:05:25,873:INFO:Initializing plot_model()
2025-04-19 20:05:25,873:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,873:INFO:Checking exceptions
2025-04-19 20:05:25,873:INFO:Initializing plot_model()
2025-04-19 20:05:25,873:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,873:INFO:Checking exceptions
2025-04-19 20:05:25,873:INFO:Initializing plot_model()
2025-04-19 20:05:25,873:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:25,873:INFO:Checking exceptions
2025-04-19 20:05:25,882:INFO:Initializing save_model()
2025-04-19 20:05:25,882:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:05:25,882:INFO:Adding model into prep_pipe
2025-04-19 20:05:25,920:INFO:models/model_5.pkl saved in current working directory
2025-04-19 20:05:25,932:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_49',
                                             'feature_43', 'feature_19',
                                             'feature_92', 'feature_68'],
                                    tr...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 20:05:25,932:INFO:save_model() successfully completed......................................
2025-04-19 20:05:26,140:INFO:Initializing plot_model()
2025-04-19 20:05:26,141:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:26,141:INFO:Checking exceptions
2025-04-19 20:05:26,141:INFO:Initializing plot_model()
2025-04-19 20:05:26,141:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:26,141:INFO:Checking exceptions
2025-04-19 20:05:26,141:INFO:Initializing plot_model()
2025-04-19 20:05:26,141:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:26,141:INFO:Checking exceptions
2025-04-19 20:05:26,141:INFO:Initializing plot_model()
2025-04-19 20:05:26,141:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=png, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=2, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C80FAE08B0>, system=True)
2025-04-19 20:05:26,141:INFO:Checking exceptions
2025-04-19 20:08:19,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:08:19,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:08:19,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:08:19,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:09:06,461:INFO:PyCaret RegressionExperiment
2025-04-19 20:09:06,461:INFO:Logging name: agn_modeling
2025-04-19 20:09:06,461:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:09:06,461:INFO:version 3.0.4
2025-04-19 20:09:06,461:INFO:Initializing setup()
2025-04-19 20:09:06,461:INFO:self.USI: c0ef
2025-04-19 20:09:06,461:INFO:self._variable_keys: {'X_train', 'X_test', 'y_train', 'fold_generator', 'pipeline', 'idx', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'exp_name_log', 'data', 'USI', 'fold_groups_param', 'gpu_n_jobs_param', 'y', 'exp_id', 'y_test', 'X', 'log_plots_param', 'seed', '_available_plots', 'transform_target_param', 'fold_shuffle_param', 'html_param', 'target_param', 'logging_param', 'memory'}
2025-04-19 20:09:06,461:INFO:Checking environment
2025-04-19 20:09:06,461:INFO:python_version: 3.10.9
2025-04-19 20:09:06,461:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:09:06,461:INFO:machine: AMD64
2025-04-19 20:09:06,471:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:09:06,472:INFO:Memory: svmem(total=16952647680, available=4276047872, percent=74.8, used=12676599808, free=4276047872)
2025-04-19 20:09:06,472:INFO:Physical Core: 4
2025-04-19 20:09:06,472:INFO:Logical Core: 8
2025-04-19 20:09:06,472:INFO:Checking libraries
2025-04-19 20:09:06,472:INFO:System:
2025-04-19 20:09:06,472:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:09:06,472:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:09:06,472:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:09:06,472:INFO:PyCaret required dependencies:
2025-04-19 20:09:06,495:INFO:                 pip: 25.0.1
2025-04-19 20:09:06,495:INFO:          setuptools: 65.5.0
2025-04-19 20:09:06,495:INFO:             pycaret: 3.0.4
2025-04-19 20:09:06,495:INFO:             IPython: 8.35.0
2025-04-19 20:09:06,495:INFO:          ipywidgets: 8.1.6
2025-04-19 20:09:06,495:INFO:                tqdm: 4.67.1
2025-04-19 20:09:06,495:INFO:               numpy: 1.23.5
2025-04-19 20:09:06,495:INFO:              pandas: 1.5.3
2025-04-19 20:09:06,495:INFO:              jinja2: 3.1.6
2025-04-19 20:09:06,495:INFO:               scipy: 1.10.1
2025-04-19 20:09:06,495:INFO:              joblib: 1.2.0
2025-04-19 20:09:06,495:INFO:             sklearn: 1.2.2
2025-04-19 20:09:06,495:INFO:                pyod: 2.0.4
2025-04-19 20:09:06,495:INFO:            imblearn: 0.12.4
2025-04-19 20:09:06,495:INFO:   category_encoders: 2.7.0
2025-04-19 20:09:06,495:INFO:            lightgbm: 4.6.0
2025-04-19 20:09:06,495:INFO:               numba: 0.60.0
2025-04-19 20:09:06,495:INFO:            requests: 2.32.3
2025-04-19 20:09:06,495:INFO:          matplotlib: 3.7.1
2025-04-19 20:09:06,495:INFO:          scikitplot: 0.3.7
2025-04-19 20:09:06,495:INFO:         yellowbrick: 1.5
2025-04-19 20:09:06,495:INFO:              plotly: 5.24.1
2025-04-19 20:09:06,495:INFO:    plotly-resampler: Not installed
2025-04-19 20:09:06,495:INFO:             kaleido: 0.2.1
2025-04-19 20:09:06,495:INFO:           schemdraw: 0.15
2025-04-19 20:09:06,495:INFO:         statsmodels: 0.14.4
2025-04-19 20:09:06,495:INFO:              sktime: 0.21.1
2025-04-19 20:09:06,495:INFO:               tbats: 1.1.3
2025-04-19 20:09:06,495:INFO:            pmdarima: 2.0.4
2025-04-19 20:09:06,495:INFO:              psutil: 7.0.0
2025-04-19 20:09:06,495:INFO:          markupsafe: 3.0.2
2025-04-19 20:09:06,495:INFO:             pickle5: Not installed
2025-04-19 20:09:06,495:INFO:         cloudpickle: 3.1.1
2025-04-19 20:09:06,495:INFO:         deprecation: 2.1.0
2025-04-19 20:09:06,495:INFO:              xxhash: 3.5.0
2025-04-19 20:09:06,495:INFO:           wurlitzer: Not installed
2025-04-19 20:09:06,497:INFO:PyCaret optional dependencies:
2025-04-19 20:09:06,718:INFO:                shap: Not installed
2025-04-19 20:09:06,718:INFO:           interpret: Not installed
2025-04-19 20:09:06,718:INFO:                umap: Not installed
2025-04-19 20:09:06,718:INFO:    pandas_profiling: Not installed
2025-04-19 20:09:06,718:INFO:  explainerdashboard: Not installed
2025-04-19 20:09:06,718:INFO:             autoviz: Not installed
2025-04-19 20:09:06,718:INFO:           fairlearn: Not installed
2025-04-19 20:09:06,718:INFO:          deepchecks: Not installed
2025-04-19 20:09:06,718:INFO:             xgboost: Not installed
2025-04-19 20:09:06,718:INFO:            catboost: Not installed
2025-04-19 20:09:06,718:INFO:              kmodes: Not installed
2025-04-19 20:09:06,718:INFO:             mlxtend: Not installed
2025-04-19 20:09:06,718:INFO:       statsforecast: Not installed
2025-04-19 20:09:06,718:INFO:        tune_sklearn: Not installed
2025-04-19 20:09:06,718:INFO:                 ray: Not installed
2025-04-19 20:09:06,718:INFO:            hyperopt: Not installed
2025-04-19 20:09:06,718:INFO:              optuna: Not installed
2025-04-19 20:09:06,718:INFO:               skopt: Not installed
2025-04-19 20:09:06,718:INFO:              mlflow: 2.21.3
2025-04-19 20:09:06,718:INFO:              gradio: Not installed
2025-04-19 20:09:06,718:INFO:             fastapi: 0.115.12
2025-04-19 20:09:06,718:INFO:             uvicorn: 0.34.2
2025-04-19 20:09:06,718:INFO:              m2cgen: Not installed
2025-04-19 20:09:06,718:INFO:           evidently: Not installed
2025-04-19 20:09:06,718:INFO:               fugue: Not installed
2025-04-19 20:09:06,718:INFO:           streamlit: Not installed
2025-04-19 20:09:06,718:INFO:             prophet: Not installed
2025-04-19 20:09:06,718:INFO:None
2025-04-19 20:09:06,718:INFO:Set up data.
2025-04-19 20:09:06,722:INFO:Set up train/test split.
2025-04-19 20:09:06,726:INFO:Set up index.
2025-04-19 20:09:06,726:INFO:Set up folding strategy.
2025-04-19 20:09:06,726:INFO:Assigning column types.
2025-04-19 20:09:06,728:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:09:06,728:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,732:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:06,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:06,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,822:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:06,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:06,913:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:09:06,919:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:09:06,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,060:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,173:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:09:07,181:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,287:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,383:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:09:07,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,584:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:09:07,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:09:07,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,774:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:09:07,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:07,958:INFO:Preparing preprocessing pipeline...
2025-04-19 20:09:07,958:INFO:Set up target transformation.
2025-04-19 20:09:07,958:INFO:Set up simple imputation.
2025-04-19 20:09:07,958:INFO:Set up removing multicollinearity.
2025-04-19 20:09:07,958:INFO:Set up removing outliers.
2025-04-19 20:09:07,958:INFO:Set up feature normalization.
2025-04-19 20:09:08,117:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:08,444:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:09:08,450:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:09:08,450:INFO:Creating final display dataframe.
2025-04-19 20:09:08,608:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:09,038:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 6)
4        Transformed data shape     (7719, 6)
5   Transformed train set shape     (5319, 6)
6    Transformed test set shape     (2400, 6)
7              Numeric features             5
8      Rows with missing values          9.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          c0ef
2025-04-19 20:09:09,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:09,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:09,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:09,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:09:09,222:INFO:setup() successfully completed in 2.87s...............
2025-04-19 20:09:09,222:INFO:Initializing compare_models()
2025-04-19 20:09:09,222:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 20:09:09,222:INFO:Checking exceptions
2025-04-19 20:09:09,222:INFO:Preparing display monitor
2025-04-19 20:09:09,222:INFO:Initializing Linear Regression
2025-04-19 20:09:09,222:INFO:Total runtime is 0.0 minutes
2025-04-19 20:09:09,222:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:09,222:INFO:Initializing create_model()
2025-04-19 20:09:09,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:09,222:INFO:Checking exceptions
2025-04-19 20:09:09,222:INFO:Importing libraries
2025-04-19 20:09:09,222:INFO:Copying training dataset
2025-04-19 20:09:09,237:INFO:Defining folds
2025-04-19 20:09:09,237:INFO:Declaring metric variables
2025-04-19 20:09:09,237:INFO:Importing untrained model
2025-04-19 20:09:09,237:INFO:Linear Regression Imported successfully
2025-04-19 20:09:09,237:INFO:Starting cross validation
2025-04-19 20:09:09,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:13,715:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,744:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,756:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,758:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,818:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,838:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:13,846:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:14,022:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:14,894:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:14,914:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:09:15,634:INFO:Calculating mean and std
2025-04-19 20:09:15,634:INFO:Creating metrics dataframe
2025-04-19 20:09:15,785:INFO:Uploading results into container
2025-04-19 20:09:15,785:INFO:Uploading model into container now
2025-04-19 20:09:15,785:INFO:_master_model_container: 1
2025-04-19 20:09:15,785:INFO:_display_container: 2
2025-04-19 20:09:15,801:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:09:15,801:INFO:create_model() successfully completed......................................
2025-04-19 20:09:15,957:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:15,957:INFO:Creating metrics dataframe
2025-04-19 20:09:15,957:INFO:Initializing Lasso Regression
2025-04-19 20:09:15,957:INFO:Total runtime is 0.11224723259607951 minutes
2025-04-19 20:09:15,957:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:15,957:INFO:Initializing create_model()
2025-04-19 20:09:15,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:15,957:INFO:Checking exceptions
2025-04-19 20:09:15,957:INFO:Importing libraries
2025-04-19 20:09:15,957:INFO:Copying training dataset
2025-04-19 20:09:15,965:INFO:Defining folds
2025-04-19 20:09:15,965:INFO:Declaring metric variables
2025-04-19 20:09:15,965:INFO:Importing untrained model
2025-04-19 20:09:15,965:INFO:Lasso Regression Imported successfully
2025-04-19 20:09:15,965:INFO:Starting cross validation
2025-04-19 20:09:15,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:17,246:INFO:Calculating mean and std
2025-04-19 20:09:17,246:INFO:Creating metrics dataframe
2025-04-19 20:09:17,420:INFO:Uploading results into container
2025-04-19 20:09:17,420:INFO:Uploading model into container now
2025-04-19 20:09:17,420:INFO:_master_model_container: 2
2025-04-19 20:09:17,420:INFO:_display_container: 2
2025-04-19 20:09:17,420:INFO:Lasso(random_state=42)
2025-04-19 20:09:17,420:INFO:create_model() successfully completed......................................
2025-04-19 20:09:17,608:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:17,608:INFO:Creating metrics dataframe
2025-04-19 20:09:17,620:INFO:Initializing Ridge Regression
2025-04-19 20:09:17,620:INFO:Total runtime is 0.13996280034383138 minutes
2025-04-19 20:09:17,620:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:17,620:INFO:Initializing create_model()
2025-04-19 20:09:17,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:17,620:INFO:Checking exceptions
2025-04-19 20:09:17,620:INFO:Importing libraries
2025-04-19 20:09:17,620:INFO:Copying training dataset
2025-04-19 20:09:17,620:INFO:Defining folds
2025-04-19 20:09:17,620:INFO:Declaring metric variables
2025-04-19 20:09:17,620:INFO:Importing untrained model
2025-04-19 20:09:17,620:INFO:Ridge Regression Imported successfully
2025-04-19 20:09:17,620:INFO:Starting cross validation
2025-04-19 20:09:17,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:18,813:INFO:Calculating mean and std
2025-04-19 20:09:18,813:INFO:Creating metrics dataframe
2025-04-19 20:09:18,976:INFO:Uploading results into container
2025-04-19 20:09:18,976:INFO:Uploading model into container now
2025-04-19 20:09:18,976:INFO:_master_model_container: 3
2025-04-19 20:09:18,976:INFO:_display_container: 2
2025-04-19 20:09:18,976:INFO:Ridge(random_state=42)
2025-04-19 20:09:18,976:INFO:create_model() successfully completed......................................
2025-04-19 20:09:19,055:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:19,055:INFO:Creating metrics dataframe
2025-04-19 20:09:19,071:INFO:Initializing Elastic Net
2025-04-19 20:09:19,071:INFO:Total runtime is 0.1641473094622294 minutes
2025-04-19 20:09:19,071:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:19,071:INFO:Initializing create_model()
2025-04-19 20:09:19,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:19,071:INFO:Checking exceptions
2025-04-19 20:09:19,071:INFO:Importing libraries
2025-04-19 20:09:19,071:INFO:Copying training dataset
2025-04-19 20:09:19,071:INFO:Defining folds
2025-04-19 20:09:19,071:INFO:Declaring metric variables
2025-04-19 20:09:19,071:INFO:Importing untrained model
2025-04-19 20:09:19,071:INFO:Elastic Net Imported successfully
2025-04-19 20:09:19,071:INFO:Starting cross validation
2025-04-19 20:09:19,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:20,269:INFO:Calculating mean and std
2025-04-19 20:09:20,269:INFO:Creating metrics dataframe
2025-04-19 20:09:20,434:INFO:Uploading results into container
2025-04-19 20:09:20,434:INFO:Uploading model into container now
2025-04-19 20:09:20,434:INFO:_master_model_container: 4
2025-04-19 20:09:20,434:INFO:_display_container: 2
2025-04-19 20:09:20,434:INFO:ElasticNet(random_state=42)
2025-04-19 20:09:20,434:INFO:create_model() successfully completed......................................
2025-04-19 20:09:20,539:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:20,539:INFO:Creating metrics dataframe
2025-04-19 20:09:20,539:INFO:Initializing Least Angle Regression
2025-04-19 20:09:20,539:INFO:Total runtime is 0.18861246903737386 minutes
2025-04-19 20:09:20,539:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:20,539:INFO:Initializing create_model()
2025-04-19 20:09:20,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:20,539:INFO:Checking exceptions
2025-04-19 20:09:20,539:INFO:Importing libraries
2025-04-19 20:09:20,539:INFO:Copying training dataset
2025-04-19 20:09:20,539:INFO:Defining folds
2025-04-19 20:09:20,539:INFO:Declaring metric variables
2025-04-19 20:09:20,539:INFO:Importing untrained model
2025-04-19 20:09:20,539:INFO:Least Angle Regression Imported successfully
2025-04-19 20:09:20,539:INFO:Starting cross validation
2025-04-19 20:09:20,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:21,751:INFO:Calculating mean and std
2025-04-19 20:09:21,751:INFO:Creating metrics dataframe
2025-04-19 20:09:21,917:INFO:Uploading results into container
2025-04-19 20:09:21,917:INFO:Uploading model into container now
2025-04-19 20:09:21,917:INFO:_master_model_container: 5
2025-04-19 20:09:21,917:INFO:_display_container: 2
2025-04-19 20:09:21,917:INFO:Lars(random_state=42)
2025-04-19 20:09:21,917:INFO:create_model() successfully completed......................................
2025-04-19 20:09:22,005:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:22,005:INFO:Creating metrics dataframe
2025-04-19 20:09:22,017:INFO:Initializing Lasso Least Angle Regression
2025-04-19 20:09:22,017:INFO:Total runtime is 0.21325114170710247 minutes
2025-04-19 20:09:22,017:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:22,017:INFO:Initializing create_model()
2025-04-19 20:09:22,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:22,017:INFO:Checking exceptions
2025-04-19 20:09:22,017:INFO:Importing libraries
2025-04-19 20:09:22,017:INFO:Copying training dataset
2025-04-19 20:09:22,020:INFO:Defining folds
2025-04-19 20:09:22,020:INFO:Declaring metric variables
2025-04-19 20:09:22,021:INFO:Importing untrained model
2025-04-19 20:09:22,021:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 20:09:22,021:INFO:Starting cross validation
2025-04-19 20:09:22,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:23,301:INFO:Calculating mean and std
2025-04-19 20:09:23,301:INFO:Creating metrics dataframe
2025-04-19 20:09:23,454:INFO:Uploading results into container
2025-04-19 20:09:23,454:INFO:Uploading model into container now
2025-04-19 20:09:23,454:INFO:_master_model_container: 6
2025-04-19 20:09:23,454:INFO:_display_container: 2
2025-04-19 20:09:23,454:INFO:LassoLars(random_state=42)
2025-04-19 20:09:23,454:INFO:create_model() successfully completed......................................
2025-04-19 20:09:23,555:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:23,555:INFO:Creating metrics dataframe
2025-04-19 20:09:23,559:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 20:09:23,559:INFO:Total runtime is 0.23895650704701743 minutes
2025-04-19 20:09:23,559:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:23,559:INFO:Initializing create_model()
2025-04-19 20:09:23,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:23,559:INFO:Checking exceptions
2025-04-19 20:09:23,559:INFO:Importing libraries
2025-04-19 20:09:23,559:INFO:Copying training dataset
2025-04-19 20:09:23,559:INFO:Defining folds
2025-04-19 20:09:23,559:INFO:Declaring metric variables
2025-04-19 20:09:23,559:INFO:Importing untrained model
2025-04-19 20:09:23,559:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 20:09:23,559:INFO:Starting cross validation
2025-04-19 20:09:23,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:24,806:INFO:Calculating mean and std
2025-04-19 20:09:24,806:INFO:Creating metrics dataframe
2025-04-19 20:09:24,951:INFO:Uploading results into container
2025-04-19 20:09:24,951:INFO:Uploading model into container now
2025-04-19 20:09:24,951:INFO:_master_model_container: 7
2025-04-19 20:09:24,951:INFO:_display_container: 2
2025-04-19 20:09:24,951:INFO:OrthogonalMatchingPursuit()
2025-04-19 20:09:24,951:INFO:create_model() successfully completed......................................
2025-04-19 20:09:25,056:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:25,056:INFO:Creating metrics dataframe
2025-04-19 20:09:25,056:INFO:Initializing Bayesian Ridge
2025-04-19 20:09:25,056:INFO:Total runtime is 0.26389920711517334 minutes
2025-04-19 20:09:25,056:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:25,056:INFO:Initializing create_model()
2025-04-19 20:09:25,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:25,056:INFO:Checking exceptions
2025-04-19 20:09:25,056:INFO:Importing libraries
2025-04-19 20:09:25,056:INFO:Copying training dataset
2025-04-19 20:09:25,056:INFO:Defining folds
2025-04-19 20:09:25,056:INFO:Declaring metric variables
2025-04-19 20:09:25,056:INFO:Importing untrained model
2025-04-19 20:09:25,056:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:09:25,056:INFO:Starting cross validation
2025-04-19 20:09:25,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:26,261:INFO:Calculating mean and std
2025-04-19 20:09:26,261:INFO:Creating metrics dataframe
2025-04-19 20:09:26,422:INFO:Uploading results into container
2025-04-19 20:09:26,422:INFO:Uploading model into container now
2025-04-19 20:09:26,422:INFO:_master_model_container: 8
2025-04-19 20:09:26,422:INFO:_display_container: 2
2025-04-19 20:09:26,422:INFO:BayesianRidge()
2025-04-19 20:09:26,422:INFO:create_model() successfully completed......................................
2025-04-19 20:09:26,504:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:26,504:INFO:Creating metrics dataframe
2025-04-19 20:09:26,522:INFO:Initializing Passive Aggressive Regressor
2025-04-19 20:09:26,522:INFO:Total runtime is 0.2883356293042501 minutes
2025-04-19 20:09:26,522:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:26,522:INFO:Initializing create_model()
2025-04-19 20:09:26,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:26,522:INFO:Checking exceptions
2025-04-19 20:09:26,522:INFO:Importing libraries
2025-04-19 20:09:26,522:INFO:Copying training dataset
2025-04-19 20:09:26,522:INFO:Defining folds
2025-04-19 20:09:26,522:INFO:Declaring metric variables
2025-04-19 20:09:26,522:INFO:Importing untrained model
2025-04-19 20:09:26,522:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 20:09:26,522:INFO:Starting cross validation
2025-04-19 20:09:26,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:27,701:INFO:Calculating mean and std
2025-04-19 20:09:27,701:INFO:Creating metrics dataframe
2025-04-19 20:09:27,863:INFO:Uploading results into container
2025-04-19 20:09:27,868:INFO:Uploading model into container now
2025-04-19 20:09:27,868:INFO:_master_model_container: 9
2025-04-19 20:09:27,868:INFO:_display_container: 2
2025-04-19 20:09:27,868:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 20:09:27,868:INFO:create_model() successfully completed......................................
2025-04-19 20:09:27,956:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:27,956:INFO:Creating metrics dataframe
2025-04-19 20:09:27,956:INFO:Initializing Huber Regressor
2025-04-19 20:09:27,956:INFO:Total runtime is 0.3122352560361227 minutes
2025-04-19 20:09:27,956:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:27,956:INFO:Initializing create_model()
2025-04-19 20:09:27,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:27,956:INFO:Checking exceptions
2025-04-19 20:09:27,956:INFO:Importing libraries
2025-04-19 20:09:27,956:INFO:Copying training dataset
2025-04-19 20:09:27,956:INFO:Defining folds
2025-04-19 20:09:27,956:INFO:Declaring metric variables
2025-04-19 20:09:27,956:INFO:Importing untrained model
2025-04-19 20:09:27,956:INFO:Huber Regressor Imported successfully
2025-04-19 20:09:27,956:INFO:Starting cross validation
2025-04-19 20:09:27,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:29,163:INFO:Calculating mean and std
2025-04-19 20:09:29,163:INFO:Creating metrics dataframe
2025-04-19 20:09:29,333:INFO:Uploading results into container
2025-04-19 20:09:29,333:INFO:Uploading model into container now
2025-04-19 20:09:29,333:INFO:_master_model_container: 10
2025-04-19 20:09:29,333:INFO:_display_container: 2
2025-04-19 20:09:29,333:INFO:HuberRegressor()
2025-04-19 20:09:29,333:INFO:create_model() successfully completed......................................
2025-04-19 20:09:29,425:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:29,425:INFO:Creating metrics dataframe
2025-04-19 20:09:29,425:INFO:Initializing K Neighbors Regressor
2025-04-19 20:09:29,425:INFO:Total runtime is 0.33671800692876186 minutes
2025-04-19 20:09:29,425:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:29,425:INFO:Initializing create_model()
2025-04-19 20:09:29,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:29,425:INFO:Checking exceptions
2025-04-19 20:09:29,425:INFO:Importing libraries
2025-04-19 20:09:29,425:INFO:Copying training dataset
2025-04-19 20:09:29,425:INFO:Defining folds
2025-04-19 20:09:29,425:INFO:Declaring metric variables
2025-04-19 20:09:29,425:INFO:Importing untrained model
2025-04-19 20:09:29,425:INFO:K Neighbors Regressor Imported successfully
2025-04-19 20:09:29,425:INFO:Starting cross validation
2025-04-19 20:09:29,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:30,741:INFO:Calculating mean and std
2025-04-19 20:09:30,741:INFO:Creating metrics dataframe
2025-04-19 20:09:30,924:INFO:Uploading results into container
2025-04-19 20:09:30,924:INFO:Uploading model into container now
2025-04-19 20:09:30,924:INFO:_master_model_container: 11
2025-04-19 20:09:30,924:INFO:_display_container: 2
2025-04-19 20:09:30,927:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 20:09:30,927:INFO:create_model() successfully completed......................................
2025-04-19 20:09:31,039:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:31,039:INFO:Creating metrics dataframe
2025-04-19 20:09:31,039:INFO:Initializing Decision Tree Regressor
2025-04-19 20:09:31,039:INFO:Total runtime is 0.3636156876881918 minutes
2025-04-19 20:09:31,039:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:31,039:INFO:Initializing create_model()
2025-04-19 20:09:31,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:31,039:INFO:Checking exceptions
2025-04-19 20:09:31,039:INFO:Importing libraries
2025-04-19 20:09:31,039:INFO:Copying training dataset
2025-04-19 20:09:31,039:INFO:Defining folds
2025-04-19 20:09:31,039:INFO:Declaring metric variables
2025-04-19 20:09:31,039:INFO:Importing untrained model
2025-04-19 20:09:31,039:INFO:Decision Tree Regressor Imported successfully
2025-04-19 20:09:31,039:INFO:Starting cross validation
2025-04-19 20:09:31,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:32,417:INFO:Calculating mean and std
2025-04-19 20:09:32,417:INFO:Creating metrics dataframe
2025-04-19 20:09:32,567:INFO:Uploading results into container
2025-04-19 20:09:32,567:INFO:Uploading model into container now
2025-04-19 20:09:32,567:INFO:_master_model_container: 12
2025-04-19 20:09:32,583:INFO:_display_container: 2
2025-04-19 20:09:32,583:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 20:09:32,583:INFO:create_model() successfully completed......................................
2025-04-19 20:09:32,671:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:32,671:INFO:Creating metrics dataframe
2025-04-19 20:09:32,671:INFO:Initializing Random Forest Regressor
2025-04-19 20:09:32,671:INFO:Total runtime is 0.39081786870956425 minutes
2025-04-19 20:09:32,671:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:32,671:INFO:Initializing create_model()
2025-04-19 20:09:32,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:32,671:INFO:Checking exceptions
2025-04-19 20:09:32,671:INFO:Importing libraries
2025-04-19 20:09:32,671:INFO:Copying training dataset
2025-04-19 20:09:32,671:INFO:Defining folds
2025-04-19 20:09:32,671:INFO:Declaring metric variables
2025-04-19 20:09:32,671:INFO:Importing untrained model
2025-04-19 20:09:32,671:INFO:Random Forest Regressor Imported successfully
2025-04-19 20:09:32,671:INFO:Starting cross validation
2025-04-19 20:09:32,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:36,910:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:36,966:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:37,064:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:38,300:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 20:09:40,856:INFO:Calculating mean and std
2025-04-19 20:09:40,857:INFO:Creating metrics dataframe
2025-04-19 20:09:41,036:INFO:Uploading results into container
2025-04-19 20:09:41,036:INFO:Uploading model into container now
2025-04-19 20:09:41,036:INFO:_master_model_container: 13
2025-04-19 20:09:41,036:INFO:_display_container: 2
2025-04-19 20:09:41,036:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:09:41,036:INFO:create_model() successfully completed......................................
2025-04-19 20:09:41,155:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:41,155:INFO:Creating metrics dataframe
2025-04-19 20:09:41,165:INFO:Initializing Extra Trees Regressor
2025-04-19 20:09:41,165:INFO:Total runtime is 0.5323838432629904 minutes
2025-04-19 20:09:41,165:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:41,165:INFO:Initializing create_model()
2025-04-19 20:09:41,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:41,165:INFO:Checking exceptions
2025-04-19 20:09:41,165:INFO:Importing libraries
2025-04-19 20:09:41,165:INFO:Copying training dataset
2025-04-19 20:09:41,171:INFO:Defining folds
2025-04-19 20:09:41,171:INFO:Declaring metric variables
2025-04-19 20:09:41,171:INFO:Importing untrained model
2025-04-19 20:09:41,171:INFO:Extra Trees Regressor Imported successfully
2025-04-19 20:09:41,171:INFO:Starting cross validation
2025-04-19 20:09:41,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:42,819:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:43,096:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:43,126:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:09:44,996:INFO:Calculating mean and std
2025-04-19 20:09:44,997:INFO:Creating metrics dataframe
2025-04-19 20:09:45,156:INFO:Uploading results into container
2025-04-19 20:09:45,156:INFO:Uploading model into container now
2025-04-19 20:09:45,156:INFO:_master_model_container: 14
2025-04-19 20:09:45,156:INFO:_display_container: 2
2025-04-19 20:09:45,156:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:09:45,156:INFO:create_model() successfully completed......................................
2025-04-19 20:09:45,269:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:45,269:INFO:Creating metrics dataframe
2025-04-19 20:09:45,273:INFO:Initializing AdaBoost Regressor
2025-04-19 20:09:45,273:INFO:Total runtime is 0.6008487820625306 minutes
2025-04-19 20:09:45,273:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:45,273:INFO:Initializing create_model()
2025-04-19 20:09:45,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:45,274:INFO:Checking exceptions
2025-04-19 20:09:45,274:INFO:Importing libraries
2025-04-19 20:09:45,274:INFO:Copying training dataset
2025-04-19 20:09:45,277:INFO:Defining folds
2025-04-19 20:09:45,278:INFO:Declaring metric variables
2025-04-19 20:09:45,278:INFO:Importing untrained model
2025-04-19 20:09:45,278:INFO:AdaBoost Regressor Imported successfully
2025-04-19 20:09:45,278:INFO:Starting cross validation
2025-04-19 20:09:45,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:46,754:INFO:Calculating mean and std
2025-04-19 20:09:46,756:INFO:Creating metrics dataframe
2025-04-19 20:09:46,964:INFO:Uploading results into container
2025-04-19 20:09:46,964:INFO:Uploading model into container now
2025-04-19 20:09:46,965:INFO:_master_model_container: 15
2025-04-19 20:09:46,965:INFO:_display_container: 2
2025-04-19 20:09:46,965:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 20:09:46,965:INFO:create_model() successfully completed......................................
2025-04-19 20:09:47,070:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:47,070:INFO:Creating metrics dataframe
2025-04-19 20:09:47,075:INFO:Initializing Gradient Boosting Regressor
2025-04-19 20:09:47,075:INFO:Total runtime is 0.6308820645014446 minutes
2025-04-19 20:09:47,075:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:47,075:INFO:Initializing create_model()
2025-04-19 20:09:47,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:47,075:INFO:Checking exceptions
2025-04-19 20:09:47,076:INFO:Importing libraries
2025-04-19 20:09:47,076:INFO:Copying training dataset
2025-04-19 20:09:47,079:INFO:Defining folds
2025-04-19 20:09:47,079:INFO:Declaring metric variables
2025-04-19 20:09:47,079:INFO:Importing untrained model
2025-04-19 20:09:47,080:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 20:09:47,080:INFO:Starting cross validation
2025-04-19 20:09:47,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:49,807:INFO:Calculating mean and std
2025-04-19 20:09:49,808:INFO:Creating metrics dataframe
2025-04-19 20:09:50,010:INFO:Uploading results into container
2025-04-19 20:09:50,010:INFO:Uploading model into container now
2025-04-19 20:09:50,011:INFO:_master_model_container: 16
2025-04-19 20:09:50,011:INFO:_display_container: 2
2025-04-19 20:09:50,011:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 20:09:50,011:INFO:create_model() successfully completed......................................
2025-04-19 20:09:50,111:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:50,111:INFO:Creating metrics dataframe
2025-04-19 20:09:50,115:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 20:09:50,115:INFO:Total runtime is 0.6815548062324525 minutes
2025-04-19 20:09:50,115:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:50,116:INFO:Initializing create_model()
2025-04-19 20:09:50,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:50,116:INFO:Checking exceptions
2025-04-19 20:09:50,116:INFO:Importing libraries
2025-04-19 20:09:50,117:INFO:Copying training dataset
2025-04-19 20:09:50,119:INFO:Defining folds
2025-04-19 20:09:50,120:INFO:Declaring metric variables
2025-04-19 20:09:50,120:INFO:Importing untrained model
2025-04-19 20:09:50,121:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:09:50,121:INFO:Starting cross validation
2025-04-19 20:09:50,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:52,462:INFO:Calculating mean and std
2025-04-19 20:09:52,463:INFO:Creating metrics dataframe
2025-04-19 20:09:52,653:INFO:Uploading results into container
2025-04-19 20:09:52,654:INFO:Uploading model into container now
2025-04-19 20:09:52,654:INFO:_master_model_container: 17
2025-04-19 20:09:52,655:INFO:_display_container: 2
2025-04-19 20:09:52,655:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:09:52,655:INFO:create_model() successfully completed......................................
2025-04-19 20:09:52,760:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:52,760:INFO:Creating metrics dataframe
2025-04-19 20:09:52,763:INFO:Initializing Dummy Regressor
2025-04-19 20:09:52,763:INFO:Total runtime is 0.7256776412328085 minutes
2025-04-19 20:09:52,764:INFO:SubProcess create_model() called ==================================
2025-04-19 20:09:52,764:INFO:Initializing create_model()
2025-04-19 20:09:52,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D5FC1C0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:52,764:INFO:Checking exceptions
2025-04-19 20:09:52,764:INFO:Importing libraries
2025-04-19 20:09:52,764:INFO:Copying training dataset
2025-04-19 20:09:52,768:INFO:Defining folds
2025-04-19 20:09:52,768:INFO:Declaring metric variables
2025-04-19 20:09:52,768:INFO:Importing untrained model
2025-04-19 20:09:52,768:INFO:Dummy Regressor Imported successfully
2025-04-19 20:09:52,768:INFO:Starting cross validation
2025-04-19 20:09:52,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:09:54,113:INFO:Calculating mean and std
2025-04-19 20:09:54,114:INFO:Creating metrics dataframe
2025-04-19 20:09:54,296:INFO:Uploading results into container
2025-04-19 20:09:54,297:INFO:Uploading model into container now
2025-04-19 20:09:54,297:INFO:_master_model_container: 18
2025-04-19 20:09:54,297:INFO:_display_container: 2
2025-04-19 20:09:54,297:INFO:DummyRegressor()
2025-04-19 20:09:54,297:INFO:create_model() successfully completed......................................
2025-04-19 20:09:54,392:INFO:SubProcess create_model() end ==================================
2025-04-19 20:09:54,392:INFO:Creating metrics dataframe
2025-04-19 20:09:54,398:INFO:Initializing create_model()
2025-04-19 20:09:54,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:54,398:INFO:Checking exceptions
2025-04-19 20:09:54,398:INFO:Importing libraries
2025-04-19 20:09:54,398:INFO:Copying training dataset
2025-04-19 20:09:54,401:INFO:Defining folds
2025-04-19 20:09:54,401:INFO:Declaring metric variables
2025-04-19 20:09:54,401:INFO:Importing untrained model
2025-04-19 20:09:54,401:INFO:Declaring custom model
2025-04-19 20:09:54,402:INFO:Huber Regressor Imported successfully
2025-04-19 20:09:54,409:INFO:Cross validation set to False
2025-04-19 20:09:54,409:INFO:Fitting Model
2025-04-19 20:09:54,604:INFO:HuberRegressor()
2025-04-19 20:09:54,604:INFO:create_model() successfully completed......................................
2025-04-19 20:09:54,706:INFO:Initializing create_model()
2025-04-19 20:09:54,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:54,706:INFO:Checking exceptions
2025-04-19 20:09:54,707:INFO:Importing libraries
2025-04-19 20:09:54,707:INFO:Copying training dataset
2025-04-19 20:09:54,710:INFO:Defining folds
2025-04-19 20:09:54,710:INFO:Declaring metric variables
2025-04-19 20:09:54,710:INFO:Importing untrained model
2025-04-19 20:09:54,710:INFO:Declaring custom model
2025-04-19 20:09:54,710:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:09:54,717:INFO:Cross validation set to False
2025-04-19 20:09:54,717:INFO:Fitting Model
2025-04-19 20:09:54,889:INFO:BayesianRidge()
2025-04-19 20:09:54,889:INFO:create_model() successfully completed......................................
2025-04-19 20:09:54,993:INFO:Initializing create_model()
2025-04-19 20:09:54,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:09:54,993:INFO:Checking exceptions
2025-04-19 20:09:54,994:INFO:Importing libraries
2025-04-19 20:09:54,994:INFO:Copying training dataset
2025-04-19 20:09:54,994:INFO:Defining folds
2025-04-19 20:09:54,994:INFO:Declaring metric variables
2025-04-19 20:09:54,994:INFO:Importing untrained model
2025-04-19 20:09:54,994:INFO:Declaring custom model
2025-04-19 20:09:54,994:INFO:Linear Regression Imported successfully
2025-04-19 20:09:55,007:INFO:Cross validation set to False
2025-04-19 20:09:55,007:INFO:Fitting Model
2025-04-19 20:09:55,184:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:09:55,184:INFO:create_model() successfully completed......................................
2025-04-19 20:09:55,321:INFO:_master_model_container: 18
2025-04-19 20:09:55,321:INFO:_display_container: 2
2025-04-19 20:09:55,321:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 20:09:55,321:INFO:compare_models() successfully completed......................................
2025-04-19 20:09:55,321:INFO:Initializing tune_model()
2025-04-19 20:09:55,321:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>)
2025-04-19 20:09:55,321:INFO:Checking exceptions
2025-04-19 20:09:55,321:INFO:Copying training dataset
2025-04-19 20:09:55,333:INFO:Checking base model
2025-04-19 20:09:55,333:INFO:Base model : Huber Regressor
2025-04-19 20:09:55,333:INFO:Declaring metric variables
2025-04-19 20:09:55,333:INFO:Defining Hyperparameters
2025-04-19 20:09:55,438:INFO:Tuning with n_jobs=-1
2025-04-19 20:09:55,438:INFO:Initializing RandomizedSearchCV
2025-04-19 20:10:13,004:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.3, 'actual_estimator__alpha': 0.3}
2025-04-19 20:10:13,004:INFO:Hyperparameter search completed
2025-04-19 20:10:13,004:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:13,004:INFO:Initializing create_model()
2025-04-19 20:10:13,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854D483E50>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.3, 'alpha': 0.3})
2025-04-19 20:10:13,004:INFO:Checking exceptions
2025-04-19 20:10:13,004:INFO:Importing libraries
2025-04-19 20:10:13,004:INFO:Copying training dataset
2025-04-19 20:10:13,019:INFO:Defining folds
2025-04-19 20:10:13,019:INFO:Declaring metric variables
2025-04-19 20:10:13,020:INFO:Importing untrained model
2025-04-19 20:10:13,020:INFO:Declaring custom model
2025-04-19 20:10:13,020:INFO:Huber Regressor Imported successfully
2025-04-19 20:10:13,020:INFO:Starting cross validation
2025-04-19 20:10:13,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:14,653:INFO:Calculating mean and std
2025-04-19 20:10:14,653:INFO:Creating metrics dataframe
2025-04-19 20:10:14,671:INFO:Finalizing model
2025-04-19 20:10:14,938:INFO:Uploading results into container
2025-04-19 20:10:14,938:INFO:Uploading model into container now
2025-04-19 20:10:14,938:INFO:_master_model_container: 19
2025-04-19 20:10:14,938:INFO:_display_container: 3
2025-04-19 20:10:14,938:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:10:14,938:INFO:create_model() successfully completed......................................
2025-04-19 20:10:15,037:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:15,037:INFO:choose_better activated
2025-04-19 20:10:15,037:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:15,037:INFO:Initializing create_model()
2025-04-19 20:10:15,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:10:15,037:INFO:Checking exceptions
2025-04-19 20:10:15,037:INFO:Importing libraries
2025-04-19 20:10:15,037:INFO:Copying training dataset
2025-04-19 20:10:15,052:INFO:Defining folds
2025-04-19 20:10:15,052:INFO:Declaring metric variables
2025-04-19 20:10:15,052:INFO:Importing untrained model
2025-04-19 20:10:15,052:INFO:Declaring custom model
2025-04-19 20:10:15,053:INFO:Huber Regressor Imported successfully
2025-04-19 20:10:15,053:INFO:Starting cross validation
2025-04-19 20:10:15,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:16,605:INFO:Calculating mean and std
2025-04-19 20:10:16,605:INFO:Creating metrics dataframe
2025-04-19 20:10:16,613:INFO:Finalizing model
2025-04-19 20:10:16,906:INFO:Uploading results into container
2025-04-19 20:10:16,906:INFO:Uploading model into container now
2025-04-19 20:10:16,906:INFO:_master_model_container: 20
2025-04-19 20:10:16,906:INFO:_display_container: 4
2025-04-19 20:10:16,906:INFO:HuberRegressor()
2025-04-19 20:10:16,906:INFO:create_model() successfully completed......................................
2025-04-19 20:10:17,027:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:17,027:INFO:HuberRegressor() result for R2 is 0.0003
2025-04-19 20:10:17,027:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) result for R2 is 0.0006
2025-04-19 20:10:17,027:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) is best model
2025-04-19 20:10:17,027:INFO:choose_better completed
2025-04-19 20:10:17,036:INFO:_master_model_container: 20
2025-04-19 20:10:17,037:INFO:_display_container: 3
2025-04-19 20:10:17,038:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:10:17,038:INFO:tune_model() successfully completed......................................
2025-04-19 20:10:17,323:INFO:Initializing tune_model()
2025-04-19 20:10:17,323:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>)
2025-04-19 20:10:17,323:INFO:Checking exceptions
2025-04-19 20:10:17,327:INFO:Copying training dataset
2025-04-19 20:10:17,327:INFO:Checking base model
2025-04-19 20:10:17,327:INFO:Base model : Bayesian Ridge
2025-04-19 20:10:17,327:INFO:Declaring metric variables
2025-04-19 20:10:17,327:INFO:Defining Hyperparameters
2025-04-19 20:10:17,459:INFO:Tuning with n_jobs=-1
2025-04-19 20:10:17,459:INFO:Initializing RandomizedSearchCV
2025-04-19 20:10:33,515:INFO:best_params: {'actual_estimator__lambda_2': 0.005, 'actual_estimator__lambda_1': 1e-06, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': True, 'actual_estimator__alpha_2': 0.3, 'actual_estimator__alpha_1': 0.3}
2025-04-19 20:10:33,515:INFO:Hyperparameter search completed
2025-04-19 20:10:33,515:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:33,515:INFO:Initializing create_model()
2025-04-19 20:10:33,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854E1E3940>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.005, 'lambda_1': 1e-06, 'fit_intercept': True, 'compute_score': True, 'alpha_2': 0.3, 'alpha_1': 0.3})
2025-04-19 20:10:33,515:INFO:Checking exceptions
2025-04-19 20:10:33,515:INFO:Importing libraries
2025-04-19 20:10:33,515:INFO:Copying training dataset
2025-04-19 20:10:33,520:INFO:Defining folds
2025-04-19 20:10:33,520:INFO:Declaring metric variables
2025-04-19 20:10:33,521:INFO:Importing untrained model
2025-04-19 20:10:33,521:INFO:Declaring custom model
2025-04-19 20:10:33,521:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:10:33,521:INFO:Starting cross validation
2025-04-19 20:10:33,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:35,070:INFO:Calculating mean and std
2025-04-19 20:10:35,071:INFO:Creating metrics dataframe
2025-04-19 20:10:35,074:INFO:Finalizing model
2025-04-19 20:10:35,325:INFO:Uploading results into container
2025-04-19 20:10:35,325:INFO:Uploading model into container now
2025-04-19 20:10:35,326:INFO:_master_model_container: 21
2025-04-19 20:10:35,326:INFO:_display_container: 4
2025-04-19 20:10:35,326:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 20:10:35,326:INFO:create_model() successfully completed......................................
2025-04-19 20:10:35,420:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:35,420:INFO:choose_better activated
2025-04-19 20:10:35,420:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:35,420:INFO:Initializing create_model()
2025-04-19 20:10:35,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:10:35,420:INFO:Checking exceptions
2025-04-19 20:10:35,420:INFO:Importing libraries
2025-04-19 20:10:35,420:INFO:Copying training dataset
2025-04-19 20:10:35,420:INFO:Defining folds
2025-04-19 20:10:35,420:INFO:Declaring metric variables
2025-04-19 20:10:35,420:INFO:Importing untrained model
2025-04-19 20:10:35,420:INFO:Declaring custom model
2025-04-19 20:10:35,420:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:10:35,420:INFO:Starting cross validation
2025-04-19 20:10:35,420:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:36,955:INFO:Calculating mean and std
2025-04-19 20:10:36,955:INFO:Creating metrics dataframe
2025-04-19 20:10:36,959:INFO:Finalizing model
2025-04-19 20:10:37,224:INFO:Uploading results into container
2025-04-19 20:10:37,224:INFO:Uploading model into container now
2025-04-19 20:10:37,224:INFO:_master_model_container: 22
2025-04-19 20:10:37,224:INFO:_display_container: 5
2025-04-19 20:10:37,224:INFO:BayesianRidge()
2025-04-19 20:10:37,224:INFO:create_model() successfully completed......................................
2025-04-19 20:10:37,392:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:37,392:INFO:BayesianRidge() result for R2 is -0.005
2025-04-19 20:10:37,393:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) result for R2 is -0.0049
2025-04-19 20:10:37,393:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) is best model
2025-04-19 20:10:37,393:INFO:choose_better completed
2025-04-19 20:10:37,415:INFO:_master_model_container: 22
2025-04-19 20:10:37,415:INFO:_display_container: 4
2025-04-19 20:10:37,416:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 20:10:37,416:INFO:tune_model() successfully completed......................................
2025-04-19 20:10:37,709:INFO:Initializing tune_model()
2025-04-19 20:10:37,709:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>)
2025-04-19 20:10:37,709:INFO:Checking exceptions
2025-04-19 20:10:37,712:INFO:Copying training dataset
2025-04-19 20:10:37,714:INFO:Checking base model
2025-04-19 20:10:37,714:INFO:Base model : Linear Regression
2025-04-19 20:10:37,715:INFO:Declaring metric variables
2025-04-19 20:10:37,715:INFO:Defining Hyperparameters
2025-04-19 20:10:37,715:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 20:10:37,830:INFO:Tuning with n_jobs=-1
2025-04-19 20:10:37,830:INFO:Initializing GridSearchCV
2025-04-19 20:10:41,306:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 20:10:41,307:INFO:Hyperparameter search completed
2025-04-19 20:10:41,307:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:41,308:INFO:Initializing create_model()
2025-04-19 20:10:41,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001854E453760>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 20:10:41,308:INFO:Checking exceptions
2025-04-19 20:10:41,308:INFO:Importing libraries
2025-04-19 20:10:41,308:INFO:Copying training dataset
2025-04-19 20:10:41,308:INFO:Defining folds
2025-04-19 20:10:41,308:INFO:Declaring metric variables
2025-04-19 20:10:41,308:INFO:Importing untrained model
2025-04-19 20:10:41,308:INFO:Declaring custom model
2025-04-19 20:10:41,308:INFO:Linear Regression Imported successfully
2025-04-19 20:10:41,308:INFO:Starting cross validation
2025-04-19 20:10:41,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:42,752:INFO:Calculating mean and std
2025-04-19 20:10:42,752:INFO:Creating metrics dataframe
2025-04-19 20:10:42,752:INFO:Finalizing model
2025-04-19 20:10:43,011:INFO:Uploading results into container
2025-04-19 20:10:43,011:INFO:Uploading model into container now
2025-04-19 20:10:43,012:INFO:_master_model_container: 23
2025-04-19 20:10:43,012:INFO:_display_container: 5
2025-04-19 20:10:43,012:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:10:43,012:INFO:create_model() successfully completed......................................
2025-04-19 20:10:43,109:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:43,109:INFO:choose_better activated
2025-04-19 20:10:43,109:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:43,110:INFO:Initializing create_model()
2025-04-19 20:10:43,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:10:43,110:INFO:Checking exceptions
2025-04-19 20:10:43,111:INFO:Importing libraries
2025-04-19 20:10:43,111:INFO:Copying training dataset
2025-04-19 20:10:43,114:INFO:Defining folds
2025-04-19 20:10:43,114:INFO:Declaring metric variables
2025-04-19 20:10:43,114:INFO:Importing untrained model
2025-04-19 20:10:43,114:INFO:Declaring custom model
2025-04-19 20:10:43,114:INFO:Linear Regression Imported successfully
2025-04-19 20:10:43,114:INFO:Starting cross validation
2025-04-19 20:10:43,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:44,599:INFO:Calculating mean and std
2025-04-19 20:10:44,599:INFO:Creating metrics dataframe
2025-04-19 20:10:44,599:INFO:Finalizing model
2025-04-19 20:10:44,857:INFO:Uploading results into container
2025-04-19 20:10:44,857:INFO:Uploading model into container now
2025-04-19 20:10:44,857:INFO:_master_model_container: 24
2025-04-19 20:10:44,857:INFO:_display_container: 6
2025-04-19 20:10:44,857:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:10:44,857:INFO:create_model() successfully completed......................................
2025-04-19 20:10:44,957:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:44,957:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0051
2025-04-19 20:10:44,957:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0051
2025-04-19 20:10:44,957:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 20:10:44,957:INFO:choose_better completed
2025-04-19 20:10:44,957:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:10:44,972:INFO:_master_model_container: 24
2025-04-19 20:10:44,972:INFO:_display_container: 5
2025-04-19 20:10:44,973:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:10:44,973:INFO:tune_model() successfully completed......................................
2025-04-19 20:10:45,207:INFO:Initializing blend_models()
2025-04-19 20:10:45,207:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:10:45,207:INFO:Checking exceptions
2025-04-19 20:10:45,207:INFO:Importing libraries
2025-04-19 20:10:45,207:INFO:Copying training dataset
2025-04-19 20:10:45,207:INFO:Getting model names
2025-04-19 20:10:45,207:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:45,207:INFO:Initializing create_model()
2025-04-19 20:10:45,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018543DB8FA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:10:45,207:INFO:Checking exceptions
2025-04-19 20:10:45,207:INFO:Importing libraries
2025-04-19 20:10:45,207:INFO:Copying training dataset
2025-04-19 20:10:45,207:INFO:Defining folds
2025-04-19 20:10:45,207:INFO:Declaring metric variables
2025-04-19 20:10:45,207:INFO:Importing untrained model
2025-04-19 20:10:45,207:INFO:Declaring custom model
2025-04-19 20:10:45,207:INFO:Voting Regressor Imported successfully
2025-04-19 20:10:45,219:INFO:Starting cross validation
2025-04-19 20:10:45,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:46,842:INFO:Calculating mean and std
2025-04-19 20:10:46,844:INFO:Creating metrics dataframe
2025-04-19 20:10:46,844:INFO:Finalizing model
2025-04-19 20:10:47,177:INFO:Uploading results into container
2025-04-19 20:10:47,177:INFO:Uploading model into container now
2025-04-19 20:10:47,177:INFO:_master_model_container: 25
2025-04-19 20:10:47,177:INFO:_display_container: 6
2025-04-19 20:10:47,177:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:10:47,177:INFO:create_model() successfully completed......................................
2025-04-19 20:10:47,302:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:47,310:INFO:_master_model_container: 25
2025-04-19 20:10:47,310:INFO:_display_container: 6
2025-04-19 20:10:47,310:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:10:47,310:INFO:blend_models() successfully completed......................................
2025-04-19 20:10:47,420:INFO:Initializing stack_models()
2025-04-19 20:10:47,420:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:10:47,420:INFO:Checking exceptions
2025-04-19 20:10:47,420:INFO:Defining meta model
2025-04-19 20:10:47,420:INFO:Getting model names
2025-04-19 20:10:47,420:INFO:[('Huber Regressor', HuberRegressor(alpha=0.3, epsilon=1.3)), ('Bayesian Ridge', BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 20:10:47,420:INFO:SubProcess create_model() called ==================================
2025-04-19 20:10:47,420:INFO:Initializing create_model()
2025-04-19 20:10:47,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018543DB8FA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:10:47,420:INFO:Checking exceptions
2025-04-19 20:10:47,420:INFO:Importing libraries
2025-04-19 20:10:47,420:INFO:Copying training dataset
2025-04-19 20:10:47,438:INFO:Defining folds
2025-04-19 20:10:47,438:INFO:Declaring metric variables
2025-04-19 20:10:47,438:INFO:Importing untrained model
2025-04-19 20:10:47,438:INFO:Declaring custom model
2025-04-19 20:10:47,440:INFO:Stacking Regressor Imported successfully
2025-04-19 20:10:47,440:INFO:Starting cross validation
2025-04-19 20:10:47,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:10:49,247:INFO:Calculating mean and std
2025-04-19 20:10:49,247:INFO:Creating metrics dataframe
2025-04-19 20:10:49,247:INFO:Finalizing model
2025-04-19 20:10:49,632:INFO:Uploading results into container
2025-04-19 20:10:49,632:INFO:Uploading model into container now
2025-04-19 20:10:49,632:INFO:_master_model_container: 26
2025-04-19 20:10:49,632:INFO:_display_container: 7
2025-04-19 20:10:49,632:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:10:49,632:INFO:create_model() successfully completed......................................
2025-04-19 20:10:49,746:INFO:SubProcess create_model() end ==================================
2025-04-19 20:10:49,752:INFO:_master_model_container: 26
2025-04-19 20:10:49,752:INFO:_display_container: 7
2025-04-19 20:10:49,752:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:10:49,752:INFO:stack_models() successfully completed......................................
2025-04-19 20:10:49,877:INFO:Initializing save_model()
2025-04-19 20:10:49,877:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:10:49,877:INFO:Adding model into prep_pipe
2025-04-19 20:10:49,917:INFO:models/model_1.pkl saved in current working directory
2025-04-19 20:10:49,935:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor(alpha=0.3,
                                                             epsilon=1.3)),
                                             ('Bayesian Ridge',
                                              BayesianRidge(alpha_1=0.3,
                                                            alpha_2=0.3,
                                                            compute_score=True,
                                                            lambda_2=0.005)),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 20:10:49,935:INFO:save_model() successfully completed......................................
2025-04-19 20:10:50,165:INFO:Initializing plot_model()
2025-04-19 20:10:50,165:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:50,165:INFO:Checking exceptions
2025-04-19 20:10:50,168:INFO:Initializing plot_model()
2025-04-19 20:10:50,168:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:50,169:INFO:Checking exceptions
2025-04-19 20:10:50,171:INFO:Preloading libraries
2025-04-19 20:10:50,171:INFO:Copying training dataset
2025-04-19 20:10:50,172:INFO:Plot type: residuals
2025-04-19 20:10:50,470:INFO:Fitting Model
2025-04-19 20:10:50,470:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:10:50,503:INFO:Scoring test/hold-out set
2025-04-19 20:10:50,534:INFO:Saving 'Residuals.png'
2025-04-19 20:10:51,355:INFO:Visual Rendered Successfully
2025-04-19 20:10:51,509:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:51,753:INFO:Initializing plot_model()
2025-04-19 20:10:51,753:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:51,754:INFO:Checking exceptions
2025-04-19 20:10:51,755:INFO:Preloading libraries
2025-04-19 20:10:51,756:INFO:Copying training dataset
2025-04-19 20:10:51,756:INFO:Plot type: error
2025-04-19 20:10:52,108:INFO:Fitting Model
2025-04-19 20:10:52,108:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:10:52,108:INFO:Scoring test/hold-out set
2025-04-19 20:10:52,136:INFO:Saving 'Prediction Error.png'
2025-04-19 20:10:52,548:INFO:Visual Rendered Successfully
2025-04-19 20:10:52,681:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:52,852:INFO:Initializing plot_model()
2025-04-19 20:10:52,852:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:52,852:INFO:Checking exceptions
2025-04-19 20:10:52,854:INFO:Preloading libraries
2025-04-19 20:10:52,854:INFO:Copying training dataset
2025-04-19 20:10:52,854:INFO:Plot type: learning
2025-04-19 20:10:53,176:INFO:Fitting Model
2025-04-19 20:10:54,028:INFO:Saving 'Learning Curve.png'
2025-04-19 20:10:54,408:INFO:Visual Rendered Successfully
2025-04-19 20:10:54,521:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:54,694:INFO:Initializing save_model()
2025-04-19 20:10:54,694:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:10:54,694:INFO:Adding model into prep_pipe
2025-04-19 20:10:54,741:INFO:models/model_2.pkl saved in current working directory
2025-04-19 20:10:54,758:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor(alpha=0.3,
                                                               epsilon=1.3)),
                                               ('Bayesian Ridge',
                                                BayesianRidge(alpha_1=0.3,
                                                              alpha_2=0.3,
                                                              compute_score=True,
                                                              lambda_2=0.005)),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 20:10:54,758:INFO:save_model() successfully completed......................................
2025-04-19 20:10:55,018:INFO:Initializing plot_model()
2025-04-19 20:10:55,019:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:55,019:INFO:Checking exceptions
2025-04-19 20:10:55,024:INFO:Initializing plot_model()
2025-04-19 20:10:55,024:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:55,024:INFO:Checking exceptions
2025-04-19 20:10:55,027:INFO:Preloading libraries
2025-04-19 20:10:55,028:INFO:Copying training dataset
2025-04-19 20:10:55,029:INFO:Plot type: residuals
2025-04-19 20:10:55,318:INFO:Fitting Model
2025-04-19 20:10:55,318:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:10:55,353:INFO:Scoring test/hold-out set
2025-04-19 20:10:55,388:INFO:Saving 'Residuals.png'
2025-04-19 20:10:56,222:INFO:Visual Rendered Successfully
2025-04-19 20:10:56,358:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:56,497:INFO:Initializing plot_model()
2025-04-19 20:10:56,497:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:56,497:INFO:Checking exceptions
2025-04-19 20:10:56,497:INFO:Preloading libraries
2025-04-19 20:10:56,497:INFO:Copying training dataset
2025-04-19 20:10:56,497:INFO:Plot type: error
2025-04-19 20:10:56,734:INFO:Fitting Model
2025-04-19 20:10:56,735:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:10:56,735:INFO:Scoring test/hold-out set
2025-04-19 20:10:56,752:INFO:Saving 'Prediction Error.png'
2025-04-19 20:10:57,050:INFO:Visual Rendered Successfully
2025-04-19 20:10:57,167:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:57,466:INFO:Initializing plot_model()
2025-04-19 20:10:57,466:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:10:57,466:INFO:Checking exceptions
2025-04-19 20:10:57,473:INFO:Preloading libraries
2025-04-19 20:10:57,473:INFO:Copying training dataset
2025-04-19 20:10:57,473:INFO:Plot type: learning
2025-04-19 20:10:57,786:INFO:Fitting Model
2025-04-19 20:10:59,253:INFO:Saving 'Learning Curve.png'
2025-04-19 20:10:59,655:INFO:Visual Rendered Successfully
2025-04-19 20:10:59,793:INFO:plot_model() successfully completed......................................
2025-04-19 20:10:59,960:INFO:Initializing save_model()
2025-04-19 20:10:59,960:INFO:save_model(model=HuberRegressor(alpha=0.3, epsilon=1.3), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:10:59,960:INFO:Adding model into prep_pipe
2025-04-19 20:11:00,005:INFO:models/model_3.pkl saved in current working directory
2025-04-19 20:11:00,016:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor(alpha=0.3, epsilon=1.3))])
2025-04-19 20:11:00,016:INFO:save_model() successfully completed......................................
2025-04-19 20:11:00,257:INFO:Initializing plot_model()
2025-04-19 20:11:00,257:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:00,257:INFO:Checking exceptions
2025-04-19 20:11:00,259:INFO:Preloading libraries
2025-04-19 20:11:00,260:INFO:Copying training dataset
2025-04-19 20:11:00,260:INFO:Plot type: feature
2025-04-19 20:11:00,439:INFO:Saving 'Feature Importance.png'
2025-04-19 20:11:00,575:INFO:Visual Rendered Successfully
2025-04-19 20:11:00,687:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:00,903:INFO:Initializing plot_model()
2025-04-19 20:11:00,903:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:00,903:INFO:Checking exceptions
2025-04-19 20:11:00,905:INFO:Preloading libraries
2025-04-19 20:11:00,905:INFO:Copying training dataset
2025-04-19 20:11:00,905:INFO:Plot type: residuals
2025-04-19 20:11:01,252:INFO:Fitting Model
2025-04-19 20:11:01,252:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:11:01,284:INFO:Scoring test/hold-out set
2025-04-19 20:11:01,303:INFO:Saving 'Residuals.png'
2025-04-19 20:11:01,922:INFO:Visual Rendered Successfully
2025-04-19 20:11:02,028:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:02,254:INFO:Initializing plot_model()
2025-04-19 20:11:02,255:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:02,255:INFO:Checking exceptions
2025-04-19 20:11:02,257:INFO:Preloading libraries
2025-04-19 20:11:02,257:INFO:Copying training dataset
2025-04-19 20:11:02,257:INFO:Plot type: error
2025-04-19 20:11:02,541:INFO:Fitting Model
2025-04-19 20:11:02,541:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:11:02,541:INFO:Scoring test/hold-out set
2025-04-19 20:11:02,548:INFO:Saving 'Prediction Error.png'
2025-04-19 20:11:02,905:INFO:Visual Rendered Successfully
2025-04-19 20:11:03,000:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:03,174:INFO:Initializing plot_model()
2025-04-19 20:11:03,174:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:03,174:INFO:Checking exceptions
2025-04-19 20:11:03,176:INFO:Preloading libraries
2025-04-19 20:11:03,176:INFO:Copying training dataset
2025-04-19 20:11:03,176:INFO:Plot type: learning
2025-04-19 20:11:03,440:INFO:Fitting Model
2025-04-19 20:11:03,759:INFO:Saving 'Learning Curve.png'
2025-04-19 20:11:04,123:INFO:Visual Rendered Successfully
2025-04-19 20:11:04,241:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:04,463:INFO:Initializing save_model()
2025-04-19 20:11:04,463:INFO:save_model(model=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:11:04,463:INFO:Adding model into prep_pipe
2025-04-19 20:11:04,496:INFO:models/model_4.pkl saved in current working directory
2025-04-19 20:11:04,512:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True,
                               lambda_2=0.005))])
2025-04-19 20:11:04,513:INFO:save_model() successfully completed......................................
2025-04-19 20:11:04,736:INFO:Initializing plot_model()
2025-04-19 20:11:04,736:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:04,736:INFO:Checking exceptions
2025-04-19 20:11:04,736:INFO:Preloading libraries
2025-04-19 20:11:04,736:INFO:Copying training dataset
2025-04-19 20:11:04,736:INFO:Plot type: feature
2025-04-19 20:11:04,922:INFO:Saving 'Feature Importance.png'
2025-04-19 20:11:05,098:INFO:Visual Rendered Successfully
2025-04-19 20:11:05,202:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:05,370:INFO:Initializing plot_model()
2025-04-19 20:11:05,370:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:05,370:INFO:Checking exceptions
2025-04-19 20:11:05,370:INFO:Preloading libraries
2025-04-19 20:11:05,370:INFO:Copying training dataset
2025-04-19 20:11:05,370:INFO:Plot type: residuals
2025-04-19 20:11:05,686:INFO:Fitting Model
2025-04-19 20:11:05,686:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 20:11:05,719:INFO:Scoring test/hold-out set
2025-04-19 20:11:05,752:INFO:Saving 'Residuals.png'
2025-04-19 20:11:06,492:INFO:Visual Rendered Successfully
2025-04-19 20:11:06,624:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:06,786:INFO:Initializing plot_model()
2025-04-19 20:11:06,786:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:06,786:INFO:Checking exceptions
2025-04-19 20:11:06,786:INFO:Preloading libraries
2025-04-19 20:11:06,786:INFO:Copying training dataset
2025-04-19 20:11:06,786:INFO:Plot type: error
2025-04-19 20:11:07,071:INFO:Fitting Model
2025-04-19 20:11:07,071:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 20:11:07,071:INFO:Scoring test/hold-out set
2025-04-19 20:11:07,101:INFO:Saving 'Prediction Error.png'
2025-04-19 20:11:07,488:INFO:Visual Rendered Successfully
2025-04-19 20:11:07,594:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:07,753:INFO:Initializing plot_model()
2025-04-19 20:11:07,753:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:07,753:INFO:Checking exceptions
2025-04-19 20:11:07,753:INFO:Preloading libraries
2025-04-19 20:11:07,753:INFO:Copying training dataset
2025-04-19 20:11:07,753:INFO:Plot type: learning
2025-04-19 20:11:08,051:INFO:Fitting Model
2025-04-19 20:11:08,252:INFO:Saving 'Learning Curve.png'
2025-04-19 20:11:08,633:INFO:Visual Rendered Successfully
2025-04-19 20:11:08,756:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:08,949:INFO:Initializing save_model()
2025-04-19 20:11:08,949:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:11:08,949:INFO:Adding model into prep_pipe
2025-04-19 20:11:08,998:INFO:models/model_5.pkl saved in current working directory
2025-04-19 20:11:09,015:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_49', 'feature_11',
                                             'feature_20'],
                                    transformer=Sim...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 20:11:09,015:INFO:save_model() successfully completed......................................
2025-04-19 20:11:09,342:INFO:Initializing plot_model()
2025-04-19 20:11:09,342:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:09,342:INFO:Checking exceptions
2025-04-19 20:11:09,342:INFO:Preloading libraries
2025-04-19 20:11:09,342:INFO:Copying training dataset
2025-04-19 20:11:09,342:INFO:Plot type: feature
2025-04-19 20:11:09,568:INFO:Saving 'Feature Importance.png'
2025-04-19 20:11:09,726:INFO:Visual Rendered Successfully
2025-04-19 20:11:09,840:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:09,996:INFO:Initializing plot_model()
2025-04-19 20:11:09,996:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:09,997:INFO:Checking exceptions
2025-04-19 20:11:09,998:INFO:Preloading libraries
2025-04-19 20:11:09,998:INFO:Copying training dataset
2025-04-19 20:11:09,998:INFO:Plot type: residuals
2025-04-19 20:11:10,291:INFO:Fitting Model
2025-04-19 20:11:10,291:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 20:11:10,317:INFO:Scoring test/hold-out set
2025-04-19 20:11:10,346:INFO:Saving 'Residuals.png'
2025-04-19 20:11:11,155:INFO:Visual Rendered Successfully
2025-04-19 20:11:11,331:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:11,481:INFO:Initializing plot_model()
2025-04-19 20:11:11,481:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:11,481:INFO:Checking exceptions
2025-04-19 20:11:11,482:INFO:Preloading libraries
2025-04-19 20:11:11,483:INFO:Copying training dataset
2025-04-19 20:11:11,483:INFO:Plot type: error
2025-04-19 20:11:11,773:INFO:Fitting Model
2025-04-19 20:11:11,773:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 20:11:11,773:INFO:Scoring test/hold-out set
2025-04-19 20:11:11,790:INFO:Saving 'Prediction Error.png'
2025-04-19 20:11:12,101:INFO:Visual Rendered Successfully
2025-04-19 20:11:12,219:INFO:plot_model() successfully completed......................................
2025-04-19 20:11:12,462:INFO:Initializing plot_model()
2025-04-19 20:11:12,462:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001854FAF25C0>, system=True)
2025-04-19 20:11:12,462:INFO:Checking exceptions
2025-04-19 20:11:12,469:INFO:Preloading libraries
2025-04-19 20:11:12,470:INFO:Copying training dataset
2025-04-19 20:11:12,470:INFO:Plot type: learning
2025-04-19 20:11:12,758:INFO:Fitting Model
2025-04-19 20:11:12,978:INFO:Saving 'Learning Curve.png'
2025-04-19 20:11:13,361:INFO:Visual Rendered Successfully
2025-04-19 20:11:13,488:INFO:plot_model() successfully completed......................................
2025-04-19 20:13:41,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:13:41,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:13:41,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:13:41,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:14:42,078:INFO:PyCaret RegressionExperiment
2025-04-19 20:14:42,078:INFO:Logging name: agn_modeling
2025-04-19 20:14:42,078:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:14:42,078:INFO:version 3.0.4
2025-04-19 20:14:42,078:INFO:Initializing setup()
2025-04-19 20:14:42,078:INFO:self.USI: b262
2025-04-19 20:14:42,078:INFO:self._variable_keys: {'data', 'pipeline', 'html_param', 'y', 'target_param', 'X', 'USI', 'X_train', 'n_jobs_param', 'seed', 'fold_groups_param', '_ml_usecase', 'fold_generator', 'X_test', 'exp_id', 'transform_target_param', 'logging_param', 'log_plots_param', '_available_plots', 'idx', 'exp_name_log', 'gpu_param', 'y_test', 'memory', 'y_train', 'gpu_n_jobs_param', 'fold_shuffle_param'}
2025-04-19 20:14:42,078:INFO:Checking environment
2025-04-19 20:14:42,078:INFO:python_version: 3.10.9
2025-04-19 20:14:42,078:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:14:42,078:INFO:machine: AMD64
2025-04-19 20:14:42,078:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:14:42,095:INFO:Memory: svmem(total=16952647680, available=3528785920, percent=79.2, used=13423861760, free=3528785920)
2025-04-19 20:14:42,095:INFO:Physical Core: 4
2025-04-19 20:14:42,095:INFO:Logical Core: 8
2025-04-19 20:14:42,095:INFO:Checking libraries
2025-04-19 20:14:42,095:INFO:System:
2025-04-19 20:14:42,095:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:14:42,095:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:14:42,095:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:14:42,095:INFO:PyCaret required dependencies:
2025-04-19 20:14:42,147:INFO:                 pip: 25.0.1
2025-04-19 20:14:42,147:INFO:          setuptools: 65.5.0
2025-04-19 20:14:42,147:INFO:             pycaret: 3.0.4
2025-04-19 20:14:42,147:INFO:             IPython: 8.35.0
2025-04-19 20:14:42,147:INFO:          ipywidgets: 8.1.6
2025-04-19 20:14:42,147:INFO:                tqdm: 4.67.1
2025-04-19 20:14:42,147:INFO:               numpy: 1.23.5
2025-04-19 20:14:42,147:INFO:              pandas: 1.5.3
2025-04-19 20:14:42,147:INFO:              jinja2: 3.1.6
2025-04-19 20:14:42,147:INFO:               scipy: 1.10.1
2025-04-19 20:14:42,147:INFO:              joblib: 1.2.0
2025-04-19 20:14:42,147:INFO:             sklearn: 1.2.2
2025-04-19 20:14:42,147:INFO:                pyod: 2.0.4
2025-04-19 20:14:42,147:INFO:            imblearn: 0.12.4
2025-04-19 20:14:42,147:INFO:   category_encoders: 2.7.0
2025-04-19 20:14:42,147:INFO:            lightgbm: 4.6.0
2025-04-19 20:14:42,147:INFO:               numba: 0.60.0
2025-04-19 20:14:42,147:INFO:            requests: 2.32.3
2025-04-19 20:14:42,147:INFO:          matplotlib: 3.7.1
2025-04-19 20:14:42,147:INFO:          scikitplot: 0.3.7
2025-04-19 20:14:42,147:INFO:         yellowbrick: 1.5
2025-04-19 20:14:42,147:INFO:              plotly: 5.24.1
2025-04-19 20:14:42,147:INFO:    plotly-resampler: Not installed
2025-04-19 20:14:42,147:INFO:             kaleido: 0.2.1
2025-04-19 20:14:42,147:INFO:           schemdraw: 0.15
2025-04-19 20:14:42,147:INFO:         statsmodels: 0.14.4
2025-04-19 20:14:42,147:INFO:              sktime: 0.21.1
2025-04-19 20:14:42,147:INFO:               tbats: 1.1.3
2025-04-19 20:14:42,147:INFO:            pmdarima: 2.0.4
2025-04-19 20:14:42,147:INFO:              psutil: 7.0.0
2025-04-19 20:14:42,147:INFO:          markupsafe: 3.0.2
2025-04-19 20:14:42,147:INFO:             pickle5: Not installed
2025-04-19 20:14:42,147:INFO:         cloudpickle: 3.1.1
2025-04-19 20:14:42,147:INFO:         deprecation: 2.1.0
2025-04-19 20:14:42,147:INFO:              xxhash: 3.5.0
2025-04-19 20:14:42,147:INFO:           wurlitzer: Not installed
2025-04-19 20:14:42,147:INFO:PyCaret optional dependencies:
2025-04-19 20:14:42,627:INFO:                shap: Not installed
2025-04-19 20:14:42,627:INFO:           interpret: Not installed
2025-04-19 20:14:42,627:INFO:                umap: Not installed
2025-04-19 20:14:42,627:INFO:    pandas_profiling: Not installed
2025-04-19 20:14:42,627:INFO:  explainerdashboard: Not installed
2025-04-19 20:14:42,627:INFO:             autoviz: Not installed
2025-04-19 20:14:42,627:INFO:           fairlearn: Not installed
2025-04-19 20:14:42,627:INFO:          deepchecks: Not installed
2025-04-19 20:14:42,627:INFO:             xgboost: Not installed
2025-04-19 20:14:42,627:INFO:            catboost: Not installed
2025-04-19 20:14:42,627:INFO:              kmodes: Not installed
2025-04-19 20:14:42,627:INFO:             mlxtend: Not installed
2025-04-19 20:14:42,627:INFO:       statsforecast: Not installed
2025-04-19 20:14:42,627:INFO:        tune_sklearn: Not installed
2025-04-19 20:14:42,627:INFO:                 ray: Not installed
2025-04-19 20:14:42,627:INFO:            hyperopt: Not installed
2025-04-19 20:14:42,627:INFO:              optuna: Not installed
2025-04-19 20:14:42,627:INFO:               skopt: Not installed
2025-04-19 20:14:42,627:INFO:              mlflow: 2.21.3
2025-04-19 20:14:42,627:INFO:              gradio: Not installed
2025-04-19 20:14:42,627:INFO:             fastapi: 0.115.12
2025-04-19 20:14:42,627:INFO:             uvicorn: 0.34.2
2025-04-19 20:14:42,627:INFO:              m2cgen: Not installed
2025-04-19 20:14:42,627:INFO:           evidently: Not installed
2025-04-19 20:14:42,627:INFO:               fugue: Not installed
2025-04-19 20:14:42,627:INFO:           streamlit: Not installed
2025-04-19 20:14:42,627:INFO:             prophet: Not installed
2025-04-19 20:14:42,627:INFO:None
2025-04-19 20:14:42,627:INFO:Set up data.
2025-04-19 20:14:42,627:INFO:Set up train/test split.
2025-04-19 20:14:42,642:INFO:Set up index.
2025-04-19 20:14:42,643:INFO:Set up folding strategy.
2025-04-19 20:14:42,643:INFO:Assigning column types.
2025-04-19 20:14:42,643:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:14:42,643:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,643:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:42,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:42,776:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,799:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,976:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:42,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:42,976:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:14:42,991:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:14:42,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,164:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,168:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,318:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:14:43,327:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,472:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,636:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:14:43,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,810:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:14:43,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:43,952:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:14:44,093:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:44,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:14:44,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,340:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:14:44,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:44,618:INFO:Preparing preprocessing pipeline...
2025-04-19 20:14:44,618:INFO:Set up target transformation.
2025-04-19 20:14:44,618:INFO:Set up simple imputation.
2025-04-19 20:14:44,618:INFO:Set up removing multicollinearity.
2025-04-19 20:14:44,618:INFO:Set up removing outliers.
2025-04-19 20:14:44,618:INFO:Set up feature normalization.
2025-04-19 20:14:44,706:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:14:44,733:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_49',
                                             'feature_20'],
                                    transformer=Sim...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:14:44,733:INFO:Creating final display dataframe.
2025-04-19 20:14:44,885:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 6)
4        Transformed data shape     (7719, 6)
5   Transformed train set shape     (5319, 6)
6    Transformed test set shape     (2400, 6)
7              Numeric features             5
8      Rows with missing values          9.6%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment  MlflowLogger
26              Experiment Name  agn_modeling
27                          USI          b262
2025-04-19 20:14:45,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:45,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:45,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:45,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:14:45,207:INFO:Logging experiment in loggers
2025-04-19 20:18:54,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:18:54,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:18:54,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:18:54,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:19:41,432:INFO:PyCaret RegressionExperiment
2025-04-19 20:19:41,432:INFO:Logging name: agn_modeling
2025-04-19 20:19:41,432:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:19:41,432:INFO:version 3.0.4
2025-04-19 20:19:41,432:INFO:Initializing setup()
2025-04-19 20:19:41,432:INFO:self.USI: 8914
2025-04-19 20:19:41,432:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'target_param', 'y_train', 'X_test', 'idx', 'transform_target_param', 'memory', 'log_plots_param', '_available_plots', 'X_train', 'gpu_param', 'seed', 'pipeline', 'X', 'fold_generator', 'n_jobs_param', 'y', 'USI', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'logging_param', 'fold_shuffle_param', 'exp_name_log', 'exp_id', 'y_test'}
2025-04-19 20:19:41,432:INFO:Checking environment
2025-04-19 20:19:41,432:INFO:python_version: 3.10.9
2025-04-19 20:19:41,432:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:19:41,432:INFO:machine: AMD64
2025-04-19 20:19:41,437:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:19:41,448:INFO:Memory: svmem(total=16952647680, available=3969056768, percent=76.6, used=12983590912, free=3969056768)
2025-04-19 20:19:41,448:INFO:Physical Core: 4
2025-04-19 20:19:41,448:INFO:Logical Core: 8
2025-04-19 20:19:41,448:INFO:Checking libraries
2025-04-19 20:19:41,448:INFO:System:
2025-04-19 20:19:41,448:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:19:41,448:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:19:41,448:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:19:41,448:INFO:PyCaret required dependencies:
2025-04-19 20:19:41,467:INFO:                 pip: 25.0.1
2025-04-19 20:19:41,467:INFO:          setuptools: 65.5.0
2025-04-19 20:19:41,467:INFO:             pycaret: 3.0.4
2025-04-19 20:19:41,467:INFO:             IPython: 8.35.0
2025-04-19 20:19:41,467:INFO:          ipywidgets: 8.1.6
2025-04-19 20:19:41,467:INFO:                tqdm: 4.67.1
2025-04-19 20:19:41,467:INFO:               numpy: 1.23.5
2025-04-19 20:19:41,467:INFO:              pandas: 1.5.3
2025-04-19 20:19:41,467:INFO:              jinja2: 3.1.6
2025-04-19 20:19:41,467:INFO:               scipy: 1.10.1
2025-04-19 20:19:41,467:INFO:              joblib: 1.2.0
2025-04-19 20:19:41,467:INFO:             sklearn: 1.2.2
2025-04-19 20:19:41,467:INFO:                pyod: 2.0.4
2025-04-19 20:19:41,467:INFO:            imblearn: 0.12.4
2025-04-19 20:19:41,467:INFO:   category_encoders: 2.7.0
2025-04-19 20:19:41,467:INFO:            lightgbm: 4.6.0
2025-04-19 20:19:41,467:INFO:               numba: 0.60.0
2025-04-19 20:19:41,467:INFO:            requests: 2.32.3
2025-04-19 20:19:41,467:INFO:          matplotlib: 3.7.1
2025-04-19 20:19:41,467:INFO:          scikitplot: 0.3.7
2025-04-19 20:19:41,467:INFO:         yellowbrick: 1.5
2025-04-19 20:19:41,467:INFO:              plotly: 5.24.1
2025-04-19 20:19:41,467:INFO:    plotly-resampler: Not installed
2025-04-19 20:19:41,467:INFO:             kaleido: 0.2.1
2025-04-19 20:19:41,467:INFO:           schemdraw: 0.15
2025-04-19 20:19:41,467:INFO:         statsmodels: 0.14.4
2025-04-19 20:19:41,467:INFO:              sktime: 0.21.1
2025-04-19 20:19:41,467:INFO:               tbats: 1.1.3
2025-04-19 20:19:41,467:INFO:            pmdarima: 2.0.4
2025-04-19 20:19:41,467:INFO:              psutil: 7.0.0
2025-04-19 20:19:41,467:INFO:          markupsafe: 3.0.2
2025-04-19 20:19:41,467:INFO:             pickle5: Not installed
2025-04-19 20:19:41,467:INFO:         cloudpickle: 3.1.1
2025-04-19 20:19:41,467:INFO:         deprecation: 2.1.0
2025-04-19 20:19:41,467:INFO:              xxhash: 3.5.0
2025-04-19 20:19:41,467:INFO:           wurlitzer: Not installed
2025-04-19 20:19:41,467:INFO:PyCaret optional dependencies:
2025-04-19 20:19:41,667:INFO:                shap: Not installed
2025-04-19 20:19:41,667:INFO:           interpret: Not installed
2025-04-19 20:19:41,667:INFO:                umap: Not installed
2025-04-19 20:19:41,667:INFO:    pandas_profiling: Not installed
2025-04-19 20:19:41,667:INFO:  explainerdashboard: Not installed
2025-04-19 20:19:41,667:INFO:             autoviz: Not installed
2025-04-19 20:19:41,667:INFO:           fairlearn: Not installed
2025-04-19 20:19:41,667:INFO:          deepchecks: Not installed
2025-04-19 20:19:41,667:INFO:             xgboost: Not installed
2025-04-19 20:19:41,667:INFO:            catboost: Not installed
2025-04-19 20:19:41,667:INFO:              kmodes: Not installed
2025-04-19 20:19:41,667:INFO:             mlxtend: Not installed
2025-04-19 20:19:41,667:INFO:       statsforecast: Not installed
2025-04-19 20:19:41,667:INFO:        tune_sklearn: Not installed
2025-04-19 20:19:41,667:INFO:                 ray: Not installed
2025-04-19 20:19:41,667:INFO:            hyperopt: Not installed
2025-04-19 20:19:41,667:INFO:              optuna: Not installed
2025-04-19 20:19:41,667:INFO:               skopt: Not installed
2025-04-19 20:19:41,667:INFO:              mlflow: 2.21.3
2025-04-19 20:19:41,667:INFO:              gradio: Not installed
2025-04-19 20:19:41,667:INFO:             fastapi: 0.115.12
2025-04-19 20:19:41,667:INFO:             uvicorn: 0.34.2
2025-04-19 20:19:41,667:INFO:              m2cgen: Not installed
2025-04-19 20:19:41,667:INFO:           evidently: Not installed
2025-04-19 20:19:41,667:INFO:               fugue: Not installed
2025-04-19 20:19:41,667:INFO:           streamlit: Not installed
2025-04-19 20:19:41,667:INFO:             prophet: Not installed
2025-04-19 20:19:41,667:INFO:None
2025-04-19 20:19:41,667:INFO:Set up data.
2025-04-19 20:19:41,667:INFO:Set up train/test split.
2025-04-19 20:19:41,681:INFO:Set up index.
2025-04-19 20:19:41,681:INFO:Set up folding strategy.
2025-04-19 20:19:41,681:INFO:Assigning column types.
2025-04-19 20:19:41,684:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:19:41,684:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,684:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,767:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,767:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,858:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:19:41,868:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,874:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:41,953:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:19:41,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,039:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:19:42,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,227:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:19:42,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,452:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:19:42,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:19:42,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,663:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:19:42,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:42,843:INFO:Preparing preprocessing pipeline...
2025-04-19 20:19:42,843:INFO:Set up target transformation.
2025-04-19 20:19:42,843:INFO:Set up simple imputation.
2025-04-19 20:19:42,843:INFO:Set up removing multicollinearity.
2025-04-19 20:19:42,843:INFO:Set up removing outliers.
2025-04-19 20:19:42,843:INFO:Set up feature normalization.
2025-04-19 20:19:42,988:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:43,285:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:19:43,300:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:19:43,300:INFO:Creating final display dataframe.
2025-04-19 20:19:43,500:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:43,959:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 5)
4        Transformed data shape     (7719, 5)
5   Transformed train set shape     (5319, 5)
6    Transformed test set shape     (2400, 5)
7              Numeric features             4
8      Rows with missing values          7.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          8914
2025-04-19 20:19:44,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:44,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:44,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:44,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 20:19:44,145:INFO:setup() successfully completed in 2.84s...............
2025-04-19 20:19:44,145:INFO:Initializing compare_models()
2025-04-19 20:19:44,145:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 20:19:44,145:INFO:Checking exceptions
2025-04-19 20:19:44,145:INFO:Preparing display monitor
2025-04-19 20:19:44,145:INFO:Initializing Linear Regression
2025-04-19 20:19:44,145:INFO:Total runtime is 0.0 minutes
2025-04-19 20:19:44,145:INFO:SubProcess create_model() called ==================================
2025-04-19 20:19:44,145:INFO:Initializing create_model()
2025-04-19 20:19:44,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:19:44,145:INFO:Checking exceptions
2025-04-19 20:19:44,145:INFO:Importing libraries
2025-04-19 20:19:44,145:INFO:Copying training dataset
2025-04-19 20:19:44,155:INFO:Defining folds
2025-04-19 20:19:44,157:INFO:Declaring metric variables
2025-04-19 20:19:44,157:INFO:Importing untrained model
2025-04-19 20:19:44,157:INFO:Linear Regression Imported successfully
2025-04-19 20:19:44,157:INFO:Starting cross validation
2025-04-19 20:19:44,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:19:49,266:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,313:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,321:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,353:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,379:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,532:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,670:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:49,811:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:50,630:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:50,685:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:19:51,746:INFO:Calculating mean and std
2025-04-19 20:19:51,747:INFO:Creating metrics dataframe
2025-04-19 20:19:51,979:INFO:Uploading results into container
2025-04-19 20:19:51,980:INFO:Uploading model into container now
2025-04-19 20:19:51,981:INFO:_master_model_container: 1
2025-04-19 20:19:51,981:INFO:_display_container: 2
2025-04-19 20:19:51,981:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:19:51,981:INFO:create_model() successfully completed......................................
2025-04-19 20:19:52,149:INFO:SubProcess create_model() end ==================================
2025-04-19 20:19:52,149:INFO:Creating metrics dataframe
2025-04-19 20:19:52,155:INFO:Initializing Lasso Regression
2025-04-19 20:19:52,155:INFO:Total runtime is 0.13350407679875692 minutes
2025-04-19 20:19:52,155:INFO:SubProcess create_model() called ==================================
2025-04-19 20:19:52,156:INFO:Initializing create_model()
2025-04-19 20:19:52,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:19:52,156:INFO:Checking exceptions
2025-04-19 20:19:52,156:INFO:Importing libraries
2025-04-19 20:19:52,156:INFO:Copying training dataset
2025-04-19 20:19:52,161:INFO:Defining folds
2025-04-19 20:19:52,161:INFO:Declaring metric variables
2025-04-19 20:19:52,161:INFO:Importing untrained model
2025-04-19 20:19:52,162:INFO:Lasso Regression Imported successfully
2025-04-19 20:19:52,162:INFO:Starting cross validation
2025-04-19 20:19:52,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:19:53,703:INFO:Calculating mean and std
2025-04-19 20:19:53,703:INFO:Creating metrics dataframe
2025-04-19 20:19:53,897:INFO:Uploading results into container
2025-04-19 20:19:53,897:INFO:Uploading model into container now
2025-04-19 20:19:53,897:INFO:_master_model_container: 2
2025-04-19 20:19:53,897:INFO:_display_container: 2
2025-04-19 20:19:53,897:INFO:Lasso(random_state=42)
2025-04-19 20:19:53,897:INFO:create_model() successfully completed......................................
2025-04-19 20:19:54,122:INFO:SubProcess create_model() end ==================================
2025-04-19 20:19:54,122:INFO:Creating metrics dataframe
2025-04-19 20:19:54,122:INFO:Initializing Ridge Regression
2025-04-19 20:19:54,122:INFO:Total runtime is 0.16628328561782837 minutes
2025-04-19 20:19:54,122:INFO:SubProcess create_model() called ==================================
2025-04-19 20:19:54,122:INFO:Initializing create_model()
2025-04-19 20:19:54,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:19:54,122:INFO:Checking exceptions
2025-04-19 20:19:54,122:INFO:Importing libraries
2025-04-19 20:19:54,122:INFO:Copying training dataset
2025-04-19 20:19:54,122:INFO:Defining folds
2025-04-19 20:19:54,122:INFO:Declaring metric variables
2025-04-19 20:19:54,122:INFO:Importing untrained model
2025-04-19 20:19:54,122:INFO:Ridge Regression Imported successfully
2025-04-19 20:19:54,122:INFO:Starting cross validation
2025-04-19 20:19:54,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:19:55,625:INFO:Calculating mean and std
2025-04-19 20:19:55,625:INFO:Creating metrics dataframe
2025-04-19 20:19:55,885:INFO:Uploading results into container
2025-04-19 20:19:55,886:INFO:Uploading model into container now
2025-04-19 20:19:55,887:INFO:_master_model_container: 3
2025-04-19 20:19:55,887:INFO:_display_container: 2
2025-04-19 20:19:55,887:INFO:Ridge(random_state=42)
2025-04-19 20:19:55,887:INFO:create_model() successfully completed......................................
2025-04-19 20:19:56,003:INFO:SubProcess create_model() end ==================================
2025-04-19 20:19:56,003:INFO:Creating metrics dataframe
2025-04-19 20:19:56,010:INFO:Initializing Elastic Net
2025-04-19 20:19:56,010:INFO:Total runtime is 0.19774169127146404 minutes
2025-04-19 20:19:56,010:INFO:SubProcess create_model() called ==================================
2025-04-19 20:19:56,011:INFO:Initializing create_model()
2025-04-19 20:19:56,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:19:56,011:INFO:Checking exceptions
2025-04-19 20:19:56,011:INFO:Importing libraries
2025-04-19 20:19:56,011:INFO:Copying training dataset
2025-04-19 20:19:56,016:INFO:Defining folds
2025-04-19 20:19:56,017:INFO:Declaring metric variables
2025-04-19 20:19:56,017:INFO:Importing untrained model
2025-04-19 20:19:56,017:INFO:Elastic Net Imported successfully
2025-04-19 20:19:56,017:INFO:Starting cross validation
2025-04-19 20:19:56,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:19:57,838:INFO:Calculating mean and std
2025-04-19 20:19:57,838:INFO:Creating metrics dataframe
2025-04-19 20:19:58,088:INFO:Uploading results into container
2025-04-19 20:19:58,088:INFO:Uploading model into container now
2025-04-19 20:19:58,089:INFO:_master_model_container: 4
2025-04-19 20:19:58,089:INFO:_display_container: 2
2025-04-19 20:19:58,089:INFO:ElasticNet(random_state=42)
2025-04-19 20:19:58,089:INFO:create_model() successfully completed......................................
2025-04-19 20:19:58,218:INFO:SubProcess create_model() end ==================================
2025-04-19 20:19:58,218:INFO:Creating metrics dataframe
2025-04-19 20:19:58,222:INFO:Initializing Least Angle Regression
2025-04-19 20:19:58,223:INFO:Total runtime is 0.2346284826596578 minutes
2025-04-19 20:19:58,223:INFO:SubProcess create_model() called ==================================
2025-04-19 20:19:58,223:INFO:Initializing create_model()
2025-04-19 20:19:58,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:19:58,223:INFO:Checking exceptions
2025-04-19 20:19:58,223:INFO:Importing libraries
2025-04-19 20:19:58,223:INFO:Copying training dataset
2025-04-19 20:19:58,225:INFO:Defining folds
2025-04-19 20:19:58,225:INFO:Declaring metric variables
2025-04-19 20:19:58,225:INFO:Importing untrained model
2025-04-19 20:19:58,225:INFO:Least Angle Regression Imported successfully
2025-04-19 20:19:58,225:INFO:Starting cross validation
2025-04-19 20:19:58,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:00,039:INFO:Calculating mean and std
2025-04-19 20:20:00,046:INFO:Creating metrics dataframe
2025-04-19 20:20:00,261:INFO:Uploading results into container
2025-04-19 20:20:00,261:INFO:Uploading model into container now
2025-04-19 20:20:00,261:INFO:_master_model_container: 5
2025-04-19 20:20:00,261:INFO:_display_container: 2
2025-04-19 20:20:00,261:INFO:Lars(random_state=42)
2025-04-19 20:20:00,261:INFO:create_model() successfully completed......................................
2025-04-19 20:20:00,405:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:00,405:INFO:Creating metrics dataframe
2025-04-19 20:20:00,411:INFO:Initializing Lasso Least Angle Regression
2025-04-19 20:20:00,411:INFO:Total runtime is 0.2710922837257385 minutes
2025-04-19 20:20:00,411:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:00,411:INFO:Initializing create_model()
2025-04-19 20:20:00,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:00,411:INFO:Checking exceptions
2025-04-19 20:20:00,411:INFO:Importing libraries
2025-04-19 20:20:00,411:INFO:Copying training dataset
2025-04-19 20:20:00,419:INFO:Defining folds
2025-04-19 20:20:00,419:INFO:Declaring metric variables
2025-04-19 20:20:00,420:INFO:Importing untrained model
2025-04-19 20:20:00,420:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 20:20:00,420:INFO:Starting cross validation
2025-04-19 20:20:00,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:02,233:INFO:Calculating mean and std
2025-04-19 20:20:02,233:INFO:Creating metrics dataframe
2025-04-19 20:20:02,503:INFO:Uploading results into container
2025-04-19 20:20:02,504:INFO:Uploading model into container now
2025-04-19 20:20:02,504:INFO:_master_model_container: 6
2025-04-19 20:20:02,505:INFO:_display_container: 2
2025-04-19 20:20:02,505:INFO:LassoLars(random_state=42)
2025-04-19 20:20:02,505:INFO:create_model() successfully completed......................................
2025-04-19 20:20:02,630:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:02,630:INFO:Creating metrics dataframe
2025-04-19 20:20:02,634:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 20:20:02,634:INFO:Total runtime is 0.30814765294392904 minutes
2025-04-19 20:20:02,635:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:02,635:INFO:Initializing create_model()
2025-04-19 20:20:02,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:02,635:INFO:Checking exceptions
2025-04-19 20:20:02,635:INFO:Importing libraries
2025-04-19 20:20:02,635:INFO:Copying training dataset
2025-04-19 20:20:02,639:INFO:Defining folds
2025-04-19 20:20:02,640:INFO:Declaring metric variables
2025-04-19 20:20:02,640:INFO:Importing untrained model
2025-04-19 20:20:02,640:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 20:20:02,640:INFO:Starting cross validation
2025-04-19 20:20:02,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:04,393:INFO:Calculating mean and std
2025-04-19 20:20:04,394:INFO:Creating metrics dataframe
2025-04-19 20:20:04,653:INFO:Uploading results into container
2025-04-19 20:20:04,654:INFO:Uploading model into container now
2025-04-19 20:20:04,655:INFO:_master_model_container: 7
2025-04-19 20:20:04,655:INFO:_display_container: 2
2025-04-19 20:20:04,655:INFO:OrthogonalMatchingPursuit()
2025-04-19 20:20:04,655:INFO:create_model() successfully completed......................................
2025-04-19 20:20:04,783:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:04,783:INFO:Creating metrics dataframe
2025-04-19 20:20:04,790:INFO:Initializing Bayesian Ridge
2025-04-19 20:20:04,790:INFO:Total runtime is 0.34407647053400675 minutes
2025-04-19 20:20:04,790:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:04,790:INFO:Initializing create_model()
2025-04-19 20:20:04,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:04,791:INFO:Checking exceptions
2025-04-19 20:20:04,791:INFO:Importing libraries
2025-04-19 20:20:04,791:INFO:Copying training dataset
2025-04-19 20:20:04,792:INFO:Defining folds
2025-04-19 20:20:04,792:INFO:Declaring metric variables
2025-04-19 20:20:04,792:INFO:Importing untrained model
2025-04-19 20:20:04,792:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:20:04,792:INFO:Starting cross validation
2025-04-19 20:20:04,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:06,524:INFO:Calculating mean and std
2025-04-19 20:20:06,531:INFO:Creating metrics dataframe
2025-04-19 20:20:06,771:INFO:Uploading results into container
2025-04-19 20:20:06,773:INFO:Uploading model into container now
2025-04-19 20:20:06,774:INFO:_master_model_container: 8
2025-04-19 20:20:06,774:INFO:_display_container: 2
2025-04-19 20:20:06,774:INFO:BayesianRidge()
2025-04-19 20:20:06,774:INFO:create_model() successfully completed......................................
2025-04-19 20:20:06,891:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:06,891:INFO:Creating metrics dataframe
2025-04-19 20:20:06,891:INFO:Initializing Passive Aggressive Regressor
2025-04-19 20:20:06,891:INFO:Total runtime is 0.3791060249010722 minutes
2025-04-19 20:20:06,891:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:06,891:INFO:Initializing create_model()
2025-04-19 20:20:06,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:06,891:INFO:Checking exceptions
2025-04-19 20:20:06,891:INFO:Importing libraries
2025-04-19 20:20:06,891:INFO:Copying training dataset
2025-04-19 20:20:06,902:INFO:Defining folds
2025-04-19 20:20:06,902:INFO:Declaring metric variables
2025-04-19 20:20:06,902:INFO:Importing untrained model
2025-04-19 20:20:06,902:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 20:20:06,902:INFO:Starting cross validation
2025-04-19 20:20:06,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:08,646:INFO:Calculating mean and std
2025-04-19 20:20:08,646:INFO:Creating metrics dataframe
2025-04-19 20:20:08,884:INFO:Uploading results into container
2025-04-19 20:20:08,884:INFO:Uploading model into container now
2025-04-19 20:20:08,884:INFO:_master_model_container: 9
2025-04-19 20:20:08,884:INFO:_display_container: 2
2025-04-19 20:20:08,884:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 20:20:08,884:INFO:create_model() successfully completed......................................
2025-04-19 20:20:08,976:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:08,976:INFO:Creating metrics dataframe
2025-04-19 20:20:08,985:INFO:Initializing Huber Regressor
2025-04-19 20:20:08,985:INFO:Total runtime is 0.4140003879865011 minutes
2025-04-19 20:20:08,985:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:08,985:INFO:Initializing create_model()
2025-04-19 20:20:08,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:08,985:INFO:Checking exceptions
2025-04-19 20:20:08,985:INFO:Importing libraries
2025-04-19 20:20:08,985:INFO:Copying training dataset
2025-04-19 20:20:08,989:INFO:Defining folds
2025-04-19 20:20:08,989:INFO:Declaring metric variables
2025-04-19 20:20:08,989:INFO:Importing untrained model
2025-04-19 20:20:08,989:INFO:Huber Regressor Imported successfully
2025-04-19 20:20:08,989:INFO:Starting cross validation
2025-04-19 20:20:08,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:10,595:INFO:Calculating mean and std
2025-04-19 20:20:10,595:INFO:Creating metrics dataframe
2025-04-19 20:20:10,807:INFO:Uploading results into container
2025-04-19 20:20:10,807:INFO:Uploading model into container now
2025-04-19 20:20:10,807:INFO:_master_model_container: 10
2025-04-19 20:20:10,807:INFO:_display_container: 2
2025-04-19 20:20:10,807:INFO:HuberRegressor()
2025-04-19 20:20:10,807:INFO:create_model() successfully completed......................................
2025-04-19 20:20:10,904:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:10,904:INFO:Creating metrics dataframe
2025-04-19 20:20:10,909:INFO:Initializing K Neighbors Regressor
2025-04-19 20:20:10,909:INFO:Total runtime is 0.446060053507487 minutes
2025-04-19 20:20:10,909:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:10,909:INFO:Initializing create_model()
2025-04-19 20:20:10,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:10,909:INFO:Checking exceptions
2025-04-19 20:20:10,909:INFO:Importing libraries
2025-04-19 20:20:10,909:INFO:Copying training dataset
2025-04-19 20:20:10,910:INFO:Defining folds
2025-04-19 20:20:10,910:INFO:Declaring metric variables
2025-04-19 20:20:10,910:INFO:Importing untrained model
2025-04-19 20:20:10,910:INFO:K Neighbors Regressor Imported successfully
2025-04-19 20:20:10,910:INFO:Starting cross validation
2025-04-19 20:20:10,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:12,463:INFO:Calculating mean and std
2025-04-19 20:20:12,465:INFO:Creating metrics dataframe
2025-04-19 20:20:12,676:INFO:Uploading results into container
2025-04-19 20:20:12,676:INFO:Uploading model into container now
2025-04-19 20:20:12,676:INFO:_master_model_container: 11
2025-04-19 20:20:12,676:INFO:_display_container: 2
2025-04-19 20:20:12,676:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 20:20:12,676:INFO:create_model() successfully completed......................................
2025-04-19 20:20:12,761:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:12,761:INFO:Creating metrics dataframe
2025-04-19 20:20:12,777:INFO:Initializing Decision Tree Regressor
2025-04-19 20:20:12,777:INFO:Total runtime is 0.47719975312550866 minutes
2025-04-19 20:20:12,777:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:12,777:INFO:Initializing create_model()
2025-04-19 20:20:12,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:12,777:INFO:Checking exceptions
2025-04-19 20:20:12,777:INFO:Importing libraries
2025-04-19 20:20:12,777:INFO:Copying training dataset
2025-04-19 20:20:12,777:INFO:Defining folds
2025-04-19 20:20:12,777:INFO:Declaring metric variables
2025-04-19 20:20:12,784:INFO:Importing untrained model
2025-04-19 20:20:12,784:INFO:Decision Tree Regressor Imported successfully
2025-04-19 20:20:12,784:INFO:Starting cross validation
2025-04-19 20:20:12,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:14,338:INFO:Calculating mean and std
2025-04-19 20:20:14,338:INFO:Creating metrics dataframe
2025-04-19 20:20:14,550:INFO:Uploading results into container
2025-04-19 20:20:14,550:INFO:Uploading model into container now
2025-04-19 20:20:14,550:INFO:_master_model_container: 12
2025-04-19 20:20:14,550:INFO:_display_container: 2
2025-04-19 20:20:14,550:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 20:20:14,550:INFO:create_model() successfully completed......................................
2025-04-19 20:20:14,646:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:14,646:INFO:Creating metrics dataframe
2025-04-19 20:20:14,650:INFO:Initializing Random Forest Regressor
2025-04-19 20:20:14,650:INFO:Total runtime is 0.5084080696105957 minutes
2025-04-19 20:20:14,650:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:14,651:INFO:Initializing create_model()
2025-04-19 20:20:14,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:14,651:INFO:Checking exceptions
2025-04-19 20:20:14,651:INFO:Importing libraries
2025-04-19 20:20:14,651:INFO:Copying training dataset
2025-04-19 20:20:14,651:INFO:Defining folds
2025-04-19 20:20:14,651:INFO:Declaring metric variables
2025-04-19 20:20:14,651:INFO:Importing untrained model
2025-04-19 20:20:14,651:INFO:Random Forest Regressor Imported successfully
2025-04-19 20:20:14,651:INFO:Starting cross validation
2025-04-19 20:20:14,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:17,944:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:20:18,259:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:20:18,572:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:20:19,480:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 20:20:22,059:INFO:Calculating mean and std
2025-04-19 20:20:22,059:INFO:Creating metrics dataframe
2025-04-19 20:20:22,263:INFO:Uploading results into container
2025-04-19 20:20:22,263:INFO:Uploading model into container now
2025-04-19 20:20:22,263:INFO:_master_model_container: 13
2025-04-19 20:20:22,263:INFO:_display_container: 2
2025-04-19 20:20:22,263:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:20:22,263:INFO:create_model() successfully completed......................................
2025-04-19 20:20:22,363:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:22,363:INFO:Creating metrics dataframe
2025-04-19 20:20:22,367:INFO:Initializing Extra Trees Regressor
2025-04-19 20:20:22,367:INFO:Total runtime is 0.6370408733685812 minutes
2025-04-19 20:20:22,367:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:22,367:INFO:Initializing create_model()
2025-04-19 20:20:22,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:22,367:INFO:Checking exceptions
2025-04-19 20:20:22,367:INFO:Importing libraries
2025-04-19 20:20:22,367:INFO:Copying training dataset
2025-04-19 20:20:22,372:INFO:Defining folds
2025-04-19 20:20:22,372:INFO:Declaring metric variables
2025-04-19 20:20:22,372:INFO:Importing untrained model
2025-04-19 20:20:22,372:INFO:Extra Trees Regressor Imported successfully
2025-04-19 20:20:22,372:INFO:Starting cross validation
2025-04-19 20:20:22,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:24,040:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:20:24,040:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:20:26,301:INFO:Calculating mean and std
2025-04-19 20:20:26,302:INFO:Creating metrics dataframe
2025-04-19 20:20:26,513:INFO:Uploading results into container
2025-04-19 20:20:26,516:INFO:Uploading model into container now
2025-04-19 20:20:26,516:INFO:_master_model_container: 14
2025-04-19 20:20:26,516:INFO:_display_container: 2
2025-04-19 20:20:26,516:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:20:26,516:INFO:create_model() successfully completed......................................
2025-04-19 20:20:26,599:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:26,599:INFO:Creating metrics dataframe
2025-04-19 20:20:26,615:INFO:Initializing AdaBoost Regressor
2025-04-19 20:20:26,615:INFO:Total runtime is 0.7078288594881694 minutes
2025-04-19 20:20:26,615:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:26,615:INFO:Initializing create_model()
2025-04-19 20:20:26,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:26,615:INFO:Checking exceptions
2025-04-19 20:20:26,615:INFO:Importing libraries
2025-04-19 20:20:26,615:INFO:Copying training dataset
2025-04-19 20:20:26,619:INFO:Defining folds
2025-04-19 20:20:26,619:INFO:Declaring metric variables
2025-04-19 20:20:26,619:INFO:Importing untrained model
2025-04-19 20:20:26,619:INFO:AdaBoost Regressor Imported successfully
2025-04-19 20:20:26,619:INFO:Starting cross validation
2025-04-19 20:20:26,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:28,448:INFO:Calculating mean and std
2025-04-19 20:20:28,448:INFO:Creating metrics dataframe
2025-04-19 20:20:28,684:INFO:Uploading results into container
2025-04-19 20:20:28,684:INFO:Uploading model into container now
2025-04-19 20:20:28,687:INFO:_master_model_container: 15
2025-04-19 20:20:28,687:INFO:_display_container: 2
2025-04-19 20:20:28,687:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 20:20:28,687:INFO:create_model() successfully completed......................................
2025-04-19 20:20:28,799:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:28,799:INFO:Creating metrics dataframe
2025-04-19 20:20:28,806:INFO:Initializing Gradient Boosting Regressor
2025-04-19 20:20:28,807:INFO:Total runtime is 0.7443660577138266 minutes
2025-04-19 20:20:28,808:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:28,808:INFO:Initializing create_model()
2025-04-19 20:20:28,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:28,808:INFO:Checking exceptions
2025-04-19 20:20:28,808:INFO:Importing libraries
2025-04-19 20:20:28,808:INFO:Copying training dataset
2025-04-19 20:20:28,812:INFO:Defining folds
2025-04-19 20:20:28,812:INFO:Declaring metric variables
2025-04-19 20:20:28,812:INFO:Importing untrained model
2025-04-19 20:20:28,812:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 20:20:28,813:INFO:Starting cross validation
2025-04-19 20:20:28,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:31,683:INFO:Calculating mean and std
2025-04-19 20:20:31,683:INFO:Creating metrics dataframe
2025-04-19 20:20:31,900:INFO:Uploading results into container
2025-04-19 20:20:31,900:INFO:Uploading model into container now
2025-04-19 20:20:31,900:INFO:_master_model_container: 16
2025-04-19 20:20:31,900:INFO:_display_container: 2
2025-04-19 20:20:31,900:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 20:20:31,900:INFO:create_model() successfully completed......................................
2025-04-19 20:20:32,003:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:32,003:INFO:Creating metrics dataframe
2025-04-19 20:20:32,003:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 20:20:32,003:INFO:Total runtime is 0.7976351102193198 minutes
2025-04-19 20:20:32,003:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:32,003:INFO:Initializing create_model()
2025-04-19 20:20:32,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:32,003:INFO:Checking exceptions
2025-04-19 20:20:32,003:INFO:Importing libraries
2025-04-19 20:20:32,003:INFO:Copying training dataset
2025-04-19 20:20:32,019:INFO:Defining folds
2025-04-19 20:20:32,019:INFO:Declaring metric variables
2025-04-19 20:20:32,020:INFO:Importing untrained model
2025-04-19 20:20:32,020:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:20:32,021:INFO:Starting cross validation
2025-04-19 20:20:32,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:34,602:INFO:Calculating mean and std
2025-04-19 20:20:34,602:INFO:Creating metrics dataframe
2025-04-19 20:20:34,844:INFO:Uploading results into container
2025-04-19 20:20:34,844:INFO:Uploading model into container now
2025-04-19 20:20:34,844:INFO:_master_model_container: 17
2025-04-19 20:20:34,844:INFO:_display_container: 2
2025-04-19 20:20:34,846:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:20:34,846:INFO:create_model() successfully completed......................................
2025-04-19 20:20:34,933:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:34,933:INFO:Creating metrics dataframe
2025-04-19 20:20:34,933:INFO:Initializing Dummy Regressor
2025-04-19 20:20:34,933:INFO:Total runtime is 0.8464697003364564 minutes
2025-04-19 20:20:34,933:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:34,933:INFO:Initializing create_model()
2025-04-19 20:20:34,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952BA7FF10>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:34,933:INFO:Checking exceptions
2025-04-19 20:20:34,933:INFO:Importing libraries
2025-04-19 20:20:34,933:INFO:Copying training dataset
2025-04-19 20:20:34,947:INFO:Defining folds
2025-04-19 20:20:34,947:INFO:Declaring metric variables
2025-04-19 20:20:34,947:INFO:Importing untrained model
2025-04-19 20:20:34,947:INFO:Dummy Regressor Imported successfully
2025-04-19 20:20:34,947:INFO:Starting cross validation
2025-04-19 20:20:34,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:36,652:INFO:Calculating mean and std
2025-04-19 20:20:36,652:INFO:Creating metrics dataframe
2025-04-19 20:20:36,896:INFO:Uploading results into container
2025-04-19 20:20:36,897:INFO:Uploading model into container now
2025-04-19 20:20:36,897:INFO:_master_model_container: 18
2025-04-19 20:20:36,898:INFO:_display_container: 2
2025-04-19 20:20:36,898:INFO:DummyRegressor()
2025-04-19 20:20:36,898:INFO:create_model() successfully completed......................................
2025-04-19 20:20:36,997:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:36,997:INFO:Creating metrics dataframe
2025-04-19 20:20:37,002:INFO:Initializing create_model()
2025-04-19 20:20:37,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:37,002:INFO:Checking exceptions
2025-04-19 20:20:37,002:INFO:Importing libraries
2025-04-19 20:20:37,002:INFO:Copying training dataset
2025-04-19 20:20:37,002:INFO:Defining folds
2025-04-19 20:20:37,002:INFO:Declaring metric variables
2025-04-19 20:20:37,002:INFO:Importing untrained model
2025-04-19 20:20:37,002:INFO:Declaring custom model
2025-04-19 20:20:37,002:INFO:Huber Regressor Imported successfully
2025-04-19 20:20:37,020:INFO:Cross validation set to False
2025-04-19 20:20:37,020:INFO:Fitting Model
2025-04-19 20:20:37,238:INFO:HuberRegressor()
2025-04-19 20:20:37,238:INFO:create_model() successfully completed......................................
2025-04-19 20:20:37,337:INFO:Initializing create_model()
2025-04-19 20:20:37,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:37,337:INFO:Checking exceptions
2025-04-19 20:20:37,337:INFO:Importing libraries
2025-04-19 20:20:37,337:INFO:Copying training dataset
2025-04-19 20:20:37,343:INFO:Defining folds
2025-04-19 20:20:37,343:INFO:Declaring metric variables
2025-04-19 20:20:37,343:INFO:Importing untrained model
2025-04-19 20:20:37,343:INFO:Declaring custom model
2025-04-19 20:20:37,343:INFO:Ridge Regression Imported successfully
2025-04-19 20:20:37,353:INFO:Cross validation set to False
2025-04-19 20:20:37,353:INFO:Fitting Model
2025-04-19 20:20:37,561:INFO:Ridge(random_state=42)
2025-04-19 20:20:37,561:INFO:create_model() successfully completed......................................
2025-04-19 20:20:37,641:INFO:Initializing create_model()
2025-04-19 20:20:37,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Lars(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:37,641:INFO:Checking exceptions
2025-04-19 20:20:37,641:INFO:Importing libraries
2025-04-19 20:20:37,641:INFO:Copying training dataset
2025-04-19 20:20:37,641:INFO:Defining folds
2025-04-19 20:20:37,641:INFO:Declaring metric variables
2025-04-19 20:20:37,657:INFO:Importing untrained model
2025-04-19 20:20:37,657:INFO:Declaring custom model
2025-04-19 20:20:37,657:INFO:Least Angle Regression Imported successfully
2025-04-19 20:20:37,657:INFO:Cross validation set to False
2025-04-19 20:20:37,657:INFO:Fitting Model
2025-04-19 20:20:37,834:INFO:Lars(random_state=42)
2025-04-19 20:20:37,834:INFO:create_model() successfully completed......................................
2025-04-19 20:20:37,940:INFO:_master_model_container: 18
2025-04-19 20:20:37,940:INFO:_display_container: 2
2025-04-19 20:20:37,940:INFO:[HuberRegressor(), Ridge(random_state=42), Lars(random_state=42)]
2025-04-19 20:20:37,943:INFO:compare_models() successfully completed......................................
2025-04-19 20:20:37,944:INFO:Initializing tune_model()
2025-04-19 20:20:37,944:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>)
2025-04-19 20:20:37,944:INFO:Checking exceptions
2025-04-19 20:20:37,944:INFO:Copying training dataset
2025-04-19 20:20:37,952:INFO:Checking base model
2025-04-19 20:20:37,952:INFO:Base model : Huber Regressor
2025-04-19 20:20:37,952:INFO:Declaring metric variables
2025-04-19 20:20:37,952:INFO:Defining Hyperparameters
2025-04-19 20:20:38,048:INFO:Tuning with n_jobs=-1
2025-04-19 20:20:38,048:INFO:Initializing RandomizedSearchCV
2025-04-19 20:20:55,697:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.3, 'actual_estimator__alpha': 0.3}
2025-04-19 20:20:55,706:INFO:Hyperparameter search completed
2025-04-19 20:20:55,706:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:55,706:INFO:Initializing create_model()
2025-04-19 20:20:55,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002951E10C3D0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.3, 'alpha': 0.3})
2025-04-19 20:20:55,706:INFO:Checking exceptions
2025-04-19 20:20:55,708:INFO:Importing libraries
2025-04-19 20:20:55,708:INFO:Copying training dataset
2025-04-19 20:20:55,723:INFO:Defining folds
2025-04-19 20:20:55,723:INFO:Declaring metric variables
2025-04-19 20:20:55,723:INFO:Importing untrained model
2025-04-19 20:20:55,723:INFO:Declaring custom model
2025-04-19 20:20:55,723:INFO:Huber Regressor Imported successfully
2025-04-19 20:20:55,723:INFO:Starting cross validation
2025-04-19 20:20:55,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:20:58,918:INFO:Calculating mean and std
2025-04-19 20:20:58,920:INFO:Creating metrics dataframe
2025-04-19 20:20:58,924:INFO:Finalizing model
2025-04-19 20:20:59,474:INFO:Uploading results into container
2025-04-19 20:20:59,474:INFO:Uploading model into container now
2025-04-19 20:20:59,478:INFO:_master_model_container: 19
2025-04-19 20:20:59,478:INFO:_display_container: 3
2025-04-19 20:20:59,478:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:20:59,478:INFO:create_model() successfully completed......................................
2025-04-19 20:20:59,625:INFO:SubProcess create_model() end ==================================
2025-04-19 20:20:59,625:INFO:choose_better activated
2025-04-19 20:20:59,627:INFO:SubProcess create_model() called ==================================
2025-04-19 20:20:59,627:INFO:Initializing create_model()
2025-04-19 20:20:59,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:20:59,627:INFO:Checking exceptions
2025-04-19 20:20:59,627:INFO:Importing libraries
2025-04-19 20:20:59,627:INFO:Copying training dataset
2025-04-19 20:20:59,633:INFO:Defining folds
2025-04-19 20:20:59,633:INFO:Declaring metric variables
2025-04-19 20:20:59,633:INFO:Importing untrained model
2025-04-19 20:20:59,633:INFO:Declaring custom model
2025-04-19 20:20:59,633:INFO:Huber Regressor Imported successfully
2025-04-19 20:20:59,633:INFO:Starting cross validation
2025-04-19 20:20:59,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:01,683:INFO:Calculating mean and std
2025-04-19 20:21:01,683:INFO:Creating metrics dataframe
2025-04-19 20:21:01,698:INFO:Finalizing model
2025-04-19 20:21:02,016:INFO:Uploading results into container
2025-04-19 20:21:02,016:INFO:Uploading model into container now
2025-04-19 20:21:02,016:INFO:_master_model_container: 20
2025-04-19 20:21:02,016:INFO:_display_container: 4
2025-04-19 20:21:02,016:INFO:HuberRegressor()
2025-04-19 20:21:02,016:INFO:create_model() successfully completed......................................
2025-04-19 20:21:02,117:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:02,117:INFO:HuberRegressor() result for R2 is 0.0006
2025-04-19 20:21:02,117:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) result for R2 is 0.0008
2025-04-19 20:21:02,117:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) is best model
2025-04-19 20:21:02,117:INFO:choose_better completed
2025-04-19 20:21:02,117:INFO:_master_model_container: 20
2025-04-19 20:21:02,117:INFO:_display_container: 3
2025-04-19 20:21:02,117:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:21:02,117:INFO:tune_model() successfully completed......................................
2025-04-19 20:21:02,395:INFO:Initializing tune_model()
2025-04-19 20:21:02,395:INFO:tune_model(estimator=Ridge(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>)
2025-04-19 20:21:02,395:INFO:Checking exceptions
2025-04-19 20:21:02,395:INFO:Copying training dataset
2025-04-19 20:21:02,395:INFO:Checking base model
2025-04-19 20:21:02,395:INFO:Base model : Ridge Regression
2025-04-19 20:21:02,395:INFO:Declaring metric variables
2025-04-19 20:21:02,395:INFO:Defining Hyperparameters
2025-04-19 20:21:02,497:INFO:Tuning with n_jobs=-1
2025-04-19 20:21:02,497:INFO:Initializing RandomizedSearchCV
2025-04-19 20:21:20,201:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 8.63}
2025-04-19 20:21:20,202:INFO:Hyperparameter search completed
2025-04-19 20:21:20,202:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:20,202:INFO:Initializing create_model()
2025-04-19 20:21:20,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952C64EE00>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'alpha': 8.63})
2025-04-19 20:21:20,202:INFO:Checking exceptions
2025-04-19 20:21:20,202:INFO:Importing libraries
2025-04-19 20:21:20,202:INFO:Copying training dataset
2025-04-19 20:21:20,206:INFO:Defining folds
2025-04-19 20:21:20,207:INFO:Declaring metric variables
2025-04-19 20:21:20,207:INFO:Importing untrained model
2025-04-19 20:21:20,207:INFO:Declaring custom model
2025-04-19 20:21:20,207:INFO:Ridge Regression Imported successfully
2025-04-19 20:21:20,207:INFO:Starting cross validation
2025-04-19 20:21:20,207:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:21,733:INFO:Calculating mean and std
2025-04-19 20:21:21,733:INFO:Creating metrics dataframe
2025-04-19 20:21:21,733:INFO:Finalizing model
2025-04-19 20:21:21,981:INFO:Uploading results into container
2025-04-19 20:21:21,986:INFO:Uploading model into container now
2025-04-19 20:21:21,986:INFO:_master_model_container: 21
2025-04-19 20:21:21,986:INFO:_display_container: 4
2025-04-19 20:21:21,986:INFO:Ridge(alpha=8.63, random_state=42)
2025-04-19 20:21:21,986:INFO:create_model() successfully completed......................................
2025-04-19 20:21:22,071:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:22,071:INFO:choose_better activated
2025-04-19 20:21:22,071:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:22,071:INFO:Initializing create_model()
2025-04-19 20:21:22,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Ridge(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:21:22,073:INFO:Checking exceptions
2025-04-19 20:21:22,073:INFO:Importing libraries
2025-04-19 20:21:22,073:INFO:Copying training dataset
2025-04-19 20:21:22,075:INFO:Defining folds
2025-04-19 20:21:22,075:INFO:Declaring metric variables
2025-04-19 20:21:22,075:INFO:Importing untrained model
2025-04-19 20:21:22,075:INFO:Declaring custom model
2025-04-19 20:21:22,075:INFO:Ridge Regression Imported successfully
2025-04-19 20:21:22,075:INFO:Starting cross validation
2025-04-19 20:21:22,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:23,588:INFO:Calculating mean and std
2025-04-19 20:21:23,588:INFO:Creating metrics dataframe
2025-04-19 20:21:23,588:INFO:Finalizing model
2025-04-19 20:21:23,888:INFO:Uploading results into container
2025-04-19 20:21:23,888:INFO:Uploading model into container now
2025-04-19 20:21:23,888:INFO:_master_model_container: 22
2025-04-19 20:21:23,888:INFO:_display_container: 5
2025-04-19 20:21:23,888:INFO:Ridge(random_state=42)
2025-04-19 20:21:23,888:INFO:create_model() successfully completed......................................
2025-04-19 20:21:23,976:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:23,976:INFO:Ridge(random_state=42) result for R2 is -0.0052
2025-04-19 20:21:23,976:INFO:Ridge(alpha=8.63, random_state=42) result for R2 is -0.0052
2025-04-19 20:21:23,976:INFO:Ridge(random_state=42) is best model
2025-04-19 20:21:23,976:INFO:choose_better completed
2025-04-19 20:21:23,976:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:21:23,980:INFO:_master_model_container: 22
2025-04-19 20:21:23,980:INFO:_display_container: 4
2025-04-19 20:21:23,980:INFO:Ridge(random_state=42)
2025-04-19 20:21:23,980:INFO:tune_model() successfully completed......................................
2025-04-19 20:21:24,204:INFO:Initializing tune_model()
2025-04-19 20:21:24,204:INFO:tune_model(estimator=Lars(random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>)
2025-04-19 20:21:24,204:INFO:Checking exceptions
2025-04-19 20:21:24,209:INFO:Copying training dataset
2025-04-19 20:21:24,209:INFO:Checking base model
2025-04-19 20:21:24,209:INFO:Base model : Least Angle Regression
2025-04-19 20:21:24,209:INFO:Declaring metric variables
2025-04-19 20:21:24,209:INFO:Defining Hyperparameters
2025-04-19 20:21:24,292:INFO:Tuning with n_jobs=-1
2025-04-19 20:21:24,292:INFO:Initializing RandomizedSearchCV
2025-04-19 20:21:41,002:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__eps': 0.0001}
2025-04-19 20:21:41,003:INFO:Hyperparameter search completed
2025-04-19 20:21:41,003:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:41,004:INFO:Initializing create_model()
2025-04-19 20:21:41,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Lars(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002952CB7BAF0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'eps': 0.0001})
2025-04-19 20:21:41,004:INFO:Checking exceptions
2025-04-19 20:21:41,004:INFO:Importing libraries
2025-04-19 20:21:41,004:INFO:Copying training dataset
2025-04-19 20:21:41,054:INFO:Defining folds
2025-04-19 20:21:41,054:INFO:Declaring metric variables
2025-04-19 20:21:41,054:INFO:Importing untrained model
2025-04-19 20:21:41,054:INFO:Declaring custom model
2025-04-19 20:21:41,055:INFO:Least Angle Regression Imported successfully
2025-04-19 20:21:41,055:INFO:Starting cross validation
2025-04-19 20:21:41,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:42,726:INFO:Calculating mean and std
2025-04-19 20:21:42,727:INFO:Creating metrics dataframe
2025-04-19 20:21:42,729:INFO:Finalizing model
2025-04-19 20:21:43,004:INFO:Uploading results into container
2025-04-19 20:21:43,004:INFO:Uploading model into container now
2025-04-19 20:21:43,004:INFO:_master_model_container: 23
2025-04-19 20:21:43,004:INFO:_display_container: 5
2025-04-19 20:21:43,004:INFO:Lars(eps=0.0001, random_state=42)
2025-04-19 20:21:43,004:INFO:create_model() successfully completed......................................
2025-04-19 20:21:43,113:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:43,113:INFO:choose_better activated
2025-04-19 20:21:43,114:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:43,114:INFO:Initializing create_model()
2025-04-19 20:21:43,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Lars(random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:21:43,115:INFO:Checking exceptions
2025-04-19 20:21:43,118:INFO:Importing libraries
2025-04-19 20:21:43,118:INFO:Copying training dataset
2025-04-19 20:21:43,118:INFO:Defining folds
2025-04-19 20:21:43,118:INFO:Declaring metric variables
2025-04-19 20:21:43,118:INFO:Importing untrained model
2025-04-19 20:21:43,118:INFO:Declaring custom model
2025-04-19 20:21:43,118:INFO:Least Angle Regression Imported successfully
2025-04-19 20:21:43,118:INFO:Starting cross validation
2025-04-19 20:21:43,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:44,800:INFO:Calculating mean and std
2025-04-19 20:21:44,801:INFO:Creating metrics dataframe
2025-04-19 20:21:44,803:INFO:Finalizing model
2025-04-19 20:21:45,079:INFO:Uploading results into container
2025-04-19 20:21:45,079:INFO:Uploading model into container now
2025-04-19 20:21:45,079:INFO:_master_model_container: 24
2025-04-19 20:21:45,079:INFO:_display_container: 6
2025-04-19 20:21:45,079:INFO:Lars(random_state=42)
2025-04-19 20:21:45,079:INFO:create_model() successfully completed......................................
2025-04-19 20:21:45,165:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:45,165:INFO:Lars(random_state=42) result for R2 is -0.0052
2025-04-19 20:21:45,165:INFO:Lars(eps=0.0001, random_state=42) result for R2 is -0.0052
2025-04-19 20:21:45,165:INFO:Lars(random_state=42) is best model
2025-04-19 20:21:45,165:INFO:choose_better completed
2025-04-19 20:21:45,165:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:21:45,184:INFO:_master_model_container: 24
2025-04-19 20:21:45,184:INFO:_display_container: 5
2025-04-19 20:21:45,184:INFO:Lars(random_state=42)
2025-04-19 20:21:45,184:INFO:tune_model() successfully completed......................................
2025-04-19 20:21:45,417:INFO:Initializing blend_models()
2025-04-19 20:21:45,417:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), Ridge(random_state=42), Lars(random_state=42)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:21:45,417:INFO:Checking exceptions
2025-04-19 20:21:45,420:INFO:Importing libraries
2025-04-19 20:21:45,420:INFO:Copying training dataset
2025-04-19 20:21:45,420:INFO:Getting model names
2025-04-19 20:21:45,421:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:45,423:INFO:Initializing create_model()
2025-04-19 20:21:45,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029523610A30>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:21:45,423:INFO:Checking exceptions
2025-04-19 20:21:45,423:INFO:Importing libraries
2025-04-19 20:21:45,423:INFO:Copying training dataset
2025-04-19 20:21:45,426:INFO:Defining folds
2025-04-19 20:21:45,426:INFO:Declaring metric variables
2025-04-19 20:21:45,426:INFO:Importing untrained model
2025-04-19 20:21:45,427:INFO:Declaring custom model
2025-04-19 20:21:45,428:INFO:Voting Regressor Imported successfully
2025-04-19 20:21:45,428:INFO:Starting cross validation
2025-04-19 20:21:45,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:47,042:INFO:Calculating mean and std
2025-04-19 20:21:47,042:INFO:Creating metrics dataframe
2025-04-19 20:21:47,059:INFO:Finalizing model
2025-04-19 20:21:47,399:INFO:Uploading results into container
2025-04-19 20:21:47,399:INFO:Uploading model into container now
2025-04-19 20:21:47,399:INFO:_master_model_container: 25
2025-04-19 20:21:47,399:INFO:_display_container: 6
2025-04-19 20:21:47,399:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1)
2025-04-19 20:21:47,399:INFO:create_model() successfully completed......................................
2025-04-19 20:21:47,491:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:47,499:INFO:_master_model_container: 25
2025-04-19 20:21:47,499:INFO:_display_container: 6
2025-04-19 20:21:47,499:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1)
2025-04-19 20:21:47,499:INFO:blend_models() successfully completed......................................
2025-04-19 20:21:47,596:INFO:Initializing stack_models()
2025-04-19 20:21:47,596:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), Ridge(random_state=42), Lars(random_state=42)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:21:47,596:INFO:Checking exceptions
2025-04-19 20:21:47,596:INFO:Defining meta model
2025-04-19 20:21:47,596:INFO:Getting model names
2025-04-19 20:21:47,596:INFO:[('Huber Regressor', HuberRegressor(alpha=0.3, epsilon=1.3)), ('Ridge Regression', Ridge(random_state=42)), ('Least Angle Regression', Lars(random_state=42))]
2025-04-19 20:21:47,596:INFO:SubProcess create_model() called ==================================
2025-04-19 20:21:47,596:INFO:Initializing create_model()
2025-04-19 20:21:47,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029523610A30>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:21:47,596:INFO:Checking exceptions
2025-04-19 20:21:47,596:INFO:Importing libraries
2025-04-19 20:21:47,596:INFO:Copying training dataset
2025-04-19 20:21:47,596:INFO:Defining folds
2025-04-19 20:21:47,596:INFO:Declaring metric variables
2025-04-19 20:21:47,596:INFO:Importing untrained model
2025-04-19 20:21:47,596:INFO:Declaring custom model
2025-04-19 20:21:47,596:INFO:Stacking Regressor Imported successfully
2025-04-19 20:21:47,596:INFO:Starting cross validation
2025-04-19 20:21:47,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:21:49,498:INFO:Calculating mean and std
2025-04-19 20:21:49,498:INFO:Creating metrics dataframe
2025-04-19 20:21:49,498:INFO:Finalizing model
2025-04-19 20:21:49,881:INFO:Uploading results into container
2025-04-19 20:21:49,881:INFO:Uploading model into container now
2025-04-19 20:21:49,881:INFO:_master_model_container: 26
2025-04-19 20:21:49,881:INFO:_display_container: 7
2025-04-19 20:21:49,881:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:21:49,881:INFO:create_model() successfully completed......................................
2025-04-19 20:21:49,979:INFO:SubProcess create_model() end ==================================
2025-04-19 20:21:49,992:INFO:_master_model_container: 26
2025-04-19 20:21:49,992:INFO:_display_container: 7
2025-04-19 20:21:49,995:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:21:49,995:INFO:stack_models() successfully completed......................................
2025-04-19 20:21:50,115:INFO:Initializing save_model()
2025-04-19 20:21:50,115:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:21:50,115:INFO:Adding model into prep_pipe
2025-04-19 20:21:50,157:INFO:models/model_1.pkl saved in current working directory
2025-04-19 20:21:50,180:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor(alpha=0.3,
                                                             epsilon=1.3)),
                                             ('Ridge Regression',
                                              Ridge(random_state=42)),
                                             ('Least Angle Regression',
                                              Lars(random_state=42))],
                                 n_jobs=-1))])
2025-04-19 20:21:50,181:INFO:save_model() successfully completed......................................
2025-04-19 20:21:50,410:INFO:Initializing plot_model()
2025-04-19 20:21:50,410:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:50,410:INFO:Checking exceptions
2025-04-19 20:21:50,410:INFO:Initializing plot_model()
2025-04-19 20:21:50,410:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:50,410:INFO:Checking exceptions
2025-04-19 20:21:50,423:INFO:Preloading libraries
2025-04-19 20:21:50,423:INFO:Copying training dataset
2025-04-19 20:21:50,423:INFO:Plot type: residuals
2025-04-19 20:21:50,715:INFO:Fitting Model
2025-04-19 20:21:50,715:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:21:50,745:INFO:Scoring test/hold-out set
2025-04-19 20:21:50,776:INFO:Saving 'Residuals.png'
2025-04-19 20:21:51,529:INFO:Visual Rendered Successfully
2025-04-19 20:21:51,649:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:51,829:INFO:Initializing plot_model()
2025-04-19 20:21:51,838:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:51,838:INFO:Checking exceptions
2025-04-19 20:21:51,839:INFO:Preloading libraries
2025-04-19 20:21:51,839:INFO:Copying training dataset
2025-04-19 20:21:51,839:INFO:Plot type: error
2025-04-19 20:21:52,113:INFO:Fitting Model
2025-04-19 20:21:52,113:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:21:52,113:INFO:Scoring test/hold-out set
2025-04-19 20:21:52,150:INFO:Saving 'Prediction Error.png'
2025-04-19 20:21:52,508:INFO:Visual Rendered Successfully
2025-04-19 20:21:52,637:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:52,796:INFO:Initializing plot_model()
2025-04-19 20:21:52,796:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:52,796:INFO:Checking exceptions
2025-04-19 20:21:52,798:INFO:Preloading libraries
2025-04-19 20:21:52,798:INFO:Copying training dataset
2025-04-19 20:21:52,798:INFO:Plot type: learning
2025-04-19 20:21:53,084:INFO:Fitting Model
2025-04-19 20:21:53,699:INFO:Saving 'Learning Curve.png'
2025-04-19 20:21:54,030:INFO:Visual Rendered Successfully
2025-04-19 20:21:54,150:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:54,348:INFO:Initializing save_model()
2025-04-19 20:21:54,348:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:21:54,348:INFO:Adding model into prep_pipe
2025-04-19 20:21:54,384:INFO:models/model_2.pkl saved in current working directory
2025-04-19 20:21:54,401:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor(alpha=0.3,
                                                               epsilon=1.3)),
                                               ('Ridge Regression',
                                                Ridge(random_state=42)),
                                               ('Least Angle Regression',
                                                Lars(random_state=42))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 20:21:54,401:INFO:save_model() successfully completed......................................
2025-04-19 20:21:54,644:INFO:Initializing plot_model()
2025-04-19 20:21:54,644:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:54,644:INFO:Checking exceptions
2025-04-19 20:21:54,646:INFO:Initializing plot_model()
2025-04-19 20:21:54,646:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:54,646:INFO:Checking exceptions
2025-04-19 20:21:54,646:INFO:Preloading libraries
2025-04-19 20:21:54,646:INFO:Copying training dataset
2025-04-19 20:21:54,646:INFO:Plot type: residuals
2025-04-19 20:21:54,966:INFO:Fitting Model
2025-04-19 20:21:54,966:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:21:54,999:INFO:Scoring test/hold-out set
2025-04-19 20:21:55,030:INFO:Saving 'Residuals.png'
2025-04-19 20:21:55,760:INFO:Visual Rendered Successfully
2025-04-19 20:21:55,881:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:56,081:INFO:Initializing plot_model()
2025-04-19 20:21:56,081:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:56,081:INFO:Checking exceptions
2025-04-19 20:21:56,081:INFO:Preloading libraries
2025-04-19 20:21:56,081:INFO:Copying training dataset
2025-04-19 20:21:56,081:INFO:Plot type: error
2025-04-19 20:21:56,345:INFO:Fitting Model
2025-04-19 20:21:56,345:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:21:56,345:INFO:Scoring test/hold-out set
2025-04-19 20:21:56,373:INFO:Saving 'Prediction Error.png'
2025-04-19 20:21:56,803:INFO:Visual Rendered Successfully
2025-04-19 20:21:56,926:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:57,082:INFO:Initializing plot_model()
2025-04-19 20:21:57,082:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:57,082:INFO:Checking exceptions
2025-04-19 20:21:57,082:INFO:Preloading libraries
2025-04-19 20:21:57,082:INFO:Copying training dataset
2025-04-19 20:21:57,082:INFO:Plot type: learning
2025-04-19 20:21:57,412:INFO:Fitting Model
2025-04-19 20:21:58,739:INFO:Saving 'Learning Curve.png'
2025-04-19 20:21:59,065:INFO:Visual Rendered Successfully
2025-04-19 20:21:59,181:INFO:plot_model() successfully completed......................................
2025-04-19 20:21:59,338:INFO:Initializing save_model()
2025-04-19 20:21:59,338:INFO:save_model(model=HuberRegressor(alpha=0.3, epsilon=1.3), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:21:59,338:INFO:Adding model into prep_pipe
2025-04-19 20:21:59,364:INFO:models/model_3.pkl saved in current working directory
2025-04-19 20:21:59,381:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor(alpha=0.3, epsilon=1.3))])
2025-04-19 20:21:59,381:INFO:save_model() successfully completed......................................
2025-04-19 20:21:59,644:INFO:Initializing plot_model()
2025-04-19 20:21:59,644:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:21:59,644:INFO:Checking exceptions
2025-04-19 20:21:59,644:INFO:Preloading libraries
2025-04-19 20:21:59,644:INFO:Copying training dataset
2025-04-19 20:21:59,644:INFO:Plot type: feature
2025-04-19 20:21:59,807:INFO:Saving 'Feature Importance.png'
2025-04-19 20:21:59,939:INFO:Visual Rendered Successfully
2025-04-19 20:22:00,058:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:00,292:INFO:Initializing plot_model()
2025-04-19 20:22:00,292:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:00,292:INFO:Checking exceptions
2025-04-19 20:22:00,295:INFO:Preloading libraries
2025-04-19 20:22:00,295:INFO:Copying training dataset
2025-04-19 20:22:00,295:INFO:Plot type: residuals
2025-04-19 20:22:00,756:INFO:Fitting Model
2025-04-19 20:22:00,756:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:22:00,804:INFO:Scoring test/hold-out set
2025-04-19 20:22:00,857:INFO:Saving 'Residuals.png'
2025-04-19 20:22:01,940:INFO:Visual Rendered Successfully
2025-04-19 20:22:02,140:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:02,469:INFO:Initializing plot_model()
2025-04-19 20:22:02,469:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:02,469:INFO:Checking exceptions
2025-04-19 20:22:02,473:INFO:Preloading libraries
2025-04-19 20:22:02,473:INFO:Copying training dataset
2025-04-19 20:22:02,473:INFO:Plot type: error
2025-04-19 20:22:02,949:INFO:Fitting Model
2025-04-19 20:22:02,949:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:22:02,949:INFO:Scoring test/hold-out set
2025-04-19 20:22:02,981:INFO:Saving 'Prediction Error.png'
2025-04-19 20:22:03,534:INFO:Visual Rendered Successfully
2025-04-19 20:22:03,694:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:03,982:INFO:Initializing plot_model()
2025-04-19 20:22:03,996:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:03,996:INFO:Checking exceptions
2025-04-19 20:22:03,999:INFO:Preloading libraries
2025-04-19 20:22:03,999:INFO:Copying training dataset
2025-04-19 20:22:03,999:INFO:Plot type: learning
2025-04-19 20:22:04,370:INFO:Fitting Model
2025-04-19 20:22:04,669:INFO:Saving 'Learning Curve.png'
2025-04-19 20:22:05,131:INFO:Visual Rendered Successfully
2025-04-19 20:22:05,250:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:05,430:INFO:Initializing save_model()
2025-04-19 20:22:05,430:INFO:save_model(model=Ridge(random_state=42), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:22:05,430:INFO:Adding model into prep_pipe
2025-04-19 20:22:05,461:INFO:models/model_4.pkl saved in current working directory
2025-04-19 20:22:05,480:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', Ridge(random_state=42))])
2025-04-19 20:22:05,480:INFO:save_model() successfully completed......................................
2025-04-19 20:22:05,719:INFO:Initializing plot_model()
2025-04-19 20:22:05,719:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Ridge(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:05,719:INFO:Checking exceptions
2025-04-19 20:22:05,719:INFO:Preloading libraries
2025-04-19 20:22:05,719:INFO:Copying training dataset
2025-04-19 20:22:05,719:INFO:Plot type: feature
2025-04-19 20:22:05,912:INFO:Saving 'Feature Importance.png'
2025-04-19 20:22:06,084:INFO:Visual Rendered Successfully
2025-04-19 20:22:06,199:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:06,528:INFO:Initializing plot_model()
2025-04-19 20:22:06,528:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=Ridge(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:06,528:INFO:Checking exceptions
2025-04-19 20:22:06,532:INFO:Preloading libraries
2025-04-19 20:22:06,532:INFO:Copying training dataset
2025-04-19 20:22:06,532:INFO:Plot type: residuals
2025-04-19 20:22:06,979:INFO:Fitting Model
2025-04-19 20:22:06,981:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names
  warnings.warn(

2025-04-19 20:22:07,043:INFO:Scoring test/hold-out set
2025-04-19 20:22:07,095:INFO:Saving 'Residuals.png'
2025-04-19 20:22:08,057:INFO:Visual Rendered Successfully
2025-04-19 20:22:08,175:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:08,443:INFO:Initializing plot_model()
2025-04-19 20:22:08,443:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=Ridge(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:08,443:INFO:Checking exceptions
2025-04-19 20:22:08,445:INFO:Preloading libraries
2025-04-19 20:22:08,445:INFO:Copying training dataset
2025-04-19 20:22:08,445:INFO:Plot type: error
2025-04-19 20:22:08,909:INFO:Fitting Model
2025-04-19 20:22:08,909:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names
  warnings.warn(

2025-04-19 20:22:08,909:INFO:Scoring test/hold-out set
2025-04-19 20:22:08,939:INFO:Saving 'Prediction Error.png'
2025-04-19 20:22:09,484:INFO:Visual Rendered Successfully
2025-04-19 20:22:09,650:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:09,915:INFO:Initializing plot_model()
2025-04-19 20:22:09,915:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=Ridge(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:09,915:INFO:Checking exceptions
2025-04-19 20:22:09,916:INFO:Preloading libraries
2025-04-19 20:22:09,916:INFO:Copying training dataset
2025-04-19 20:22:09,916:INFO:Plot type: learning
2025-04-19 20:22:10,292:INFO:Fitting Model
2025-04-19 20:22:10,532:INFO:Saving 'Learning Curve.png'
2025-04-19 20:22:11,017:INFO:Visual Rendered Successfully
2025-04-19 20:22:11,152:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:11,358:INFO:Initializing save_model()
2025-04-19 20:22:11,358:INFO:save_model(model=Lars(random_state=42), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:22:11,358:INFO:Adding model into prep_pipe
2025-04-19 20:22:11,393:INFO:models/model_5.pkl saved in current working directory
2025-04-19 20:22:11,408:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', Lars(random_state=42))])
2025-04-19 20:22:11,408:INFO:save_model() successfully completed......................................
2025-04-19 20:22:11,659:INFO:Initializing plot_model()
2025-04-19 20:22:11,659:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Lars(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:11,659:INFO:Checking exceptions
2025-04-19 20:22:11,659:INFO:Preloading libraries
2025-04-19 20:22:11,659:INFO:Copying training dataset
2025-04-19 20:22:11,659:INFO:Plot type: feature
2025-04-19 20:22:11,811:INFO:Saving 'Feature Importance.png'
2025-04-19 20:22:11,954:INFO:Visual Rendered Successfully
2025-04-19 20:22:12,070:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:12,224:INFO:Initializing plot_model()
2025-04-19 20:22:12,224:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=Lars(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:12,224:INFO:Checking exceptions
2025-04-19 20:22:12,237:INFO:Preloading libraries
2025-04-19 20:22:12,237:INFO:Copying training dataset
2025-04-19 20:22:12,237:INFO:Plot type: residuals
2025-04-19 20:22:12,504:INFO:Fitting Model
2025-04-19 20:22:12,504:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but Lars was fitted with feature names
  warnings.warn(

2025-04-19 20:22:12,529:INFO:Scoring test/hold-out set
2025-04-19 20:22:12,552:INFO:Saving 'Residuals.png'
2025-04-19 20:22:13,307:INFO:Visual Rendered Successfully
2025-04-19 20:22:13,465:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:13,842:INFO:Initializing plot_model()
2025-04-19 20:22:13,842:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=Lars(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:13,842:INFO:Checking exceptions
2025-04-19 20:22:13,846:INFO:Preloading libraries
2025-04-19 20:22:13,846:INFO:Copying training dataset
2025-04-19 20:22:13,846:INFO:Plot type: error
2025-04-19 20:22:14,243:INFO:Fitting Model
2025-04-19 20:22:14,243:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but Lars was fitted with feature names
  warnings.warn(

2025-04-19 20:22:14,243:INFO:Scoring test/hold-out set
2025-04-19 20:22:14,270:INFO:Saving 'Prediction Error.png'
2025-04-19 20:22:14,699:INFO:Visual Rendered Successfully
2025-04-19 20:22:14,866:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:15,148:INFO:Initializing plot_model()
2025-04-19 20:22:15,149:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=Lars(random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, system=True)
2025-04-19 20:22:15,149:INFO:Checking exceptions
2025-04-19 20:22:15,152:INFO:Preloading libraries
2025-04-19 20:22:15,152:INFO:Copying training dataset
2025-04-19 20:22:15,152:INFO:Plot type: learning
2025-04-19 20:22:15,493:INFO:Fitting Model
2025-04-19 20:22:15,685:INFO:Saving 'Learning Curve.png'
2025-04-19 20:22:16,048:INFO:Visual Rendered Successfully
2025-04-19 20:22:16,159:INFO:plot_model() successfully completed......................................
2025-04-19 20:22:16,361:INFO:Initializing predict_model()
2025-04-19 20:22:16,362:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Ridge Regression', Ridge(random_state=42)),
                            ('Least Angle Regression', Lars(random_state=42))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002952BA88A60>)
2025-04-19 20:22:16,362:INFO:Checking exceptions
2025-04-19 20:22:16,362:INFO:Preloading libraries
2025-04-19 20:22:16,362:INFO:Set up data.
2025-04-19 20:22:16,364:INFO:Set up index.
2025-04-19 20:22:16,524:INFO:Initializing predict_model()
2025-04-19 20:22:16,524:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Ridge Regression', Ridge(random_state=42)),
                              ('Least Angle Regression',
                               Lars(random_state=42))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002952755E200>)
2025-04-19 20:22:16,524:INFO:Checking exceptions
2025-04-19 20:22:16,524:INFO:Preloading libraries
2025-04-19 20:22:16,524:INFO:Set up data.
2025-04-19 20:22:16,524:INFO:Set up index.
2025-04-19 20:22:16,694:INFO:Initializing predict_model()
2025-04-19 20:22:16,694:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002952755E200>)
2025-04-19 20:22:16,694:INFO:Checking exceptions
2025-04-19 20:22:16,694:INFO:Preloading libraries
2025-04-19 20:22:16,694:INFO:Set up data.
2025-04-19 20:22:16,694:INFO:Set up index.
2025-04-19 20:22:16,857:INFO:Initializing predict_model()
2025-04-19 20:22:16,857:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Ridge(random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002952755E200>)
2025-04-19 20:22:16,857:INFO:Checking exceptions
2025-04-19 20:22:16,857:INFO:Preloading libraries
2025-04-19 20:22:16,857:INFO:Set up data.
2025-04-19 20:22:16,857:INFO:Set up index.
2025-04-19 20:22:17,011:INFO:Initializing predict_model()
2025-04-19 20:22:17,011:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002952CF335E0>, estimator=Lars(random_state=42), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002952755E200>)
2025-04-19 20:22:17,011:INFO:Checking exceptions
2025-04-19 20:22:17,011:INFO:Preloading libraries
2025-04-19 20:22:17,011:INFO:Set up data.
2025-04-19 20:22:17,011:INFO:Set up index.
2025-04-19 20:24:59,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:24:59,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:24:59,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:24:59,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:25:48,886:INFO:PyCaret RegressionExperiment
2025-04-19 20:25:48,887:INFO:Logging name: agn_modeling
2025-04-19 20:25:48,887:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:25:48,887:INFO:version 3.0.4
2025-04-19 20:25:48,887:INFO:Initializing setup()
2025-04-19 20:25:48,887:INFO:self.USI: df56
2025-04-19 20:25:48,887:INFO:self._variable_keys: {'pipeline', 'logging_param', '_available_plots', 'memory', 'data', 'y', 'fold_generator', 'X', 'USI', 'gpu_param', 'y_train', 'fold_groups_param', 'transform_target_param', 'html_param', 'seed', 'y_test', '_ml_usecase', 'X_train', 'n_jobs_param', 'exp_id', 'idx', 'exp_name_log', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'X_test', 'gpu_n_jobs_param'}
2025-04-19 20:25:48,887:INFO:Checking environment
2025-04-19 20:25:48,887:INFO:python_version: 3.10.9
2025-04-19 20:25:48,887:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:25:48,887:INFO:machine: AMD64
2025-04-19 20:25:48,921:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:25:48,928:INFO:Memory: svmem(total=16952647680, available=3135901696, percent=81.5, used=13816745984, free=3135901696)
2025-04-19 20:25:48,929:INFO:Physical Core: 4
2025-04-19 20:25:48,929:INFO:Logical Core: 8
2025-04-19 20:25:48,929:INFO:Checking libraries
2025-04-19 20:25:48,929:INFO:System:
2025-04-19 20:25:48,929:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:25:48,929:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:25:48,929:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:25:48,929:INFO:PyCaret required dependencies:
2025-04-19 20:25:49,018:INFO:                 pip: 25.0.1
2025-04-19 20:25:49,018:INFO:          setuptools: 65.5.0
2025-04-19 20:25:49,018:INFO:             pycaret: 3.0.4
2025-04-19 20:25:49,019:INFO:             IPython: 8.35.0
2025-04-19 20:25:49,019:INFO:          ipywidgets: 8.1.6
2025-04-19 20:25:49,019:INFO:                tqdm: 4.67.1
2025-04-19 20:25:49,019:INFO:               numpy: 1.23.5
2025-04-19 20:25:49,019:INFO:              pandas: 1.5.3
2025-04-19 20:25:49,019:INFO:              jinja2: 3.1.6
2025-04-19 20:25:49,019:INFO:               scipy: 1.10.1
2025-04-19 20:25:49,019:INFO:              joblib: 1.2.0
2025-04-19 20:25:49,019:INFO:             sklearn: 1.2.2
2025-04-19 20:25:49,019:INFO:                pyod: 2.0.4
2025-04-19 20:25:49,019:INFO:            imblearn: 0.12.4
2025-04-19 20:25:49,019:INFO:   category_encoders: 2.7.0
2025-04-19 20:25:49,019:INFO:            lightgbm: 4.6.0
2025-04-19 20:25:49,019:INFO:               numba: 0.60.0
2025-04-19 20:25:49,019:INFO:            requests: 2.32.3
2025-04-19 20:25:49,019:INFO:          matplotlib: 3.7.1
2025-04-19 20:25:49,019:INFO:          scikitplot: 0.3.7
2025-04-19 20:25:49,019:INFO:         yellowbrick: 1.5
2025-04-19 20:25:49,019:INFO:              plotly: 5.24.1
2025-04-19 20:25:49,019:INFO:    plotly-resampler: Not installed
2025-04-19 20:25:49,019:INFO:             kaleido: 0.2.1
2025-04-19 20:25:49,019:INFO:           schemdraw: 0.15
2025-04-19 20:25:49,019:INFO:         statsmodels: 0.14.4
2025-04-19 20:25:49,019:INFO:              sktime: 0.21.1
2025-04-19 20:25:49,019:INFO:               tbats: 1.1.3
2025-04-19 20:25:49,019:INFO:            pmdarima: 2.0.4
2025-04-19 20:25:49,020:INFO:              psutil: 7.0.0
2025-04-19 20:25:49,020:INFO:          markupsafe: 3.0.2
2025-04-19 20:25:49,020:INFO:             pickle5: Not installed
2025-04-19 20:25:49,020:INFO:         cloudpickle: 3.1.1
2025-04-19 20:25:49,020:INFO:         deprecation: 2.1.0
2025-04-19 20:25:49,020:INFO:              xxhash: 3.5.0
2025-04-19 20:25:49,020:INFO:           wurlitzer: Not installed
2025-04-19 20:25:49,020:INFO:PyCaret optional dependencies:
2025-04-19 20:26:07,638:INFO:                shap: Not installed
2025-04-19 20:26:07,639:INFO:           interpret: Not installed
2025-04-19 20:26:07,639:INFO:                umap: Not installed
2025-04-19 20:26:07,639:INFO:    pandas_profiling: Not installed
2025-04-19 20:26:07,639:INFO:  explainerdashboard: Not installed
2025-04-19 20:26:07,639:INFO:             autoviz: Not installed
2025-04-19 20:26:07,639:INFO:           fairlearn: Not installed
2025-04-19 20:26:07,639:INFO:          deepchecks: Not installed
2025-04-19 20:26:07,639:INFO:             xgboost: 3.0.0
2025-04-19 20:26:07,639:INFO:            catboost: 1.2.8
2025-04-19 20:26:07,639:INFO:              kmodes: 0.12.2
2025-04-19 20:26:07,639:INFO:             mlxtend: 0.23.1
2025-04-19 20:26:07,639:INFO:       statsforecast: 2.0.1
2025-04-19 20:26:07,639:INFO:        tune_sklearn: Not installed
2025-04-19 20:26:07,639:INFO:                 ray: Not installed
2025-04-19 20:26:07,639:INFO:            hyperopt: Not installed
2025-04-19 20:26:07,639:INFO:              optuna: Not installed
2025-04-19 20:26:07,639:INFO:               skopt: Not installed
2025-04-19 20:26:07,639:INFO:              mlflow: 2.21.3
2025-04-19 20:26:07,639:INFO:              gradio: Not installed
2025-04-19 20:26:07,640:INFO:             fastapi: 0.115.12
2025-04-19 20:26:07,640:INFO:             uvicorn: 0.34.2
2025-04-19 20:26:07,640:INFO:              m2cgen: Not installed
2025-04-19 20:26:07,640:INFO:           evidently: Not installed
2025-04-19 20:26:07,640:INFO:               fugue: 0.9.1
2025-04-19 20:26:07,640:INFO:           streamlit: Not installed
2025-04-19 20:26:07,640:INFO:             prophet: Not installed
2025-04-19 20:26:07,640:INFO:None
2025-04-19 20:26:07,640:INFO:Set up data.
2025-04-19 20:26:07,643:INFO:Set up train/test split.
2025-04-19 20:26:07,646:INFO:Set up index.
2025-04-19 20:26:07,646:INFO:Set up folding strategy.
2025-04-19 20:26:07,646:INFO:Assigning column types.
2025-04-19 20:26:07,648:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:26:07,648:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:26:07,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:26:07,656:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:07,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:07,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:07,745:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:07,747:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:31,902:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:26:31,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:26:31,915:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:31,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,023:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,028:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,028:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:26:32,028:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,161:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,162:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,166:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,273:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,276:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,276:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:26:32,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,395:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,397:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,406:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,493:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,493:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,493:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:26:32,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,589:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,589:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,690:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,690:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,690:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:26:32,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,800:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,802:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:26:32,905:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:32,907:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:32,908:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:26:33,007:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:33,007:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:33,106:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:33,106:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:33,106:INFO:Preparing preprocessing pipeline...
2025-04-19 20:26:33,106:INFO:Set up target transformation.
2025-04-19 20:26:33,106:INFO:Set up simple imputation.
2025-04-19 20:26:33,106:INFO:Set up removing multicollinearity.
2025-04-19 20:26:33,106:INFO:Set up removing outliers.
2025-04-19 20:26:33,106:INFO:Set up feature normalization.
2025-04-19 20:26:33,296:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:33,595:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:26:33,603:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:26:33,603:INFO:Creating final display dataframe.
2025-04-19 20:26:33,812:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:34,393:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape     (7999, 5)
4        Transformed data shape     (7719, 5)
5   Transformed train set shape     (5319, 5)
6    Transformed test set shape     (2400, 5)
7              Numeric features             4
8      Rows with missing values          7.8%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          df56
2025-04-19 20:26:34,529:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:34,533:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:34,652:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-19 20:26:34,655:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:26:34,657:INFO:setup() successfully completed in 46.01s...............
2025-04-19 20:26:34,658:INFO:Initializing compare_models()
2025-04-19 20:26:34,658:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 20:26:34,658:INFO:Checking exceptions
2025-04-19 20:26:34,660:INFO:Preparing display monitor
2025-04-19 20:26:34,664:INFO:Initializing Linear Regression
2025-04-19 20:26:34,665:INFO:Total runtime is 1.6629695892333984e-05 minutes
2025-04-19 20:26:34,665:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:34,665:INFO:Initializing create_model()
2025-04-19 20:26:34,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:34,665:INFO:Checking exceptions
2025-04-19 20:26:34,665:INFO:Importing libraries
2025-04-19 20:26:34,665:INFO:Copying training dataset
2025-04-19 20:26:34,669:INFO:Defining folds
2025-04-19 20:26:34,669:INFO:Declaring metric variables
2025-04-19 20:26:34,669:INFO:Importing untrained model
2025-04-19 20:26:34,669:INFO:Linear Regression Imported successfully
2025-04-19 20:26:34,670:INFO:Starting cross validation
2025-04-19 20:26:34,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:40,990:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:40,995:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,006:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,034:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,049:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,066:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,092:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:41,356:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:42,329:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:42,368:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:26:43,540:INFO:Calculating mean and std
2025-04-19 20:26:43,540:INFO:Creating metrics dataframe
2025-04-19 20:26:43,768:INFO:Uploading results into container
2025-04-19 20:26:43,768:INFO:Uploading model into container now
2025-04-19 20:26:43,768:INFO:_master_model_container: 1
2025-04-19 20:26:43,768:INFO:_display_container: 2
2025-04-19 20:26:43,782:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:26:43,782:INFO:create_model() successfully completed......................................
2025-04-19 20:26:43,982:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:43,982:INFO:Creating metrics dataframe
2025-04-19 20:26:43,984:INFO:Initializing Lasso Regression
2025-04-19 20:26:43,984:INFO:Total runtime is 0.1553362488746643 minutes
2025-04-19 20:26:43,986:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:43,986:INFO:Initializing create_model()
2025-04-19 20:26:43,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:43,986:INFO:Checking exceptions
2025-04-19 20:26:43,986:INFO:Importing libraries
2025-04-19 20:26:43,986:INFO:Copying training dataset
2025-04-19 20:26:43,991:INFO:Defining folds
2025-04-19 20:26:43,991:INFO:Declaring metric variables
2025-04-19 20:26:43,991:INFO:Importing untrained model
2025-04-19 20:26:43,991:INFO:Lasso Regression Imported successfully
2025-04-19 20:26:43,991:INFO:Starting cross validation
2025-04-19 20:26:43,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:45,588:INFO:Calculating mean and std
2025-04-19 20:26:45,588:INFO:Creating metrics dataframe
2025-04-19 20:26:45,800:INFO:Uploading results into container
2025-04-19 20:26:45,808:INFO:Uploading model into container now
2025-04-19 20:26:45,808:INFO:_master_model_container: 2
2025-04-19 20:26:45,808:INFO:_display_container: 2
2025-04-19 20:26:45,808:INFO:Lasso(random_state=42)
2025-04-19 20:26:45,808:INFO:create_model() successfully completed......................................
2025-04-19 20:26:46,000:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:46,000:INFO:Creating metrics dataframe
2025-04-19 20:26:46,000:INFO:Initializing Ridge Regression
2025-04-19 20:26:46,000:INFO:Total runtime is 0.18893114328384397 minutes
2025-04-19 20:26:46,000:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:46,000:INFO:Initializing create_model()
2025-04-19 20:26:46,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:46,000:INFO:Checking exceptions
2025-04-19 20:26:46,000:INFO:Importing libraries
2025-04-19 20:26:46,000:INFO:Copying training dataset
2025-04-19 20:26:46,000:INFO:Defining folds
2025-04-19 20:26:46,000:INFO:Declaring metric variables
2025-04-19 20:26:46,000:INFO:Importing untrained model
2025-04-19 20:26:46,000:INFO:Ridge Regression Imported successfully
2025-04-19 20:26:46,000:INFO:Starting cross validation
2025-04-19 20:26:46,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:47,554:INFO:Calculating mean and std
2025-04-19 20:26:47,570:INFO:Creating metrics dataframe
2025-04-19 20:26:47,768:INFO:Uploading results into container
2025-04-19 20:26:47,768:INFO:Uploading model into container now
2025-04-19 20:26:47,768:INFO:_master_model_container: 3
2025-04-19 20:26:47,768:INFO:_display_container: 2
2025-04-19 20:26:47,768:INFO:Ridge(random_state=42)
2025-04-19 20:26:47,768:INFO:create_model() successfully completed......................................
2025-04-19 20:26:47,871:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:47,871:INFO:Creating metrics dataframe
2025-04-19 20:26:47,871:INFO:Initializing Elastic Net
2025-04-19 20:26:47,871:INFO:Total runtime is 0.22012178103129065 minutes
2025-04-19 20:26:47,871:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:47,871:INFO:Initializing create_model()
2025-04-19 20:26:47,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:47,871:INFO:Checking exceptions
2025-04-19 20:26:47,871:INFO:Importing libraries
2025-04-19 20:26:47,871:INFO:Copying training dataset
2025-04-19 20:26:47,871:INFO:Defining folds
2025-04-19 20:26:47,871:INFO:Declaring metric variables
2025-04-19 20:26:47,871:INFO:Importing untrained model
2025-04-19 20:26:47,871:INFO:Elastic Net Imported successfully
2025-04-19 20:26:47,871:INFO:Starting cross validation
2025-04-19 20:26:47,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:49,420:INFO:Calculating mean and std
2025-04-19 20:26:49,420:INFO:Creating metrics dataframe
2025-04-19 20:26:49,633:INFO:Uploading results into container
2025-04-19 20:26:49,633:INFO:Uploading model into container now
2025-04-19 20:26:49,633:INFO:_master_model_container: 4
2025-04-19 20:26:49,633:INFO:_display_container: 2
2025-04-19 20:26:49,633:INFO:ElasticNet(random_state=42)
2025-04-19 20:26:49,633:INFO:create_model() successfully completed......................................
2025-04-19 20:26:49,721:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:49,721:INFO:Creating metrics dataframe
2025-04-19 20:26:49,737:INFO:Initializing Least Angle Regression
2025-04-19 20:26:49,737:INFO:Total runtime is 0.2512189944585164 minutes
2025-04-19 20:26:49,737:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:49,737:INFO:Initializing create_model()
2025-04-19 20:26:49,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:49,737:INFO:Checking exceptions
2025-04-19 20:26:49,737:INFO:Importing libraries
2025-04-19 20:26:49,737:INFO:Copying training dataset
2025-04-19 20:26:49,737:INFO:Defining folds
2025-04-19 20:26:49,737:INFO:Declaring metric variables
2025-04-19 20:26:49,744:INFO:Importing untrained model
2025-04-19 20:26:49,744:INFO:Least Angle Regression Imported successfully
2025-04-19 20:26:49,744:INFO:Starting cross validation
2025-04-19 20:26:49,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:51,551:INFO:Calculating mean and std
2025-04-19 20:26:51,552:INFO:Creating metrics dataframe
2025-04-19 20:26:51,799:INFO:Uploading results into container
2025-04-19 20:26:51,799:INFO:Uploading model into container now
2025-04-19 20:26:51,800:INFO:_master_model_container: 5
2025-04-19 20:26:51,800:INFO:_display_container: 2
2025-04-19 20:26:51,800:INFO:Lars(random_state=42)
2025-04-19 20:26:51,800:INFO:create_model() successfully completed......................................
2025-04-19 20:26:51,903:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:51,903:INFO:Creating metrics dataframe
2025-04-19 20:26:51,907:INFO:Initializing Lasso Least Angle Regression
2025-04-19 20:26:51,907:INFO:Total runtime is 0.28738945722579956 minutes
2025-04-19 20:26:51,908:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:51,908:INFO:Initializing create_model()
2025-04-19 20:26:51,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:51,908:INFO:Checking exceptions
2025-04-19 20:26:51,908:INFO:Importing libraries
2025-04-19 20:26:51,908:INFO:Copying training dataset
2025-04-19 20:26:51,908:INFO:Defining folds
2025-04-19 20:26:51,908:INFO:Declaring metric variables
2025-04-19 20:26:51,908:INFO:Importing untrained model
2025-04-19 20:26:51,908:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 20:26:51,908:INFO:Starting cross validation
2025-04-19 20:26:51,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:53,762:INFO:Calculating mean and std
2025-04-19 20:26:53,764:INFO:Creating metrics dataframe
2025-04-19 20:26:54,005:INFO:Uploading results into container
2025-04-19 20:26:54,007:INFO:Uploading model into container now
2025-04-19 20:26:54,007:INFO:_master_model_container: 6
2025-04-19 20:26:54,007:INFO:_display_container: 2
2025-04-19 20:26:54,007:INFO:LassoLars(random_state=42)
2025-04-19 20:26:54,007:INFO:create_model() successfully completed......................................
2025-04-19 20:26:54,112:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:54,112:INFO:Creating metrics dataframe
2025-04-19 20:26:54,116:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 20:26:54,116:INFO:Total runtime is 0.32420059442520144 minutes
2025-04-19 20:26:54,117:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:54,117:INFO:Initializing create_model()
2025-04-19 20:26:54,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:54,117:INFO:Checking exceptions
2025-04-19 20:26:54,117:INFO:Importing libraries
2025-04-19 20:26:54,117:INFO:Copying training dataset
2025-04-19 20:26:54,120:INFO:Defining folds
2025-04-19 20:26:54,120:INFO:Declaring metric variables
2025-04-19 20:26:54,120:INFO:Importing untrained model
2025-04-19 20:26:54,121:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 20:26:54,121:INFO:Starting cross validation
2025-04-19 20:26:54,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:55,703:INFO:Calculating mean and std
2025-04-19 20:26:55,703:INFO:Creating metrics dataframe
2025-04-19 20:26:55,915:INFO:Uploading results into container
2025-04-19 20:26:55,916:INFO:Uploading model into container now
2025-04-19 20:26:55,916:INFO:_master_model_container: 7
2025-04-19 20:26:55,916:INFO:_display_container: 2
2025-04-19 20:26:55,916:INFO:OrthogonalMatchingPursuit()
2025-04-19 20:26:55,916:INFO:create_model() successfully completed......................................
2025-04-19 20:26:56,012:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:56,012:INFO:Creating metrics dataframe
2025-04-19 20:26:56,012:INFO:Initializing Bayesian Ridge
2025-04-19 20:26:56,012:INFO:Total runtime is 0.3557929873466492 minutes
2025-04-19 20:26:56,012:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:56,012:INFO:Initializing create_model()
2025-04-19 20:26:56,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:56,012:INFO:Checking exceptions
2025-04-19 20:26:56,012:INFO:Importing libraries
2025-04-19 20:26:56,012:INFO:Copying training dataset
2025-04-19 20:26:56,012:INFO:Defining folds
2025-04-19 20:26:56,012:INFO:Declaring metric variables
2025-04-19 20:26:56,019:INFO:Importing untrained model
2025-04-19 20:26:56,019:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:26:56,019:INFO:Starting cross validation
2025-04-19 20:26:56,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:57,537:INFO:Calculating mean and std
2025-04-19 20:26:57,537:INFO:Creating metrics dataframe
2025-04-19 20:26:57,748:INFO:Uploading results into container
2025-04-19 20:26:57,748:INFO:Uploading model into container now
2025-04-19 20:26:57,748:INFO:_master_model_container: 8
2025-04-19 20:26:57,748:INFO:_display_container: 2
2025-04-19 20:26:57,748:INFO:BayesianRidge()
2025-04-19 20:26:57,748:INFO:create_model() successfully completed......................................
2025-04-19 20:26:57,838:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:57,838:INFO:Creating metrics dataframe
2025-04-19 20:26:57,838:INFO:Initializing Passive Aggressive Regressor
2025-04-19 20:26:57,838:INFO:Total runtime is 0.38623436292012536 minutes
2025-04-19 20:26:57,838:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:57,838:INFO:Initializing create_model()
2025-04-19 20:26:57,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:57,838:INFO:Checking exceptions
2025-04-19 20:26:57,838:INFO:Importing libraries
2025-04-19 20:26:57,838:INFO:Copying training dataset
2025-04-19 20:26:57,838:INFO:Defining folds
2025-04-19 20:26:57,838:INFO:Declaring metric variables
2025-04-19 20:26:57,838:INFO:Importing untrained model
2025-04-19 20:26:57,838:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 20:26:57,854:INFO:Starting cross validation
2025-04-19 20:26:57,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:26:59,382:INFO:Calculating mean and std
2025-04-19 20:26:59,382:INFO:Creating metrics dataframe
2025-04-19 20:26:59,584:INFO:Uploading results into container
2025-04-19 20:26:59,584:INFO:Uploading model into container now
2025-04-19 20:26:59,584:INFO:_master_model_container: 9
2025-04-19 20:26:59,584:INFO:_display_container: 2
2025-04-19 20:26:59,584:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 20:26:59,584:INFO:create_model() successfully completed......................................
2025-04-19 20:26:59,690:INFO:SubProcess create_model() end ==================================
2025-04-19 20:26:59,690:INFO:Creating metrics dataframe
2025-04-19 20:26:59,690:INFO:Initializing Huber Regressor
2025-04-19 20:26:59,690:INFO:Total runtime is 0.41709474722544354 minutes
2025-04-19 20:26:59,690:INFO:SubProcess create_model() called ==================================
2025-04-19 20:26:59,690:INFO:Initializing create_model()
2025-04-19 20:26:59,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:26:59,690:INFO:Checking exceptions
2025-04-19 20:26:59,690:INFO:Importing libraries
2025-04-19 20:26:59,690:INFO:Copying training dataset
2025-04-19 20:26:59,694:INFO:Defining folds
2025-04-19 20:26:59,694:INFO:Declaring metric variables
2025-04-19 20:26:59,694:INFO:Importing untrained model
2025-04-19 20:26:59,694:INFO:Huber Regressor Imported successfully
2025-04-19 20:26:59,694:INFO:Starting cross validation
2025-04-19 20:26:59,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:01,225:INFO:Calculating mean and std
2025-04-19 20:27:01,225:INFO:Creating metrics dataframe
2025-04-19 20:27:01,433:INFO:Uploading results into container
2025-04-19 20:27:01,433:INFO:Uploading model into container now
2025-04-19 20:27:01,433:INFO:_master_model_container: 10
2025-04-19 20:27:01,433:INFO:_display_container: 2
2025-04-19 20:27:01,433:INFO:HuberRegressor()
2025-04-19 20:27:01,433:INFO:create_model() successfully completed......................................
2025-04-19 20:27:01,538:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:01,538:INFO:Creating metrics dataframe
2025-04-19 20:27:01,538:INFO:Initializing K Neighbors Regressor
2025-04-19 20:27:01,538:INFO:Total runtime is 0.44789515336354574 minutes
2025-04-19 20:27:01,538:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:01,538:INFO:Initializing create_model()
2025-04-19 20:27:01,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:01,538:INFO:Checking exceptions
2025-04-19 20:27:01,538:INFO:Importing libraries
2025-04-19 20:27:01,538:INFO:Copying training dataset
2025-04-19 20:27:01,538:INFO:Defining folds
2025-04-19 20:27:01,538:INFO:Declaring metric variables
2025-04-19 20:27:01,538:INFO:Importing untrained model
2025-04-19 20:27:01,538:INFO:K Neighbors Regressor Imported successfully
2025-04-19 20:27:01,538:INFO:Starting cross validation
2025-04-19 20:27:01,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:03,278:INFO:Calculating mean and std
2025-04-19 20:27:03,280:INFO:Creating metrics dataframe
2025-04-19 20:27:03,517:INFO:Uploading results into container
2025-04-19 20:27:03,517:INFO:Uploading model into container now
2025-04-19 20:27:03,517:INFO:_master_model_container: 11
2025-04-19 20:27:03,517:INFO:_display_container: 2
2025-04-19 20:27:03,517:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 20:27:03,517:INFO:create_model() successfully completed......................................
2025-04-19 20:27:03,619:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:03,619:INFO:Creating metrics dataframe
2025-04-19 20:27:03,621:INFO:Initializing Decision Tree Regressor
2025-04-19 20:27:03,621:INFO:Total runtime is 0.4826189319292704 minutes
2025-04-19 20:27:03,621:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:03,621:INFO:Initializing create_model()
2025-04-19 20:27:03,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:03,621:INFO:Checking exceptions
2025-04-19 20:27:03,621:INFO:Importing libraries
2025-04-19 20:27:03,621:INFO:Copying training dataset
2025-04-19 20:27:03,621:INFO:Defining folds
2025-04-19 20:27:03,621:INFO:Declaring metric variables
2025-04-19 20:27:03,621:INFO:Importing untrained model
2025-04-19 20:27:03,621:INFO:Decision Tree Regressor Imported successfully
2025-04-19 20:27:03,621:INFO:Starting cross validation
2025-04-19 20:27:03,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:05,285:INFO:Calculating mean and std
2025-04-19 20:27:05,285:INFO:Creating metrics dataframe
2025-04-19 20:27:05,497:INFO:Uploading results into container
2025-04-19 20:27:05,497:INFO:Uploading model into container now
2025-04-19 20:27:05,497:INFO:_master_model_container: 12
2025-04-19 20:27:05,497:INFO:_display_container: 2
2025-04-19 20:27:05,497:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 20:27:05,497:INFO:create_model() successfully completed......................................
2025-04-19 20:27:05,588:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:05,588:INFO:Creating metrics dataframe
2025-04-19 20:27:05,604:INFO:Initializing Random Forest Regressor
2025-04-19 20:27:05,604:INFO:Total runtime is 0.5156739393870036 minutes
2025-04-19 20:27:05,604:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:05,604:INFO:Initializing create_model()
2025-04-19 20:27:05,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:05,604:INFO:Checking exceptions
2025-04-19 20:27:05,604:INFO:Importing libraries
2025-04-19 20:27:05,604:INFO:Copying training dataset
2025-04-19 20:27:05,604:INFO:Defining folds
2025-04-19 20:27:05,604:INFO:Declaring metric variables
2025-04-19 20:27:05,604:INFO:Importing untrained model
2025-04-19 20:27:05,604:INFO:Random Forest Regressor Imported successfully
2025-04-19 20:27:05,604:INFO:Starting cross validation
2025-04-19 20:27:05,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:12,922:INFO:Calculating mean and std
2025-04-19 20:27:12,922:INFO:Creating metrics dataframe
2025-04-19 20:27:13,174:INFO:Uploading results into container
2025-04-19 20:27:13,189:INFO:Uploading model into container now
2025-04-19 20:27:13,189:INFO:_master_model_container: 13
2025-04-19 20:27:13,189:INFO:_display_container: 2
2025-04-19 20:27:13,189:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:27:13,189:INFO:create_model() successfully completed......................................
2025-04-19 20:27:13,313:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:13,313:INFO:Creating metrics dataframe
2025-04-19 20:27:13,318:INFO:Initializing Extra Trees Regressor
2025-04-19 20:27:13,318:INFO:Total runtime is 0.6442398508389791 minutes
2025-04-19 20:27:13,318:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:13,318:INFO:Initializing create_model()
2025-04-19 20:27:13,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:13,319:INFO:Checking exceptions
2025-04-19 20:27:13,319:INFO:Importing libraries
2025-04-19 20:27:13,319:INFO:Copying training dataset
2025-04-19 20:27:13,324:INFO:Defining folds
2025-04-19 20:27:13,324:INFO:Declaring metric variables
2025-04-19 20:27:13,324:INFO:Importing untrained model
2025-04-19 20:27:13,324:INFO:Extra Trees Regressor Imported successfully
2025-04-19 20:27:13,324:INFO:Starting cross validation
2025-04-19 20:27:13,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:15,059:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:27:15,062:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:27:15,463:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:27:17,751:INFO:Calculating mean and std
2025-04-19 20:27:17,752:INFO:Creating metrics dataframe
2025-04-19 20:27:17,986:INFO:Uploading results into container
2025-04-19 20:27:17,986:INFO:Uploading model into container now
2025-04-19 20:27:17,986:INFO:_master_model_container: 14
2025-04-19 20:27:17,986:INFO:_display_container: 2
2025-04-19 20:27:17,986:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:27:17,986:INFO:create_model() successfully completed......................................
2025-04-19 20:27:18,105:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:18,105:INFO:Creating metrics dataframe
2025-04-19 20:27:18,105:INFO:Initializing AdaBoost Regressor
2025-04-19 20:27:18,105:INFO:Total runtime is 0.7240137775739034 minutes
2025-04-19 20:27:18,105:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:18,105:INFO:Initializing create_model()
2025-04-19 20:27:18,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:18,105:INFO:Checking exceptions
2025-04-19 20:27:18,105:INFO:Importing libraries
2025-04-19 20:27:18,105:INFO:Copying training dataset
2025-04-19 20:27:18,120:INFO:Defining folds
2025-04-19 20:27:18,120:INFO:Declaring metric variables
2025-04-19 20:27:18,121:INFO:Importing untrained model
2025-04-19 20:27:18,121:INFO:AdaBoost Regressor Imported successfully
2025-04-19 20:27:18,121:INFO:Starting cross validation
2025-04-19 20:27:18,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:21,435:INFO:Calculating mean and std
2025-04-19 20:27:21,436:INFO:Creating metrics dataframe
2025-04-19 20:27:22,037:INFO:Uploading results into container
2025-04-19 20:27:22,038:INFO:Uploading model into container now
2025-04-19 20:27:22,039:INFO:_master_model_container: 15
2025-04-19 20:27:22,039:INFO:_display_container: 2
2025-04-19 20:27:22,040:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 20:27:22,040:INFO:create_model() successfully completed......................................
2025-04-19 20:27:22,173:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:22,173:INFO:Creating metrics dataframe
2025-04-19 20:27:22,179:INFO:Initializing Gradient Boosting Regressor
2025-04-19 20:27:22,179:INFO:Total runtime is 0.7919103423754374 minutes
2025-04-19 20:27:22,179:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:22,179:INFO:Initializing create_model()
2025-04-19 20:27:22,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:22,180:INFO:Checking exceptions
2025-04-19 20:27:22,180:INFO:Importing libraries
2025-04-19 20:27:22,180:INFO:Copying training dataset
2025-04-19 20:27:22,183:INFO:Defining folds
2025-04-19 20:27:22,183:INFO:Declaring metric variables
2025-04-19 20:27:22,184:INFO:Importing untrained model
2025-04-19 20:27:22,184:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 20:27:22,184:INFO:Starting cross validation
2025-04-19 20:27:22,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:26,288:INFO:Calculating mean and std
2025-04-19 20:27:26,288:INFO:Creating metrics dataframe
2025-04-19 20:27:26,958:INFO:Uploading results into container
2025-04-19 20:27:26,958:INFO:Uploading model into container now
2025-04-19 20:27:26,959:INFO:_master_model_container: 16
2025-04-19 20:27:26,959:INFO:_display_container: 2
2025-04-19 20:27:26,960:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 20:27:26,960:INFO:create_model() successfully completed......................................
2025-04-19 20:27:27,095:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:27,096:INFO:Creating metrics dataframe
2025-04-19 20:27:27,104:INFO:Initializing Extreme Gradient Boosting
2025-04-19 20:27:27,104:INFO:Total runtime is 0.8740009903907776 minutes
2025-04-19 20:27:27,104:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:27,104:INFO:Initializing create_model()
2025-04-19 20:27:27,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:27,104:INFO:Checking exceptions
2025-04-19 20:27:27,104:INFO:Importing libraries
2025-04-19 20:27:27,104:INFO:Copying training dataset
2025-04-19 20:27:27,110:INFO:Defining folds
2025-04-19 20:27:27,110:INFO:Declaring metric variables
2025-04-19 20:27:27,111:INFO:Importing untrained model
2025-04-19 20:27:27,112:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 20:27:27,112:INFO:Starting cross validation
2025-04-19 20:27:27,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:30,018:INFO:Calculating mean and std
2025-04-19 20:27:30,018:INFO:Creating metrics dataframe
2025-04-19 20:27:30,619:INFO:Uploading results into container
2025-04-19 20:27:30,619:INFO:Uploading model into container now
2025-04-19 20:27:30,619:INFO:_master_model_container: 17
2025-04-19 20:27:30,619:INFO:_display_container: 2
2025-04-19 20:27:30,619:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-04-19 20:27:30,619:INFO:create_model() successfully completed......................................
2025-04-19 20:27:30,762:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:30,762:INFO:Creating metrics dataframe
2025-04-19 20:27:30,782:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 20:27:30,782:INFO:Total runtime is 0.9353063344955445 minutes
2025-04-19 20:27:30,782:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:30,782:INFO:Initializing create_model()
2025-04-19 20:27:30,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:30,782:INFO:Checking exceptions
2025-04-19 20:27:30,782:INFO:Importing libraries
2025-04-19 20:27:30,782:INFO:Copying training dataset
2025-04-19 20:27:30,794:INFO:Defining folds
2025-04-19 20:27:30,794:INFO:Declaring metric variables
2025-04-19 20:27:30,794:INFO:Importing untrained model
2025-04-19 20:27:30,794:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 20:27:30,794:INFO:Starting cross validation
2025-04-19 20:27:30,822:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:35,294:INFO:Calculating mean and std
2025-04-19 20:27:35,294:INFO:Creating metrics dataframe
2025-04-19 20:27:36,068:INFO:Uploading results into container
2025-04-19 20:27:36,068:INFO:Uploading model into container now
2025-04-19 20:27:36,068:INFO:_master_model_container: 18
2025-04-19 20:27:36,068:INFO:_display_container: 2
2025-04-19 20:27:36,080:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:27:36,080:INFO:create_model() successfully completed......................................
2025-04-19 20:27:36,228:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:36,230:INFO:Creating metrics dataframe
2025-04-19 20:27:36,243:INFO:Initializing Dummy Regressor
2025-04-19 20:27:36,243:INFO:Total runtime is 1.0263105114301045 minutes
2025-04-19 20:27:36,243:INFO:SubProcess create_model() called ==================================
2025-04-19 20:27:36,243:INFO:Initializing create_model()
2025-04-19 20:27:36,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB35E2200>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:36,244:INFO:Checking exceptions
2025-04-19 20:27:36,245:INFO:Importing libraries
2025-04-19 20:27:36,245:INFO:Copying training dataset
2025-04-19 20:27:36,246:INFO:Defining folds
2025-04-19 20:27:36,246:INFO:Declaring metric variables
2025-04-19 20:27:36,246:INFO:Importing untrained model
2025-04-19 20:27:36,246:INFO:Dummy Regressor Imported successfully
2025-04-19 20:27:36,246:INFO:Starting cross validation
2025-04-19 20:27:36,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:27:38,899:INFO:Calculating mean and std
2025-04-19 20:27:38,905:INFO:Creating metrics dataframe
2025-04-19 20:27:39,646:INFO:Uploading results into container
2025-04-19 20:27:39,646:INFO:Uploading model into container now
2025-04-19 20:27:39,646:INFO:_master_model_container: 19
2025-04-19 20:27:39,646:INFO:_display_container: 2
2025-04-19 20:27:39,646:INFO:DummyRegressor()
2025-04-19 20:27:39,646:INFO:create_model() successfully completed......................................
2025-04-19 20:27:39,789:INFO:SubProcess create_model() end ==================================
2025-04-19 20:27:39,789:INFO:Creating metrics dataframe
2025-04-19 20:27:39,806:INFO:Initializing create_model()
2025-04-19 20:27:39,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:39,806:INFO:Checking exceptions
2025-04-19 20:27:39,806:INFO:Importing libraries
2025-04-19 20:27:39,806:INFO:Copying training dataset
2025-04-19 20:27:39,828:INFO:Defining folds
2025-04-19 20:27:39,828:INFO:Declaring metric variables
2025-04-19 20:27:39,831:INFO:Importing untrained model
2025-04-19 20:27:39,831:INFO:Declaring custom model
2025-04-19 20:27:39,833:INFO:Huber Regressor Imported successfully
2025-04-19 20:27:39,852:INFO:Cross validation set to False
2025-04-19 20:27:39,852:INFO:Fitting Model
2025-04-19 20:27:40,321:INFO:HuberRegressor()
2025-04-19 20:27:40,321:INFO:create_model() successfully completed......................................
2025-04-19 20:27:40,456:INFO:Initializing create_model()
2025-04-19 20:27:40,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:40,456:INFO:Checking exceptions
2025-04-19 20:27:40,456:INFO:Importing libraries
2025-04-19 20:27:40,456:INFO:Copying training dataset
2025-04-19 20:27:40,472:INFO:Defining folds
2025-04-19 20:27:40,472:INFO:Declaring metric variables
2025-04-19 20:27:40,472:INFO:Importing untrained model
2025-04-19 20:27:40,472:INFO:Declaring custom model
2025-04-19 20:27:40,472:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:27:40,487:INFO:Cross validation set to False
2025-04-19 20:27:40,487:INFO:Fitting Model
2025-04-19 20:27:40,904:INFO:BayesianRidge()
2025-04-19 20:27:40,904:INFO:create_model() successfully completed......................................
2025-04-19 20:27:41,033:INFO:Initializing create_model()
2025-04-19 20:27:41,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:27:41,033:INFO:Checking exceptions
2025-04-19 20:27:41,033:INFO:Importing libraries
2025-04-19 20:27:41,033:INFO:Copying training dataset
2025-04-19 20:27:41,033:INFO:Defining folds
2025-04-19 20:27:41,044:INFO:Declaring metric variables
2025-04-19 20:27:41,045:INFO:Importing untrained model
2025-04-19 20:27:41,045:INFO:Declaring custom model
2025-04-19 20:27:41,045:INFO:Linear Regression Imported successfully
2025-04-19 20:27:41,057:INFO:Cross validation set to False
2025-04-19 20:27:41,057:INFO:Fitting Model
2025-04-19 20:27:41,414:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:27:41,414:INFO:create_model() successfully completed......................................
2025-04-19 20:27:41,609:INFO:_master_model_container: 19
2025-04-19 20:27:41,611:INFO:_display_container: 2
2025-04-19 20:27:41,611:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 20:27:41,611:INFO:compare_models() successfully completed......................................
2025-04-19 20:27:41,611:INFO:Initializing tune_model()
2025-04-19 20:27:41,611:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>)
2025-04-19 20:27:41,611:INFO:Checking exceptions
2025-04-19 20:27:41,616:INFO:Copying training dataset
2025-04-19 20:27:41,621:INFO:Checking base model
2025-04-19 20:27:41,621:INFO:Base model : Huber Regressor
2025-04-19 20:27:41,621:INFO:Declaring metric variables
2025-04-19 20:27:41,621:INFO:Defining Hyperparameters
2025-04-19 20:27:41,792:INFO:Tuning with n_jobs=-1
2025-04-19 20:27:41,792:INFO:Initializing RandomizedSearchCV
2025-04-19 20:28:13,668:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.3, 'actual_estimator__alpha': 0.3}
2025-04-19 20:28:13,669:INFO:Hyperparameter search completed
2025-04-19 20:28:13,669:INFO:SubProcess create_model() called ==================================
2025-04-19 20:28:13,670:INFO:Initializing create_model()
2025-04-19 20:28:13,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB5811210>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.3, 'alpha': 0.3})
2025-04-19 20:28:13,670:INFO:Checking exceptions
2025-04-19 20:28:13,670:INFO:Importing libraries
2025-04-19 20:28:13,670:INFO:Copying training dataset
2025-04-19 20:28:13,670:INFO:Defining folds
2025-04-19 20:28:13,670:INFO:Declaring metric variables
2025-04-19 20:28:13,670:INFO:Importing untrained model
2025-04-19 20:28:13,670:INFO:Declaring custom model
2025-04-19 20:28:13,670:INFO:Huber Regressor Imported successfully
2025-04-19 20:28:13,670:INFO:Starting cross validation
2025-04-19 20:28:13,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:28:16,175:INFO:Calculating mean and std
2025-04-19 20:28:16,175:INFO:Creating metrics dataframe
2025-04-19 20:28:16,175:INFO:Finalizing model
2025-04-19 20:28:16,907:INFO:Uploading results into container
2025-04-19 20:28:16,907:INFO:Uploading model into container now
2025-04-19 20:28:16,907:INFO:_master_model_container: 20
2025-04-19 20:28:16,907:INFO:_display_container: 3
2025-04-19 20:28:16,907:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:28:16,907:INFO:create_model() successfully completed......................................
2025-04-19 20:28:17,067:INFO:SubProcess create_model() end ==================================
2025-04-19 20:28:17,067:INFO:choose_better activated
2025-04-19 20:28:17,067:INFO:SubProcess create_model() called ==================================
2025-04-19 20:28:17,067:INFO:Initializing create_model()
2025-04-19 20:28:17,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:28:17,067:INFO:Checking exceptions
2025-04-19 20:28:17,067:INFO:Importing libraries
2025-04-19 20:28:17,067:INFO:Copying training dataset
2025-04-19 20:28:17,076:INFO:Defining folds
2025-04-19 20:28:17,076:INFO:Declaring metric variables
2025-04-19 20:28:17,076:INFO:Importing untrained model
2025-04-19 20:28:17,076:INFO:Declaring custom model
2025-04-19 20:28:17,076:INFO:Huber Regressor Imported successfully
2025-04-19 20:28:17,076:INFO:Starting cross validation
2025-04-19 20:28:17,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:28:19,684:INFO:Calculating mean and std
2025-04-19 20:28:19,685:INFO:Creating metrics dataframe
2025-04-19 20:28:19,689:INFO:Finalizing model
2025-04-19 20:28:20,448:INFO:Uploading results into container
2025-04-19 20:28:20,453:INFO:Uploading model into container now
2025-04-19 20:28:20,453:INFO:_master_model_container: 21
2025-04-19 20:28:20,453:INFO:_display_container: 4
2025-04-19 20:28:20,453:INFO:HuberRegressor()
2025-04-19 20:28:20,453:INFO:create_model() successfully completed......................................
2025-04-19 20:28:20,570:INFO:SubProcess create_model() end ==================================
2025-04-19 20:28:20,570:INFO:HuberRegressor() result for R2 is -0.0011
2025-04-19 20:28:20,570:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) result for R2 is -0.0008
2025-04-19 20:28:20,570:INFO:HuberRegressor(alpha=0.3, epsilon=1.3) is best model
2025-04-19 20:28:20,570:INFO:choose_better completed
2025-04-19 20:28:20,580:INFO:_master_model_container: 21
2025-04-19 20:28:20,580:INFO:_display_container: 3
2025-04-19 20:28:20,580:INFO:HuberRegressor(alpha=0.3, epsilon=1.3)
2025-04-19 20:28:20,580:INFO:tune_model() successfully completed......................................
2025-04-19 20:28:21,005:INFO:Initializing tune_model()
2025-04-19 20:28:21,005:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>)
2025-04-19 20:28:21,005:INFO:Checking exceptions
2025-04-19 20:28:21,021:INFO:Copying training dataset
2025-04-19 20:28:21,021:INFO:Checking base model
2025-04-19 20:28:21,021:INFO:Base model : Bayesian Ridge
2025-04-19 20:28:21,025:INFO:Declaring metric variables
2025-04-19 20:28:21,025:INFO:Defining Hyperparameters
2025-04-19 20:28:21,181:INFO:Tuning with n_jobs=-1
2025-04-19 20:28:21,181:INFO:Initializing RandomizedSearchCV
2025-04-19 20:28:48,758:INFO:best_params: {'actual_estimator__lambda_2': 0.005, 'actual_estimator__lambda_1': 0.001, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': False, 'actual_estimator__alpha_2': 0.01, 'actual_estimator__alpha_1': 0.0005}
2025-04-19 20:28:48,758:INFO:Hyperparameter search completed
2025-04-19 20:28:48,758:INFO:SubProcess create_model() called ==================================
2025-04-19 20:28:48,758:INFO:Initializing create_model()
2025-04-19 20:28:48,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB3AA04C0>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.005, 'lambda_1': 0.001, 'fit_intercept': True, 'compute_score': False, 'alpha_2': 0.01, 'alpha_1': 0.0005})
2025-04-19 20:28:48,758:INFO:Checking exceptions
2025-04-19 20:28:48,758:INFO:Importing libraries
2025-04-19 20:28:48,758:INFO:Copying training dataset
2025-04-19 20:28:48,768:INFO:Defining folds
2025-04-19 20:28:48,768:INFO:Declaring metric variables
2025-04-19 20:28:48,768:INFO:Importing untrained model
2025-04-19 20:28:48,768:INFO:Declaring custom model
2025-04-19 20:28:48,768:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:28:48,768:INFO:Starting cross validation
2025-04-19 20:28:48,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:28:50,768:INFO:Calculating mean and std
2025-04-19 20:28:50,769:INFO:Creating metrics dataframe
2025-04-19 20:28:50,770:INFO:Finalizing model
2025-04-19 20:28:51,066:INFO:Uploading results into container
2025-04-19 20:28:51,066:INFO:Uploading model into container now
2025-04-19 20:28:51,067:INFO:_master_model_container: 22
2025-04-19 20:28:51,067:INFO:_display_container: 4
2025-04-19 20:28:51,067:INFO:BayesianRidge(alpha_1=0.0005, alpha_2=0.01, lambda_1=0.001, lambda_2=0.005)
2025-04-19 20:28:51,067:INFO:create_model() successfully completed......................................
2025-04-19 20:28:51,172:INFO:SubProcess create_model() end ==================================
2025-04-19 20:28:51,172:INFO:choose_better activated
2025-04-19 20:28:51,173:INFO:SubProcess create_model() called ==================================
2025-04-19 20:28:51,173:INFO:Initializing create_model()
2025-04-19 20:28:51,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:28:51,173:INFO:Checking exceptions
2025-04-19 20:28:51,174:INFO:Importing libraries
2025-04-19 20:28:51,174:INFO:Copying training dataset
2025-04-19 20:28:51,177:INFO:Defining folds
2025-04-19 20:28:51,177:INFO:Declaring metric variables
2025-04-19 20:28:51,177:INFO:Importing untrained model
2025-04-19 20:28:51,178:INFO:Declaring custom model
2025-04-19 20:28:51,178:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:28:51,178:INFO:Starting cross validation
2025-04-19 20:28:51,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:28:53,022:INFO:Calculating mean and std
2025-04-19 20:28:53,022:INFO:Creating metrics dataframe
2025-04-19 20:28:53,022:INFO:Finalizing model
2025-04-19 20:28:53,353:INFO:Uploading results into container
2025-04-19 20:28:53,353:INFO:Uploading model into container now
2025-04-19 20:28:53,353:INFO:_master_model_container: 23
2025-04-19 20:28:53,353:INFO:_display_container: 5
2025-04-19 20:28:53,353:INFO:BayesianRidge()
2025-04-19 20:28:53,353:INFO:create_model() successfully completed......................................
2025-04-19 20:28:53,452:INFO:SubProcess create_model() end ==================================
2025-04-19 20:28:53,452:INFO:BayesianRidge() result for R2 is -0.0065
2025-04-19 20:28:53,452:INFO:BayesianRidge(alpha_1=0.0005, alpha_2=0.01, lambda_1=0.001, lambda_2=0.005) result for R2 is -0.0065
2025-04-19 20:28:53,452:INFO:BayesianRidge() is best model
2025-04-19 20:28:53,452:INFO:choose_better completed
2025-04-19 20:28:53,452:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:28:53,472:INFO:_master_model_container: 23
2025-04-19 20:28:53,472:INFO:_display_container: 4
2025-04-19 20:28:53,472:INFO:BayesianRidge()
2025-04-19 20:28:53,472:INFO:tune_model() successfully completed......................................
2025-04-19 20:28:53,799:INFO:Initializing tune_model()
2025-04-19 20:28:53,799:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>)
2025-04-19 20:28:53,799:INFO:Checking exceptions
2025-04-19 20:28:53,799:INFO:Copying training dataset
2025-04-19 20:28:53,799:INFO:Checking base model
2025-04-19 20:28:53,799:INFO:Base model : Linear Regression
2025-04-19 20:28:53,799:INFO:Declaring metric variables
2025-04-19 20:28:53,799:INFO:Defining Hyperparameters
2025-04-19 20:28:53,799:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 20:28:53,928:INFO:Tuning with n_jobs=-1
2025-04-19 20:28:53,928:INFO:Initializing GridSearchCV
2025-04-19 20:28:57,893:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 20:28:57,893:INFO:Hyperparameter search completed
2025-04-19 20:28:57,893:INFO:SubProcess create_model() called ==================================
2025-04-19 20:28:57,893:INFO:Initializing create_model()
2025-04-19 20:28:57,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB40497B0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 20:28:57,893:INFO:Checking exceptions
2025-04-19 20:28:57,893:INFO:Importing libraries
2025-04-19 20:28:57,893:INFO:Copying training dataset
2025-04-19 20:28:57,893:INFO:Defining folds
2025-04-19 20:28:57,893:INFO:Declaring metric variables
2025-04-19 20:28:57,893:INFO:Importing untrained model
2025-04-19 20:28:57,893:INFO:Declaring custom model
2025-04-19 20:28:57,893:INFO:Linear Regression Imported successfully
2025-04-19 20:28:57,893:INFO:Starting cross validation
2025-04-19 20:28:57,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:29:00,044:INFO:Calculating mean and std
2025-04-19 20:29:00,045:INFO:Creating metrics dataframe
2025-04-19 20:29:00,047:INFO:Finalizing model
2025-04-19 20:29:00,452:INFO:Uploading results into container
2025-04-19 20:29:00,452:INFO:Uploading model into container now
2025-04-19 20:29:00,453:INFO:_master_model_container: 24
2025-04-19 20:29:00,453:INFO:_display_container: 5
2025-04-19 20:29:00,453:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:29:00,453:INFO:create_model() successfully completed......................................
2025-04-19 20:29:00,582:INFO:SubProcess create_model() end ==================================
2025-04-19 20:29:00,583:INFO:choose_better activated
2025-04-19 20:29:00,583:INFO:SubProcess create_model() called ==================================
2025-04-19 20:29:00,583:INFO:Initializing create_model()
2025-04-19 20:29:00,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:29:00,583:INFO:Checking exceptions
2025-04-19 20:29:00,583:INFO:Importing libraries
2025-04-19 20:29:00,583:INFO:Copying training dataset
2025-04-19 20:29:00,590:INFO:Defining folds
2025-04-19 20:29:00,590:INFO:Declaring metric variables
2025-04-19 20:29:00,590:INFO:Importing untrained model
2025-04-19 20:29:00,590:INFO:Declaring custom model
2025-04-19 20:29:00,591:INFO:Linear Regression Imported successfully
2025-04-19 20:29:00,591:INFO:Starting cross validation
2025-04-19 20:29:00,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:29:02,884:INFO:Calculating mean and std
2025-04-19 20:29:02,884:INFO:Creating metrics dataframe
2025-04-19 20:29:02,886:INFO:Finalizing model
2025-04-19 20:29:03,409:INFO:Uploading results into container
2025-04-19 20:29:03,409:INFO:Uploading model into container now
2025-04-19 20:29:03,409:INFO:_master_model_container: 25
2025-04-19 20:29:03,409:INFO:_display_container: 6
2025-04-19 20:29:03,409:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:29:03,409:INFO:create_model() successfully completed......................................
2025-04-19 20:29:03,525:INFO:SubProcess create_model() end ==================================
2025-04-19 20:29:03,526:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0067
2025-04-19 20:29:03,526:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0067
2025-04-19 20:29:03,526:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 20:29:03,526:INFO:choose_better completed
2025-04-19 20:29:03,526:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 20:29:03,547:INFO:_master_model_container: 25
2025-04-19 20:29:03,548:INFO:_display_container: 5
2025-04-19 20:29:03,548:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:29:03,548:INFO:tune_model() successfully completed......................................
2025-04-19 20:29:03,907:INFO:Initializing blend_models()
2025-04-19 20:29:03,907:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), BayesianRidge(), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:29:03,907:INFO:Checking exceptions
2025-04-19 20:29:03,907:INFO:Importing libraries
2025-04-19 20:29:03,907:INFO:Copying training dataset
2025-04-19 20:29:03,907:INFO:Getting model names
2025-04-19 20:29:03,907:INFO:SubProcess create_model() called ==================================
2025-04-19 20:29:03,907:INFO:Initializing create_model()
2025-04-19 20:29:03,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECA975DD50>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:29:03,907:INFO:Checking exceptions
2025-04-19 20:29:03,907:INFO:Importing libraries
2025-04-19 20:29:03,907:INFO:Copying training dataset
2025-04-19 20:29:03,922:INFO:Defining folds
2025-04-19 20:29:03,922:INFO:Declaring metric variables
2025-04-19 20:29:03,922:INFO:Importing untrained model
2025-04-19 20:29:03,923:INFO:Declaring custom model
2025-04-19 20:29:03,923:INFO:Voting Regressor Imported successfully
2025-04-19 20:29:03,923:INFO:Starting cross validation
2025-04-19 20:29:03,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:29:06,017:INFO:Calculating mean and std
2025-04-19 20:29:06,019:INFO:Creating metrics dataframe
2025-04-19 20:29:06,020:INFO:Finalizing model
2025-04-19 20:29:06,499:INFO:Uploading results into container
2025-04-19 20:29:06,499:INFO:Uploading model into container now
2025-04-19 20:29:06,499:INFO:_master_model_container: 26
2025-04-19 20:29:06,499:INFO:_display_container: 6
2025-04-19 20:29:06,499:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:29:06,499:INFO:create_model() successfully completed......................................
2025-04-19 20:29:06,617:INFO:SubProcess create_model() end ==================================
2025-04-19 20:29:06,621:INFO:_master_model_container: 26
2025-04-19 20:29:06,621:INFO:_display_container: 6
2025-04-19 20:29:06,621:INFO:VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 20:29:06,621:INFO:blend_models() successfully completed......................................
2025-04-19 20:29:06,753:INFO:Initializing stack_models()
2025-04-19 20:29:06,753:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator_list=[HuberRegressor(alpha=0.3, epsilon=1.3), BayesianRidge(), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 20:29:06,753:INFO:Checking exceptions
2025-04-19 20:29:06,755:INFO:Defining meta model
2025-04-19 20:29:06,756:INFO:Getting model names
2025-04-19 20:29:06,756:INFO:[('Huber Regressor', HuberRegressor(alpha=0.3, epsilon=1.3)), ('Bayesian Ridge', BayesianRidge()), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 20:29:06,757:INFO:SubProcess create_model() called ==================================
2025-04-19 20:29:06,759:INFO:Initializing create_model()
2025-04-19 20:29:06,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002ECB2FFEA70>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:29:06,759:INFO:Checking exceptions
2025-04-19 20:29:06,759:INFO:Importing libraries
2025-04-19 20:29:06,759:INFO:Copying training dataset
2025-04-19 20:29:06,761:INFO:Defining folds
2025-04-19 20:29:06,761:INFO:Declaring metric variables
2025-04-19 20:29:06,762:INFO:Importing untrained model
2025-04-19 20:29:06,762:INFO:Declaring custom model
2025-04-19 20:29:06,762:INFO:Stacking Regressor Imported successfully
2025-04-19 20:29:06,763:INFO:Starting cross validation
2025-04-19 20:29:06,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:29:09,186:INFO:Calculating mean and std
2025-04-19 20:29:09,186:INFO:Creating metrics dataframe
2025-04-19 20:29:09,186:INFO:Finalizing model
2025-04-19 20:29:09,653:INFO:Uploading results into container
2025-04-19 20:29:09,654:INFO:Uploading model into container now
2025-04-19 20:29:09,654:INFO:_master_model_container: 27
2025-04-19 20:29:09,654:INFO:_display_container: 7
2025-04-19 20:29:09,656:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:29:09,657:INFO:create_model() successfully completed......................................
2025-04-19 20:29:09,753:INFO:SubProcess create_model() end ==================================
2025-04-19 20:29:09,760:INFO:_master_model_container: 27
2025-04-19 20:29:09,760:INFO:_display_container: 7
2025-04-19 20:29:09,762:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 20:29:09,762:INFO:stack_models() successfully completed......................................
2025-04-19 20:29:09,867:INFO:Initializing save_model()
2025-04-19 20:29:09,867:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:29:09,877:INFO:Adding model into prep_pipe
2025-04-19 20:29:09,909:INFO:models/model_1.pkl saved in current working directory
2025-04-19 20:29:09,922:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor(alpha=0.3,
                                                             epsilon=1.3)),
                                             ('Bayesian Ridge',
                                              BayesianRidge()),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 20:29:09,922:INFO:save_model() successfully completed......................................
2025-04-19 20:29:10,201:INFO:Initializing plot_model()
2025-04-19 20:29:10,201:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:10,201:INFO:Checking exceptions
2025-04-19 20:29:10,204:INFO:Initializing plot_model()
2025-04-19 20:29:10,205:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:10,205:INFO:Checking exceptions
2025-04-19 20:29:10,206:INFO:Preloading libraries
2025-04-19 20:29:10,206:INFO:Copying training dataset
2025-04-19 20:29:10,206:INFO:Plot type: residuals
2025-04-19 20:29:10,554:INFO:Fitting Model
2025-04-19 20:29:10,554:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:10,589:INFO:Scoring test/hold-out set
2025-04-19 20:29:10,618:INFO:Saving 'Residuals.png'
2025-04-19 20:29:11,448:INFO:Visual Rendered Successfully
2025-04-19 20:29:11,590:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:11,771:INFO:Initializing plot_model()
2025-04-19 20:29:11,771:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:11,771:INFO:Checking exceptions
2025-04-19 20:29:11,773:INFO:Preloading libraries
2025-04-19 20:29:11,773:INFO:Copying training dataset
2025-04-19 20:29:11,773:INFO:Plot type: error
2025-04-19 20:29:12,032:INFO:Fitting Model
2025-04-19 20:29:12,032:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:12,032:INFO:Scoring test/hold-out set
2025-04-19 20:29:12,055:INFO:Saving 'Prediction Error.png'
2025-04-19 20:29:12,385:INFO:Visual Rendered Successfully
2025-04-19 20:29:12,578:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:12,808:INFO:Initializing plot_model()
2025-04-19 20:29:12,808:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:12,808:INFO:Checking exceptions
2025-04-19 20:29:12,809:INFO:Preloading libraries
2025-04-19 20:29:12,810:INFO:Copying training dataset
2025-04-19 20:29:12,810:INFO:Plot type: learning
2025-04-19 20:29:13,068:INFO:Fitting Model
2025-04-19 20:29:13,821:INFO:Saving 'Learning Curve.png'
2025-04-19 20:29:14,158:INFO:Visual Rendered Successfully
2025-04-19 20:29:14,284:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:14,521:INFO:Initializing save_model()
2025-04-19 20:29:14,521:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:29:14,521:INFO:Adding model into prep_pipe
2025-04-19 20:29:14,562:INFO:models/model_2.pkl saved in current working directory
2025-04-19 20:29:14,579:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor(alpha=0.3,
                                                               epsilon=1.3)),
                                               ('Bayesian Ridge',
                                                BayesianRidge()),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 20:29:14,579:INFO:save_model() successfully completed......................................
2025-04-19 20:29:14,855:INFO:Initializing plot_model()
2025-04-19 20:29:14,855:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:14,855:INFO:Checking exceptions
2025-04-19 20:29:14,868:INFO:Initializing plot_model()
2025-04-19 20:29:14,868:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:14,868:INFO:Checking exceptions
2025-04-19 20:29:14,870:INFO:Preloading libraries
2025-04-19 20:29:14,870:INFO:Copying training dataset
2025-04-19 20:29:14,870:INFO:Plot type: residuals
2025-04-19 20:29:15,155:INFO:Fitting Model
2025-04-19 20:29:15,155:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:15,196:INFO:Scoring test/hold-out set
2025-04-19 20:29:15,230:INFO:Saving 'Residuals.png'
2025-04-19 20:29:16,068:INFO:Visual Rendered Successfully
2025-04-19 20:29:16,182:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:16,381:INFO:Initializing plot_model()
2025-04-19 20:29:16,381:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:16,381:INFO:Checking exceptions
2025-04-19 20:29:16,383:INFO:Preloading libraries
2025-04-19 20:29:16,383:INFO:Copying training dataset
2025-04-19 20:29:16,383:INFO:Plot type: error
2025-04-19 20:29:16,658:INFO:Fitting Model
2025-04-19 20:29:16,658:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:16,658:INFO:Scoring test/hold-out set
2025-04-19 20:29:16,681:INFO:Saving 'Prediction Error.png'
2025-04-19 20:29:17,038:INFO:Visual Rendered Successfully
2025-04-19 20:29:17,151:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:17,301:INFO:Initializing plot_model()
2025-04-19 20:29:17,301:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor',
                               HuberRegressor(alpha=0.3, epsilon=1.3)),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:17,301:INFO:Checking exceptions
2025-04-19 20:29:17,302:INFO:Preloading libraries
2025-04-19 20:29:17,302:INFO:Copying training dataset
2025-04-19 20:29:17,302:INFO:Plot type: learning
2025-04-19 20:29:17,570:INFO:Fitting Model
2025-04-19 20:29:19,096:INFO:Saving 'Learning Curve.png'
2025-04-19 20:29:19,471:INFO:Visual Rendered Successfully
2025-04-19 20:29:19,604:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:19,763:INFO:Initializing save_model()
2025-04-19 20:29:19,763:INFO:save_model(model=HuberRegressor(alpha=0.3, epsilon=1.3), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:29:19,763:INFO:Adding model into prep_pipe
2025-04-19 20:29:19,796:INFO:models/model_3.pkl saved in current working directory
2025-04-19 20:29:19,800:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor(alpha=0.3, epsilon=1.3))])
2025-04-19 20:29:19,800:INFO:save_model() successfully completed......................................
2025-04-19 20:29:20,064:INFO:Initializing plot_model()
2025-04-19 20:29:20,064:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:20,064:INFO:Checking exceptions
2025-04-19 20:29:20,066:INFO:Preloading libraries
2025-04-19 20:29:20,066:INFO:Copying training dataset
2025-04-19 20:29:20,066:INFO:Plot type: feature
2025-04-19 20:29:20,232:INFO:Saving 'Feature Importance.png'
2025-04-19 20:29:20,373:INFO:Visual Rendered Successfully
2025-04-19 20:29:20,453:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:20,591:INFO:Initializing plot_model()
2025-04-19 20:29:20,591:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:20,591:INFO:Checking exceptions
2025-04-19 20:29:20,591:INFO:Preloading libraries
2025-04-19 20:29:20,591:INFO:Copying training dataset
2025-04-19 20:29:20,591:INFO:Plot type: residuals
2025-04-19 20:29:20,859:INFO:Fitting Model
2025-04-19 20:29:20,859:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:20,875:INFO:Scoring test/hold-out set
2025-04-19 20:29:20,918:INFO:Saving 'Residuals.png'
2025-04-19 20:29:21,706:INFO:Visual Rendered Successfully
2025-04-19 20:29:21,854:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:21,993:INFO:Initializing plot_model()
2025-04-19 20:29:21,993:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:21,993:INFO:Checking exceptions
2025-04-19 20:29:22,009:INFO:Preloading libraries
2025-04-19 20:29:22,009:INFO:Copying training dataset
2025-04-19 20:29:22,009:INFO:Plot type: error
2025-04-19 20:29:22,223:INFO:Fitting Model
2025-04-19 20:29:22,223:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 20:29:22,223:INFO:Scoring test/hold-out set
2025-04-19 20:29:22,234:INFO:Saving 'Prediction Error.png'
2025-04-19 20:29:22,582:INFO:Visual Rendered Successfully
2025-04-19 20:29:22,696:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:22,922:INFO:Initializing plot_model()
2025-04-19 20:29:22,922:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(alpha=0.3, epsilon=1.3), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:22,922:INFO:Checking exceptions
2025-04-19 20:29:22,924:INFO:Preloading libraries
2025-04-19 20:29:22,924:INFO:Copying training dataset
2025-04-19 20:29:22,924:INFO:Plot type: learning
2025-04-19 20:29:23,178:INFO:Fitting Model
2025-04-19 20:29:23,414:INFO:Saving 'Learning Curve.png'
2025-04-19 20:29:23,713:INFO:Visual Rendered Successfully
2025-04-19 20:29:23,834:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:24,144:INFO:Initializing save_model()
2025-04-19 20:29:24,144:INFO:save_model(model=BayesianRidge(), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:29:24,144:INFO:Adding model into prep_pipe
2025-04-19 20:29:24,208:INFO:models/model_4.pkl saved in current working directory
2025-04-19 20:29:24,226:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', BayesianRidge())])
2025-04-19 20:29:24,226:INFO:save_model() successfully completed......................................
2025-04-19 20:29:24,588:INFO:Initializing plot_model()
2025-04-19 20:29:24,588:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:24,588:INFO:Checking exceptions
2025-04-19 20:29:24,588:INFO:Preloading libraries
2025-04-19 20:29:24,588:INFO:Copying training dataset
2025-04-19 20:29:24,588:INFO:Plot type: feature
2025-04-19 20:29:24,776:INFO:Saving 'Feature Importance.png'
2025-04-19 20:29:24,967:INFO:Visual Rendered Successfully
2025-04-19 20:29:25,087:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:25,257:INFO:Initializing plot_model()
2025-04-19 20:29:25,257:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:25,257:INFO:Checking exceptions
2025-04-19 20:29:25,257:INFO:Preloading libraries
2025-04-19 20:29:25,257:INFO:Copying training dataset
2025-04-19 20:29:25,257:INFO:Plot type: residuals
2025-04-19 20:29:25,607:INFO:Fitting Model
2025-04-19 20:29:25,607:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 20:29:25,638:INFO:Scoring test/hold-out set
2025-04-19 20:29:25,674:INFO:Saving 'Residuals.png'
2025-04-19 20:29:26,587:INFO:Visual Rendered Successfully
2025-04-19 20:29:26,736:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:26,933:INFO:Initializing plot_model()
2025-04-19 20:29:26,933:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:26,933:INFO:Checking exceptions
2025-04-19 20:29:26,933:INFO:Preloading libraries
2025-04-19 20:29:26,933:INFO:Copying training dataset
2025-04-19 20:29:26,933:INFO:Plot type: error
2025-04-19 20:29:27,255:INFO:Fitting Model
2025-04-19 20:29:27,255:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 20:29:27,255:INFO:Scoring test/hold-out set
2025-04-19 20:29:27,266:INFO:Saving 'Prediction Error.png'
2025-04-19 20:29:27,619:INFO:Visual Rendered Successfully
2025-04-19 20:29:27,748:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:27,966:INFO:Initializing plot_model()
2025-04-19 20:29:27,966:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:27,966:INFO:Checking exceptions
2025-04-19 20:29:27,968:INFO:Preloading libraries
2025-04-19 20:29:27,968:INFO:Copying training dataset
2025-04-19 20:29:27,968:INFO:Plot type: learning
2025-04-19 20:29:28,286:INFO:Fitting Model
2025-04-19 20:29:28,508:INFO:Saving 'Learning Curve.png'
2025-04-19 20:29:28,781:INFO:Visual Rendered Successfully
2025-04-19 20:29:28,888:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:29,029:INFO:Initializing save_model()
2025-04-19 20:29:29,029:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 20:29:29,029:INFO:Adding model into prep_pipe
2025-04-19 20:29:29,068:INFO:models/model_5.pkl saved in current working directory
2025-04-19 20:29:29,083:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_11',
                                             'feature_20', 'feature_49'],
                                    transformer=SimpleImputer())...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 20:29:29,083:INFO:save_model() successfully completed......................................
2025-04-19 20:29:29,369:INFO:Initializing plot_model()
2025-04-19 20:29:29,369:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:29,369:INFO:Checking exceptions
2025-04-19 20:29:29,369:INFO:Preloading libraries
2025-04-19 20:29:29,369:INFO:Copying training dataset
2025-04-19 20:29:29,369:INFO:Plot type: feature
2025-04-19 20:29:29,537:INFO:Saving 'Feature Importance.png'
2025-04-19 20:29:29,683:INFO:Visual Rendered Successfully
2025-04-19 20:29:29,801:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:29,970:INFO:Initializing plot_model()
2025-04-19 20:29:29,970:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:29,970:INFO:Checking exceptions
2025-04-19 20:29:29,972:INFO:Preloading libraries
2025-04-19 20:29:29,972:INFO:Copying training dataset
2025-04-19 20:29:29,972:INFO:Plot type: residuals
2025-04-19 20:29:30,284:INFO:Fitting Model
2025-04-19 20:29:30,284:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 20:29:30,300:INFO:Scoring test/hold-out set
2025-04-19 20:29:30,338:INFO:Saving 'Residuals.png'
2025-04-19 20:29:31,132:INFO:Visual Rendered Successfully
2025-04-19 20:29:31,259:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:31,434:INFO:Initializing plot_model()
2025-04-19 20:29:31,434:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:31,434:INFO:Checking exceptions
2025-04-19 20:29:31,434:INFO:Preloading libraries
2025-04-19 20:29:31,434:INFO:Copying training dataset
2025-04-19 20:29:31,434:INFO:Plot type: error
2025-04-19 20:29:31,673:INFO:Fitting Model
2025-04-19 20:29:31,673:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 20:29:31,673:INFO:Scoring test/hold-out set
2025-04-19 20:29:31,688:INFO:Saving 'Prediction Error.png'
2025-04-19 20:29:32,054:INFO:Visual Rendered Successfully
2025-04-19 20:29:32,172:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:32,376:INFO:Initializing plot_model()
2025-04-19 20:29:32,376:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, system=True)
2025-04-19 20:29:32,376:INFO:Checking exceptions
2025-04-19 20:29:32,376:INFO:Preloading libraries
2025-04-19 20:29:32,378:INFO:Copying training dataset
2025-04-19 20:29:32,378:INFO:Plot type: learning
2025-04-19 20:29:32,654:INFO:Fitting Model
2025-04-19 20:29:32,853:INFO:Saving 'Learning Curve.png'
2025-04-19 20:29:33,209:INFO:Visual Rendered Successfully
2025-04-19 20:29:33,321:INFO:plot_model() successfully completed......................................
2025-04-19 20:29:33,502:INFO:Initializing predict_model()
2025-04-19 20:29:33,502:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002ECB4366C50>, estimator=VotingRegressor(estimators=[('Huber Regressor',
                             HuberRegressor(alpha=0.3, epsilon=1.3)),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002ECAB5477F0>)
2025-04-19 20:29:33,502:INFO:Checking exceptions
2025-04-19 20:29:33,502:INFO:Preloading libraries
2025-04-19 20:29:33,502:INFO:Set up data.
2025-04-19 20:29:33,502:INFO:Set up index.
2025-04-19 20:45:19,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:45:19,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:45:19,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:45:19,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 20:46:01,623:INFO:PyCaret RegressionExperiment
2025-04-19 20:46:01,623:INFO:Logging name: agn_modeling
2025-04-19 20:46:01,623:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 20:46:01,623:INFO:version 3.0.4
2025-04-19 20:46:01,623:INFO:Initializing setup()
2025-04-19 20:46:01,623:INFO:self.USI: 492a
2025-04-19 20:46:01,623:INFO:self._variable_keys: {'logging_param', 'fold_shuffle_param', 'transform_target_param', 'exp_name_log', 'n_jobs_param', 'USI', '_ml_usecase', 'y_train', 'html_param', 'fold_generator', 'y_test', 'target_param', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'data', 'exp_id', 'gpu_param', 'X_test', '_available_plots', 'memory', 'fold_groups_param', 'pipeline', 'seed', 'idx', 'X_train', 'X'}
2025-04-19 20:46:01,623:INFO:Checking environment
2025-04-19 20:46:01,623:INFO:python_version: 3.10.9
2025-04-19 20:46:01,623:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 20:46:01,623:INFO:machine: AMD64
2025-04-19 20:46:01,629:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 20:46:01,636:INFO:Memory: svmem(total=16952647680, available=2670542848, percent=84.2, used=14282104832, free=2670542848)
2025-04-19 20:46:01,636:INFO:Physical Core: 4
2025-04-19 20:46:01,636:INFO:Logical Core: 8
2025-04-19 20:46:01,636:INFO:Checking libraries
2025-04-19 20:46:01,636:INFO:System:
2025-04-19 20:46:01,636:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 20:46:01,636:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 20:46:01,636:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 20:46:01,636:INFO:PyCaret required dependencies:
2025-04-19 20:46:02,334:INFO:                 pip: 25.0.1
2025-04-19 20:46:02,334:INFO:          setuptools: 65.5.0
2025-04-19 20:46:02,334:INFO:             pycaret: 3.0.4
2025-04-19 20:46:02,334:INFO:             IPython: 8.35.0
2025-04-19 20:46:02,334:INFO:          ipywidgets: 8.1.6
2025-04-19 20:46:02,334:INFO:                tqdm: 4.67.1
2025-04-19 20:46:02,334:INFO:               numpy: 1.23.5
2025-04-19 20:46:02,334:INFO:              pandas: 1.5.3
2025-04-19 20:46:02,334:INFO:              jinja2: 3.1.6
2025-04-19 20:46:02,334:INFO:               scipy: 1.11.4
2025-04-19 20:46:02,334:INFO:              joblib: 1.2.0
2025-04-19 20:46:02,334:INFO:             sklearn: 1.2.2
2025-04-19 20:46:02,334:INFO:                pyod: 2.0.4
2025-04-19 20:46:02,334:INFO:            imblearn: 0.12.4
2025-04-19 20:46:02,334:INFO:   category_encoders: 2.7.0
2025-04-19 20:46:02,334:INFO:            lightgbm: 4.6.0
2025-04-19 20:46:02,334:INFO:               numba: 0.58.1
2025-04-19 20:46:02,334:INFO:            requests: 2.32.3
2025-04-19 20:46:02,334:INFO:          matplotlib: 3.7.1
2025-04-19 20:46:02,334:INFO:          scikitplot: 0.3.7
2025-04-19 20:46:02,334:INFO:         yellowbrick: 1.5
2025-04-19 20:46:02,334:INFO:              plotly: 5.24.1
2025-04-19 20:46:02,334:INFO:    plotly-resampler: Not installed
2025-04-19 20:46:02,334:INFO:             kaleido: 0.2.1
2025-04-19 20:46:02,334:INFO:           schemdraw: 0.15
2025-04-19 20:46:02,334:INFO:         statsmodels: 0.14.4
2025-04-19 20:46:02,334:INFO:              sktime: 0.21.1
2025-04-19 20:46:02,334:INFO:               tbats: 1.1.3
2025-04-19 20:46:02,334:INFO:            pmdarima: 2.0.4
2025-04-19 20:46:02,334:INFO:              psutil: 7.0.0
2025-04-19 20:46:02,334:INFO:          markupsafe: 2.1.5
2025-04-19 20:46:02,334:INFO:             pickle5: Not installed
2025-04-19 20:46:02,334:INFO:         cloudpickle: 2.2.1
2025-04-19 20:46:02,334:INFO:         deprecation: 2.1.0
2025-04-19 20:46:02,334:INFO:              xxhash: 3.5.0
2025-04-19 20:46:02,334:INFO:           wurlitzer: Not installed
2025-04-19 20:46:02,334:INFO:PyCaret optional dependencies:
2025-04-19 20:46:27,148:INFO:                shap: 0.47.2
2025-04-19 20:46:27,148:INFO:           interpret: 0.6.6
2025-04-19 20:46:27,148:INFO:                umap: 0.5.7
2025-04-19 20:46:27,148:INFO:    pandas_profiling: Not installed
2025-04-19 20:46:27,150:INFO:  explainerdashboard: Not installed
2025-04-19 20:46:27,150:INFO:             autoviz: Not installed
2025-04-19 20:46:27,150:INFO:           fairlearn: 0.7.0
2025-04-19 20:46:27,150:INFO:          deepchecks: Not installed
2025-04-19 20:46:27,150:INFO:             xgboost: 1.6.2
2025-04-19 20:46:27,150:INFO:            catboost: 1.2.8
2025-04-19 20:46:27,150:INFO:              kmodes: 0.12.2
2025-04-19 20:46:27,150:INFO:             mlxtend: 0.23.1
2025-04-19 20:46:27,150:INFO:       statsforecast: 2.0.1
2025-04-19 20:46:27,150:INFO:        tune_sklearn: Not installed
2025-04-19 20:46:27,150:INFO:                 ray: 2.44.1
2025-04-19 20:46:27,150:INFO:            hyperopt: 0.2.7
2025-04-19 20:46:27,150:INFO:              optuna: Not installed
2025-04-19 20:46:27,150:INFO:               skopt: 0.10.2
2025-04-19 20:46:27,150:INFO:              mlflow: 2.21.3
2025-04-19 20:46:27,150:INFO:              gradio: Not installed
2025-04-19 20:46:27,150:INFO:             fastapi: 0.115.12
2025-04-19 20:46:27,150:INFO:             uvicorn: 0.34.2
2025-04-19 20:46:27,150:INFO:              m2cgen: 0.10.0
2025-04-19 20:46:27,150:INFO:           evidently: Not installed
2025-04-19 20:46:27,150:INFO:               fugue: 0.9.1
2025-04-19 20:46:27,150:INFO:           streamlit: Not installed
2025-04-19 20:46:27,150:INFO:             prophet: Not installed
2025-04-19 20:46:27,150:INFO:None
2025-04-19 20:46:27,150:INFO:Set up data.
2025-04-19 20:46:27,158:INFO:Set up train/test split.
2025-04-19 20:46:27,159:INFO:Set up index.
2025-04-19 20:46:27,159:INFO:Set up folding strategy.
2025-04-19 20:46:27,159:INFO:Assigning column types.
2025-04-19 20:46:27,159:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 20:46:27,159:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:46:27,170:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:46:27,176:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:46:27,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:46:27,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:46:27,277:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:46:47,527:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:12,749:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,757:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,925:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:12,930:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:12,933:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 20:47:12,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:47:12,945:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,095:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,098:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,106:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,110:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,272:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,276:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,276:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 20:47:13,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,374:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,439:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,443:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,458:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,589:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,592:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,593:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 20:47:13,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,746:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,751:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 20:47:13,896:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:13,899:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:13,900:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 20:47:13,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:14,053:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:14,055:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:14,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 20:47:14,218:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:14,223:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:14,224:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 20:47:14,420:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:14,426:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:14,630:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:14,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:14,658:INFO:Preparing preprocessing pipeline...
2025-04-19 20:47:14,658:INFO:Set up target transformation.
2025-04-19 20:47:14,658:INFO:Set up simple imputation.
2025-04-19 20:47:14,658:INFO:Set up removing multicollinearity.
2025-04-19 20:47:14,658:INFO:Set up removing outliers.
2025-04-19 20:47:14,658:INFO:Set up feature normalization.
2025-04-19 20:47:15,045:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:15,810:INFO:Finished creating preprocessing pipeline.
2025-04-19 20:47:15,831:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 20:47:15,831:INFO:Creating final display dataframe.
2025-04-19 20:47:16,199:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:17,160:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape    (7999, 13)
4        Transformed data shape    (7719, 12)
5   Transformed train set shape    (5319, 12)
6    Transformed test set shape    (2400, 12)
7              Numeric features            12
8      Rows with missing values         21.9%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          492a
2025-04-19 20:47:17,360:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:17,366:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:17,548:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 20:47:17,553:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 20:47:17,555:INFO:setup() successfully completed in 76.13s...............
2025-04-19 20:47:17,556:INFO:Initializing compare_models()
2025-04-19 20:47:17,557:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 20:47:17,557:INFO:Checking exceptions
2025-04-19 20:47:17,560:INFO:Preparing display monitor
2025-04-19 20:47:17,566:INFO:Initializing Linear Regression
2025-04-19 20:47:17,567:INFO:Total runtime is 1.6641616821289062e-05 minutes
2025-04-19 20:47:17,567:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:17,567:INFO:Initializing create_model()
2025-04-19 20:47:17,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:17,568:INFO:Checking exceptions
2025-04-19 20:47:17,568:INFO:Importing libraries
2025-04-19 20:47:17,568:INFO:Copying training dataset
2025-04-19 20:47:17,576:INFO:Defining folds
2025-04-19 20:47:17,576:INFO:Declaring metric variables
2025-04-19 20:47:17,576:INFO:Importing untrained model
2025-04-19 20:47:17,577:INFO:Linear Regression Imported successfully
2025-04-19 20:47:17,577:INFO:Starting cross validation
2025-04-19 20:47:17,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:47:32,154:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:32,316:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:32,623:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:32,893:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:33,025:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:33,140:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:33,436:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:34,133:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:34,756:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:34,942:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 20:47:38,341:INFO:Calculating mean and std
2025-04-19 20:47:38,343:INFO:Creating metrics dataframe
2025-04-19 20:47:39,002:INFO:Uploading results into container
2025-04-19 20:47:39,004:INFO:Uploading model into container now
2025-04-19 20:47:39,007:INFO:_master_model_container: 1
2025-04-19 20:47:39,007:INFO:_display_container: 2
2025-04-19 20:47:39,008:INFO:LinearRegression(n_jobs=-1)
2025-04-19 20:47:39,008:INFO:create_model() successfully completed......................................
2025-04-19 20:47:39,418:INFO:SubProcess create_model() end ==================================
2025-04-19 20:47:39,419:INFO:Creating metrics dataframe
2025-04-19 20:47:39,431:INFO:Initializing Lasso Regression
2025-04-19 20:47:39,432:INFO:Total runtime is 0.36443653106689455 minutes
2025-04-19 20:47:39,432:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:39,432:INFO:Initializing create_model()
2025-04-19 20:47:39,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:39,433:INFO:Checking exceptions
2025-04-19 20:47:39,433:INFO:Importing libraries
2025-04-19 20:47:39,433:INFO:Copying training dataset
2025-04-19 20:47:39,445:INFO:Defining folds
2025-04-19 20:47:39,445:INFO:Declaring metric variables
2025-04-19 20:47:39,445:INFO:Importing untrained model
2025-04-19 20:47:39,446:INFO:Lasso Regression Imported successfully
2025-04-19 20:47:39,446:INFO:Starting cross validation
2025-04-19 20:47:39,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:47:43,992:INFO:Calculating mean and std
2025-04-19 20:47:43,993:INFO:Creating metrics dataframe
2025-04-19 20:47:44,530:INFO:Uploading results into container
2025-04-19 20:47:44,530:INFO:Uploading model into container now
2025-04-19 20:47:44,530:INFO:_master_model_container: 2
2025-04-19 20:47:44,530:INFO:_display_container: 2
2025-04-19 20:47:44,532:INFO:Lasso(random_state=42)
2025-04-19 20:47:44,532:INFO:create_model() successfully completed......................................
2025-04-19 20:47:44,730:INFO:SubProcess create_model() end ==================================
2025-04-19 20:47:44,730:INFO:Creating metrics dataframe
2025-04-19 20:47:44,730:INFO:Initializing Ridge Regression
2025-04-19 20:47:44,730:INFO:Total runtime is 0.4527307391166687 minutes
2025-04-19 20:47:44,730:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:44,730:INFO:Initializing create_model()
2025-04-19 20:47:44,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:44,730:INFO:Checking exceptions
2025-04-19 20:47:44,730:INFO:Importing libraries
2025-04-19 20:47:44,730:INFO:Copying training dataset
2025-04-19 20:47:44,730:INFO:Defining folds
2025-04-19 20:47:44,730:INFO:Declaring metric variables
2025-04-19 20:47:44,730:INFO:Importing untrained model
2025-04-19 20:47:44,730:INFO:Ridge Regression Imported successfully
2025-04-19 20:47:44,730:INFO:Starting cross validation
2025-04-19 20:47:44,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:47:47,823:INFO:Calculating mean and std
2025-04-19 20:47:47,823:INFO:Creating metrics dataframe
2025-04-19 20:47:48,319:INFO:Uploading results into container
2025-04-19 20:47:48,319:INFO:Uploading model into container now
2025-04-19 20:47:48,319:INFO:_master_model_container: 3
2025-04-19 20:47:48,319:INFO:_display_container: 2
2025-04-19 20:47:48,319:INFO:Ridge(random_state=42)
2025-04-19 20:47:48,319:INFO:create_model() successfully completed......................................
2025-04-19 20:47:48,522:INFO:SubProcess create_model() end ==================================
2025-04-19 20:47:48,522:INFO:Creating metrics dataframe
2025-04-19 20:47:48,524:INFO:Initializing Elastic Net
2025-04-19 20:47:48,524:INFO:Total runtime is 0.5159734725952149 minutes
2025-04-19 20:47:48,524:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:48,524:INFO:Initializing create_model()
2025-04-19 20:47:48,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:48,524:INFO:Checking exceptions
2025-04-19 20:47:48,524:INFO:Importing libraries
2025-04-19 20:47:48,524:INFO:Copying training dataset
2025-04-19 20:47:48,532:INFO:Defining folds
2025-04-19 20:47:48,532:INFO:Declaring metric variables
2025-04-19 20:47:48,532:INFO:Importing untrained model
2025-04-19 20:47:48,532:INFO:Elastic Net Imported successfully
2025-04-19 20:47:48,532:INFO:Starting cross validation
2025-04-19 20:47:48,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:47:51,819:INFO:Calculating mean and std
2025-04-19 20:47:51,819:INFO:Creating metrics dataframe
2025-04-19 20:47:52,331:INFO:Uploading results into container
2025-04-19 20:47:52,331:INFO:Uploading model into container now
2025-04-19 20:47:52,331:INFO:_master_model_container: 4
2025-04-19 20:47:52,331:INFO:_display_container: 2
2025-04-19 20:47:52,331:INFO:ElasticNet(random_state=42)
2025-04-19 20:47:52,331:INFO:create_model() successfully completed......................................
2025-04-19 20:47:52,526:INFO:SubProcess create_model() end ==================================
2025-04-19 20:47:52,526:INFO:Creating metrics dataframe
2025-04-19 20:47:52,530:INFO:Initializing Least Angle Regression
2025-04-19 20:47:52,530:INFO:Total runtime is 0.582731819152832 minutes
2025-04-19 20:47:52,530:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:52,530:INFO:Initializing create_model()
2025-04-19 20:47:52,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:52,530:INFO:Checking exceptions
2025-04-19 20:47:52,532:INFO:Importing libraries
2025-04-19 20:47:52,532:INFO:Copying training dataset
2025-04-19 20:47:52,534:INFO:Defining folds
2025-04-19 20:47:52,536:INFO:Declaring metric variables
2025-04-19 20:47:52,536:INFO:Importing untrained model
2025-04-19 20:47:52,536:INFO:Least Angle Regression Imported successfully
2025-04-19 20:47:52,536:INFO:Starting cross validation
2025-04-19 20:47:52,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:47:55,577:INFO:Calculating mean and std
2025-04-19 20:47:55,577:INFO:Creating metrics dataframe
2025-04-19 20:47:56,050:INFO:Uploading results into container
2025-04-19 20:47:56,050:INFO:Uploading model into container now
2025-04-19 20:47:56,050:INFO:_master_model_container: 5
2025-04-19 20:47:56,050:INFO:_display_container: 2
2025-04-19 20:47:56,050:INFO:Lars(random_state=42)
2025-04-19 20:47:56,050:INFO:create_model() successfully completed......................................
2025-04-19 20:47:56,231:INFO:SubProcess create_model() end ==================================
2025-04-19 20:47:56,231:INFO:Creating metrics dataframe
2025-04-19 20:47:56,231:INFO:Initializing Lasso Least Angle Regression
2025-04-19 20:47:56,231:INFO:Total runtime is 0.6444281776746114 minutes
2025-04-19 20:47:56,231:INFO:SubProcess create_model() called ==================================
2025-04-19 20:47:56,231:INFO:Initializing create_model()
2025-04-19 20:47:56,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:47:56,231:INFO:Checking exceptions
2025-04-19 20:47:56,231:INFO:Importing libraries
2025-04-19 20:47:56,231:INFO:Copying training dataset
2025-04-19 20:47:56,231:INFO:Defining folds
2025-04-19 20:47:56,231:INFO:Declaring metric variables
2025-04-19 20:47:56,231:INFO:Importing untrained model
2025-04-19 20:47:56,231:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 20:47:56,231:INFO:Starting cross validation
2025-04-19 20:47:56,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:00,711:INFO:Calculating mean and std
2025-04-19 20:48:00,714:INFO:Creating metrics dataframe
2025-04-19 20:48:01,331:INFO:Uploading results into container
2025-04-19 20:48:01,334:INFO:Uploading model into container now
2025-04-19 20:48:01,334:INFO:_master_model_container: 6
2025-04-19 20:48:01,334:INFO:_display_container: 2
2025-04-19 20:48:01,335:INFO:LassoLars(random_state=42)
2025-04-19 20:48:01,335:INFO:create_model() successfully completed......................................
2025-04-19 20:48:01,570:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:01,571:INFO:Creating metrics dataframe
2025-04-19 20:48:01,582:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 20:48:01,582:INFO:Total runtime is 0.7336056431134541 minutes
2025-04-19 20:48:01,582:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:01,583:INFO:Initializing create_model()
2025-04-19 20:48:01,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:01,583:INFO:Checking exceptions
2025-04-19 20:48:01,583:INFO:Importing libraries
2025-04-19 20:48:01,583:INFO:Copying training dataset
2025-04-19 20:48:01,593:INFO:Defining folds
2025-04-19 20:48:01,593:INFO:Declaring metric variables
2025-04-19 20:48:01,593:INFO:Importing untrained model
2025-04-19 20:48:01,594:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 20:48:01,595:INFO:Starting cross validation
2025-04-19 20:48:01,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:05,909:INFO:Calculating mean and std
2025-04-19 20:48:05,909:INFO:Creating metrics dataframe
2025-04-19 20:48:06,568:INFO:Uploading results into container
2025-04-19 20:48:06,570:INFO:Uploading model into container now
2025-04-19 20:48:06,570:INFO:_master_model_container: 7
2025-04-19 20:48:06,570:INFO:_display_container: 2
2025-04-19 20:48:06,570:INFO:OrthogonalMatchingPursuit()
2025-04-19 20:48:06,570:INFO:create_model() successfully completed......................................
2025-04-19 20:48:06,812:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:06,812:INFO:Creating metrics dataframe
2025-04-19 20:48:06,819:INFO:Initializing Bayesian Ridge
2025-04-19 20:48:06,819:INFO:Total runtime is 0.8208931446075438 minutes
2025-04-19 20:48:06,819:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:06,819:INFO:Initializing create_model()
2025-04-19 20:48:06,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:06,819:INFO:Checking exceptions
2025-04-19 20:48:06,819:INFO:Importing libraries
2025-04-19 20:48:06,819:INFO:Copying training dataset
2025-04-19 20:48:06,831:INFO:Defining folds
2025-04-19 20:48:06,831:INFO:Declaring metric variables
2025-04-19 20:48:06,831:INFO:Importing untrained model
2025-04-19 20:48:06,831:INFO:Bayesian Ridge Imported successfully
2025-04-19 20:48:06,831:INFO:Starting cross validation
2025-04-19 20:48:06,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:13,167:INFO:Calculating mean and std
2025-04-19 20:48:13,169:INFO:Creating metrics dataframe
2025-04-19 20:48:13,783:INFO:Uploading results into container
2025-04-19 20:48:13,784:INFO:Uploading model into container now
2025-04-19 20:48:13,785:INFO:_master_model_container: 8
2025-04-19 20:48:13,785:INFO:_display_container: 2
2025-04-19 20:48:13,785:INFO:BayesianRidge()
2025-04-19 20:48:13,785:INFO:create_model() successfully completed......................................
2025-04-19 20:48:14,177:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:14,177:INFO:Creating metrics dataframe
2025-04-19 20:48:14,192:INFO:Initializing Passive Aggressive Regressor
2025-04-19 20:48:14,193:INFO:Total runtime is 0.9437844673792519 minutes
2025-04-19 20:48:14,193:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:14,193:INFO:Initializing create_model()
2025-04-19 20:48:14,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:14,194:INFO:Checking exceptions
2025-04-19 20:48:14,194:INFO:Importing libraries
2025-04-19 20:48:14,194:INFO:Copying training dataset
2025-04-19 20:48:14,204:INFO:Defining folds
2025-04-19 20:48:14,205:INFO:Declaring metric variables
2025-04-19 20:48:14,205:INFO:Importing untrained model
2025-04-19 20:48:14,206:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 20:48:14,206:INFO:Starting cross validation
2025-04-19 20:48:14,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:17,911:INFO:Calculating mean and std
2025-04-19 20:48:17,911:INFO:Creating metrics dataframe
2025-04-19 20:48:18,454:INFO:Uploading results into container
2025-04-19 20:48:18,454:INFO:Uploading model into container now
2025-04-19 20:48:18,454:INFO:_master_model_container: 9
2025-04-19 20:48:18,454:INFO:_display_container: 2
2025-04-19 20:48:18,454:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 20:48:18,454:INFO:create_model() successfully completed......................................
2025-04-19 20:48:18,647:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:18,647:INFO:Creating metrics dataframe
2025-04-19 20:48:18,647:INFO:Initializing Huber Regressor
2025-04-19 20:48:18,647:INFO:Total runtime is 1.018015666802724 minutes
2025-04-19 20:48:18,647:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:18,647:INFO:Initializing create_model()
2025-04-19 20:48:18,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:18,647:INFO:Checking exceptions
2025-04-19 20:48:18,647:INFO:Importing libraries
2025-04-19 20:48:18,647:INFO:Copying training dataset
2025-04-19 20:48:18,654:INFO:Defining folds
2025-04-19 20:48:18,654:INFO:Declaring metric variables
2025-04-19 20:48:18,654:INFO:Importing untrained model
2025-04-19 20:48:18,654:INFO:Huber Regressor Imported successfully
2025-04-19 20:48:18,654:INFO:Starting cross validation
2025-04-19 20:48:18,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:23,144:INFO:Calculating mean and std
2025-04-19 20:48:23,145:INFO:Creating metrics dataframe
2025-04-19 20:48:23,773:INFO:Uploading results into container
2025-04-19 20:48:23,774:INFO:Uploading model into container now
2025-04-19 20:48:23,775:INFO:_master_model_container: 10
2025-04-19 20:48:23,775:INFO:_display_container: 2
2025-04-19 20:48:23,775:INFO:HuberRegressor()
2025-04-19 20:48:23,775:INFO:create_model() successfully completed......................................
2025-04-19 20:48:24,102:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:24,103:INFO:Creating metrics dataframe
2025-04-19 20:48:24,115:INFO:Initializing K Neighbors Regressor
2025-04-19 20:48:24,115:INFO:Total runtime is 1.1091587781906127 minutes
2025-04-19 20:48:24,116:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:24,117:INFO:Initializing create_model()
2025-04-19 20:48:24,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:24,117:INFO:Checking exceptions
2025-04-19 20:48:24,117:INFO:Importing libraries
2025-04-19 20:48:24,117:INFO:Copying training dataset
2025-04-19 20:48:24,131:INFO:Defining folds
2025-04-19 20:48:24,132:INFO:Declaring metric variables
2025-04-19 20:48:24,132:INFO:Importing untrained model
2025-04-19 20:48:24,134:INFO:K Neighbors Regressor Imported successfully
2025-04-19 20:48:24,135:INFO:Starting cross validation
2025-04-19 20:48:24,154:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:29,720:INFO:Calculating mean and std
2025-04-19 20:48:29,722:INFO:Creating metrics dataframe
2025-04-19 20:48:30,499:INFO:Uploading results into container
2025-04-19 20:48:30,501:INFO:Uploading model into container now
2025-04-19 20:48:30,502:INFO:_master_model_container: 11
2025-04-19 20:48:30,502:INFO:_display_container: 2
2025-04-19 20:48:30,502:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 20:48:30,502:INFO:create_model() successfully completed......................................
2025-04-19 20:48:30,745:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:30,745:INFO:Creating metrics dataframe
2025-04-19 20:48:30,765:INFO:Initializing Decision Tree Regressor
2025-04-19 20:48:30,766:INFO:Total runtime is 1.220002762476603 minutes
2025-04-19 20:48:30,766:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:30,767:INFO:Initializing create_model()
2025-04-19 20:48:30,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:30,767:INFO:Checking exceptions
2025-04-19 20:48:30,767:INFO:Importing libraries
2025-04-19 20:48:30,767:INFO:Copying training dataset
2025-04-19 20:48:30,781:INFO:Defining folds
2025-04-19 20:48:30,782:INFO:Declaring metric variables
2025-04-19 20:48:30,782:INFO:Importing untrained model
2025-04-19 20:48:30,784:INFO:Decision Tree Regressor Imported successfully
2025-04-19 20:48:30,784:INFO:Starting cross validation
2025-04-19 20:48:30,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:35,054:INFO:Calculating mean and std
2025-04-19 20:48:35,054:INFO:Creating metrics dataframe
2025-04-19 20:48:35,600:INFO:Uploading results into container
2025-04-19 20:48:35,600:INFO:Uploading model into container now
2025-04-19 20:48:35,600:INFO:_master_model_container: 12
2025-04-19 20:48:35,600:INFO:_display_container: 2
2025-04-19 20:48:35,600:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 20:48:35,600:INFO:create_model() successfully completed......................................
2025-04-19 20:48:35,781:INFO:SubProcess create_model() end ==================================
2025-04-19 20:48:35,781:INFO:Creating metrics dataframe
2025-04-19 20:48:35,781:INFO:Initializing Random Forest Regressor
2025-04-19 20:48:35,781:INFO:Total runtime is 1.3035902063051859 minutes
2025-04-19 20:48:35,781:INFO:SubProcess create_model() called ==================================
2025-04-19 20:48:35,797:INFO:Initializing create_model()
2025-04-19 20:48:35,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:48:35,797:INFO:Checking exceptions
2025-04-19 20:48:35,797:INFO:Importing libraries
2025-04-19 20:48:35,797:INFO:Copying training dataset
2025-04-19 20:48:35,797:INFO:Defining folds
2025-04-19 20:48:35,797:INFO:Declaring metric variables
2025-04-19 20:48:35,797:INFO:Importing untrained model
2025-04-19 20:48:35,797:INFO:Random Forest Regressor Imported successfully
2025-04-19 20:48:35,797:INFO:Starting cross validation
2025-04-19 20:48:35,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:48:55,515:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:48:55,668:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:48:55,802:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:48:56,097:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:49:06,359:INFO:Calculating mean and std
2025-04-19 20:49:06,361:INFO:Creating metrics dataframe
2025-04-19 20:49:07,234:INFO:Uploading results into container
2025-04-19 20:49:07,236:INFO:Uploading model into container now
2025-04-19 20:49:07,238:INFO:_master_model_container: 13
2025-04-19 20:49:07,238:INFO:_display_container: 2
2025-04-19 20:49:07,239:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 20:49:07,239:INFO:create_model() successfully completed......................................
2025-04-19 20:49:07,593:INFO:SubProcess create_model() end ==================================
2025-04-19 20:49:07,593:INFO:Creating metrics dataframe
2025-04-19 20:49:07,606:INFO:Initializing Extra Trees Regressor
2025-04-19 20:49:07,606:INFO:Total runtime is 1.8340104778607684 minutes
2025-04-19 20:49:07,607:INFO:SubProcess create_model() called ==================================
2025-04-19 20:49:07,607:INFO:Initializing create_model()
2025-04-19 20:49:07,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 20:49:07,607:INFO:Checking exceptions
2025-04-19 20:49:07,607:INFO:Importing libraries
2025-04-19 20:49:07,607:INFO:Copying training dataset
2025-04-19 20:49:07,616:INFO:Defining folds
2025-04-19 20:49:07,617:INFO:Declaring metric variables
2025-04-19 20:49:07,617:INFO:Importing untrained model
2025-04-19 20:49:07,618:INFO:Extra Trees Regressor Imported successfully
2025-04-19 20:49:07,619:INFO:Starting cross validation
2025-04-19 20:49:07,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 20:49:12,835:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:49:12,847:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:49:12,918:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:49:13,041:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 20:49:13,140:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:02:27,007:INFO:Calculating mean and std
2025-04-19 21:02:27,016:INFO:Creating metrics dataframe
2025-04-19 21:02:28,389:INFO:Uploading results into container
2025-04-19 21:02:28,395:INFO:Uploading model into container now
2025-04-19 21:02:28,396:INFO:_master_model_container: 14
2025-04-19 21:02:28,396:INFO:_display_container: 2
2025-04-19 21:02:28,398:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:02:28,398:INFO:create_model() successfully completed......................................
2025-04-19 21:02:29,036:INFO:SubProcess create_model() end ==================================
2025-04-19 21:02:29,036:INFO:Creating metrics dataframe
2025-04-19 21:02:29,070:INFO:Initializing AdaBoost Regressor
2025-04-19 21:02:29,072:INFO:Total runtime is 15.191736988226573 minutes
2025-04-19 21:02:29,074:INFO:SubProcess create_model() called ==================================
2025-04-19 21:02:29,074:INFO:Initializing create_model()
2025-04-19 21:02:29,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:02:29,074:INFO:Checking exceptions
2025-04-19 21:02:29,074:INFO:Importing libraries
2025-04-19 21:02:29,074:INFO:Copying training dataset
2025-04-19 21:02:29,316:INFO:Defining folds
2025-04-19 21:02:29,316:INFO:Declaring metric variables
2025-04-19 21:02:29,318:INFO:Importing untrained model
2025-04-19 21:02:29,318:INFO:AdaBoost Regressor Imported successfully
2025-04-19 21:02:29,443:INFO:Starting cross validation
2025-04-19 21:02:29,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:02:32,574:WARNING:D:\College\agn\venv_py310\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2025-04-19 21:02:44,633:INFO:Calculating mean and std
2025-04-19 21:02:44,633:INFO:Creating metrics dataframe
2025-04-19 21:02:45,058:INFO:Uploading results into container
2025-04-19 21:02:45,058:INFO:Uploading model into container now
2025-04-19 21:02:45,058:INFO:_master_model_container: 15
2025-04-19 21:02:45,058:INFO:_display_container: 2
2025-04-19 21:02:45,058:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 21:02:45,058:INFO:create_model() successfully completed......................................
2025-04-19 21:02:45,308:INFO:SubProcess create_model() end ==================================
2025-04-19 21:02:45,308:INFO:Creating metrics dataframe
2025-04-19 21:02:45,316:INFO:Initializing Gradient Boosting Regressor
2025-04-19 21:02:45,316:INFO:Total runtime is 15.46250568230947 minutes
2025-04-19 21:02:45,316:INFO:SubProcess create_model() called ==================================
2025-04-19 21:02:45,316:INFO:Initializing create_model()
2025-04-19 21:02:45,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:02:45,316:INFO:Checking exceptions
2025-04-19 21:02:45,316:INFO:Importing libraries
2025-04-19 21:02:45,316:INFO:Copying training dataset
2025-04-19 21:02:45,320:INFO:Defining folds
2025-04-19 21:02:45,320:INFO:Declaring metric variables
2025-04-19 21:02:45,320:INFO:Importing untrained model
2025-04-19 21:02:45,323:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 21:02:45,323:INFO:Starting cross validation
2025-04-19 21:02:45,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:02:53,879:INFO:Calculating mean and std
2025-04-19 21:02:53,879:INFO:Creating metrics dataframe
2025-04-19 21:02:54,593:INFO:Uploading results into container
2025-04-19 21:02:54,593:INFO:Uploading model into container now
2025-04-19 21:02:54,609:INFO:_master_model_container: 16
2025-04-19 21:02:54,609:INFO:_display_container: 2
2025-04-19 21:02:54,609:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 21:02:54,609:INFO:create_model() successfully completed......................................
2025-04-19 21:02:54,868:INFO:SubProcess create_model() end ==================================
2025-04-19 21:02:54,868:INFO:Creating metrics dataframe
2025-04-19 21:02:54,868:INFO:Initializing Extreme Gradient Boosting
2025-04-19 21:02:54,868:INFO:Total runtime is 15.621695840358734 minutes
2025-04-19 21:02:54,868:INFO:SubProcess create_model() called ==================================
2025-04-19 21:02:54,868:INFO:Initializing create_model()
2025-04-19 21:02:54,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:02:54,868:INFO:Checking exceptions
2025-04-19 21:02:54,868:INFO:Importing libraries
2025-04-19 21:02:54,868:INFO:Copying training dataset
2025-04-19 21:02:54,879:INFO:Defining folds
2025-04-19 21:02:54,879:INFO:Declaring metric variables
2025-04-19 21:02:54,879:INFO:Importing untrained model
2025-04-19 21:02:54,879:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:02:54,879:INFO:Starting cross validation
2025-04-19 21:02:54,896:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:02:58,372:INFO:Calculating mean and std
2025-04-19 21:02:58,372:INFO:Creating metrics dataframe
2025-04-19 21:02:58,686:INFO:Uploading results into container
2025-04-19 21:02:58,686:INFO:Uploading model into container now
2025-04-19 21:02:58,686:INFO:_master_model_container: 17
2025-04-19 21:02:58,686:INFO:_display_container: 2
2025-04-19 21:02:58,689:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2025-04-19 21:02:58,689:INFO:create_model() successfully completed......................................
2025-04-19 21:02:58,819:INFO:SubProcess create_model() end ==================================
2025-04-19 21:02:58,819:INFO:Creating metrics dataframe
2025-04-19 21:02:58,835:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 21:02:58,835:INFO:Total runtime is 15.687812848885855 minutes
2025-04-19 21:02:58,835:INFO:SubProcess create_model() called ==================================
2025-04-19 21:02:58,835:INFO:Initializing create_model()
2025-04-19 21:02:58,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:02:58,835:INFO:Checking exceptions
2025-04-19 21:02:58,835:INFO:Importing libraries
2025-04-19 21:02:58,835:INFO:Copying training dataset
2025-04-19 21:02:58,840:INFO:Defining folds
2025-04-19 21:02:58,840:INFO:Declaring metric variables
2025-04-19 21:02:58,840:INFO:Importing untrained model
2025-04-19 21:02:58,840:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:02:58,840:INFO:Starting cross validation
2025-04-19 21:02:58,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:03:01,967:INFO:Calculating mean and std
2025-04-19 21:03:01,967:INFO:Creating metrics dataframe
2025-04-19 21:03:02,231:INFO:Uploading results into container
2025-04-19 21:03:02,231:INFO:Uploading model into container now
2025-04-19 21:03:02,231:INFO:_master_model_container: 18
2025-04-19 21:03:02,231:INFO:_display_container: 2
2025-04-19 21:03:02,243:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:03:02,243:INFO:create_model() successfully completed......................................
2025-04-19 21:03:02,400:INFO:SubProcess create_model() end ==================================
2025-04-19 21:03:02,400:INFO:Creating metrics dataframe
2025-04-19 21:03:02,400:INFO:Initializing Dummy Regressor
2025-04-19 21:03:02,400:INFO:Total runtime is 15.747244036197664 minutes
2025-04-19 21:03:02,400:INFO:SubProcess create_model() called ==================================
2025-04-19 21:03:02,400:INFO:Initializing create_model()
2025-04-19 21:03:02,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB527790>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:03:02,400:INFO:Checking exceptions
2025-04-19 21:03:02,400:INFO:Importing libraries
2025-04-19 21:03:02,400:INFO:Copying training dataset
2025-04-19 21:03:02,400:INFO:Defining folds
2025-04-19 21:03:02,400:INFO:Declaring metric variables
2025-04-19 21:03:02,400:INFO:Importing untrained model
2025-04-19 21:03:02,400:INFO:Dummy Regressor Imported successfully
2025-04-19 21:03:02,400:INFO:Starting cross validation
2025-04-19 21:03:02,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:03:04,426:INFO:Calculating mean and std
2025-04-19 21:03:04,427:INFO:Creating metrics dataframe
2025-04-19 21:03:04,719:INFO:Uploading results into container
2025-04-19 21:03:04,719:INFO:Uploading model into container now
2025-04-19 21:03:04,719:INFO:_master_model_container: 19
2025-04-19 21:03:04,719:INFO:_display_container: 2
2025-04-19 21:03:04,721:INFO:DummyRegressor()
2025-04-19 21:03:04,721:INFO:create_model() successfully completed......................................
2025-04-19 21:03:04,869:INFO:SubProcess create_model() end ==================================
2025-04-19 21:03:04,869:INFO:Creating metrics dataframe
2025-04-19 21:03:04,875:INFO:Initializing create_model()
2025-04-19 21:03:04,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:03:04,875:INFO:Checking exceptions
2025-04-19 21:03:04,876:INFO:Importing libraries
2025-04-19 21:03:04,876:INFO:Copying training dataset
2025-04-19 21:03:04,878:INFO:Defining folds
2025-04-19 21:03:04,879:INFO:Declaring metric variables
2025-04-19 21:03:04,879:INFO:Importing untrained model
2025-04-19 21:03:04,879:INFO:Declaring custom model
2025-04-19 21:03:04,879:INFO:Huber Regressor Imported successfully
2025-04-19 21:03:04,884:INFO:Cross validation set to False
2025-04-19 21:03:04,884:INFO:Fitting Model
2025-04-19 21:03:05,160:INFO:HuberRegressor()
2025-04-19 21:03:05,160:INFO:create_model() successfully completed......................................
2025-04-19 21:03:05,303:INFO:Initializing create_model()
2025-04-19 21:03:05,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:03:05,303:INFO:Checking exceptions
2025-04-19 21:03:05,304:INFO:Importing libraries
2025-04-19 21:03:05,304:INFO:Copying training dataset
2025-04-19 21:03:05,307:INFO:Defining folds
2025-04-19 21:03:05,307:INFO:Declaring metric variables
2025-04-19 21:03:05,307:INFO:Importing untrained model
2025-04-19 21:03:05,307:INFO:Declaring custom model
2025-04-19 21:03:05,308:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:03:05,314:INFO:Cross validation set to False
2025-04-19 21:03:05,314:INFO:Fitting Model
2025-04-19 21:03:05,569:INFO:BayesianRidge()
2025-04-19 21:03:05,569:INFO:create_model() successfully completed......................................
2025-04-19 21:03:05,717:INFO:Initializing create_model()
2025-04-19 21:03:05,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:03:05,717:INFO:Checking exceptions
2025-04-19 21:03:05,717:INFO:Importing libraries
2025-04-19 21:03:05,717:INFO:Copying training dataset
2025-04-19 21:03:05,717:INFO:Defining folds
2025-04-19 21:03:05,717:INFO:Declaring metric variables
2025-04-19 21:03:05,717:INFO:Importing untrained model
2025-04-19 21:03:05,717:INFO:Declaring custom model
2025-04-19 21:03:05,723:INFO:Linear Regression Imported successfully
2025-04-19 21:03:05,723:INFO:Cross validation set to False
2025-04-19 21:03:05,723:INFO:Fitting Model
2025-04-19 21:03:05,954:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:03:05,954:INFO:create_model() successfully completed......................................
2025-04-19 21:03:06,108:INFO:_master_model_container: 19
2025-04-19 21:03:06,108:INFO:_display_container: 2
2025-04-19 21:03:06,108:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 21:03:06,108:INFO:compare_models() successfully completed......................................
2025-04-19 21:03:06,108:INFO:Initializing tune_model()
2025-04-19 21:03:06,111:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>)
2025-04-19 21:03:06,111:INFO:Checking exceptions
2025-04-19 21:03:06,115:INFO:Copying training dataset
2025-04-19 21:03:06,117:INFO:Checking base model
2025-04-19 21:03:06,117:INFO:Base model : Huber Regressor
2025-04-19 21:03:06,117:INFO:Declaring metric variables
2025-04-19 21:03:06,118:INFO:Defining Hyperparameters
2025-04-19 21:03:06,285:INFO:Tuning with n_jobs=-1
2025-04-19 21:03:06,285:INFO:Initializing RandomizedSearchCV
2025-04-19 21:03:30,299:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.01}
2025-04-19 21:03:30,299:INFO:Hyperparameter search completed
2025-04-19 21:03:30,299:INFO:SubProcess create_model() called ==================================
2025-04-19 21:03:30,299:INFO:Initializing create_model()
2025-04-19 21:03:30,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB904AF0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.4, 'alpha': 0.01})
2025-04-19 21:03:30,299:INFO:Checking exceptions
2025-04-19 21:03:30,299:INFO:Importing libraries
2025-04-19 21:03:30,299:INFO:Copying training dataset
2025-04-19 21:03:30,299:INFO:Defining folds
2025-04-19 21:03:30,299:INFO:Declaring metric variables
2025-04-19 21:03:30,299:INFO:Importing untrained model
2025-04-19 21:03:30,299:INFO:Declaring custom model
2025-04-19 21:03:30,299:INFO:Huber Regressor Imported successfully
2025-04-19 21:03:30,299:INFO:Starting cross validation
2025-04-19 21:03:30,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:03:32,372:INFO:Calculating mean and std
2025-04-19 21:03:32,372:INFO:Creating metrics dataframe
2025-04-19 21:03:32,372:INFO:Finalizing model
2025-04-19 21:03:32,708:INFO:Uploading results into container
2025-04-19 21:03:32,708:INFO:Uploading model into container now
2025-04-19 21:03:32,708:INFO:_master_model_container: 20
2025-04-19 21:03:32,708:INFO:_display_container: 3
2025-04-19 21:03:32,708:INFO:HuberRegressor(alpha=0.01, epsilon=1.4)
2025-04-19 21:03:32,708:INFO:create_model() successfully completed......................................
2025-04-19 21:03:32,877:INFO:SubProcess create_model() end ==================================
2025-04-19 21:03:32,877:INFO:choose_better activated
2025-04-19 21:03:32,877:INFO:SubProcess create_model() called ==================================
2025-04-19 21:03:32,878:INFO:Initializing create_model()
2025-04-19 21:03:32,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:03:32,878:INFO:Checking exceptions
2025-04-19 21:03:32,878:INFO:Importing libraries
2025-04-19 21:03:32,879:INFO:Copying training dataset
2025-04-19 21:03:32,881:INFO:Defining folds
2025-04-19 21:03:32,882:INFO:Declaring metric variables
2025-04-19 21:03:32,882:INFO:Importing untrained model
2025-04-19 21:03:32,882:INFO:Declaring custom model
2025-04-19 21:03:32,882:INFO:Huber Regressor Imported successfully
2025-04-19 21:03:32,882:INFO:Starting cross validation
2025-04-19 21:03:32,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:03:34,900:INFO:Calculating mean and std
2025-04-19 21:03:34,900:INFO:Creating metrics dataframe
2025-04-19 21:03:34,900:INFO:Finalizing model
2025-04-19 21:03:35,234:INFO:Uploading results into container
2025-04-19 21:03:35,236:INFO:Uploading model into container now
2025-04-19 21:03:35,236:INFO:_master_model_container: 21
2025-04-19 21:03:35,236:INFO:_display_container: 4
2025-04-19 21:03:35,236:INFO:HuberRegressor()
2025-04-19 21:03:35,236:INFO:create_model() successfully completed......................................
2025-04-19 21:03:35,369:INFO:SubProcess create_model() end ==================================
2025-04-19 21:03:35,369:INFO:HuberRegressor() result for R2 is 0.0029
2025-04-19 21:03:35,369:INFO:HuberRegressor(alpha=0.01, epsilon=1.4) result for R2 is 0.0029
2025-04-19 21:03:35,369:INFO:HuberRegressor() is best model
2025-04-19 21:03:35,369:INFO:choose_better completed
2025-04-19 21:03:35,369:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:03:35,369:INFO:_master_model_container: 21
2025-04-19 21:03:35,369:INFO:_display_container: 3
2025-04-19 21:03:35,369:INFO:HuberRegressor()
2025-04-19 21:03:35,369:INFO:tune_model() successfully completed......................................
2025-04-19 21:03:35,711:INFO:Initializing tune_model()
2025-04-19 21:03:35,711:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>)
2025-04-19 21:03:35,711:INFO:Checking exceptions
2025-04-19 21:03:35,711:INFO:Copying training dataset
2025-04-19 21:03:35,711:INFO:Checking base model
2025-04-19 21:03:35,711:INFO:Base model : Bayesian Ridge
2025-04-19 21:03:35,711:INFO:Declaring metric variables
2025-04-19 21:03:35,711:INFO:Defining Hyperparameters
2025-04-19 21:03:35,878:INFO:Tuning with n_jobs=-1
2025-04-19 21:03:35,878:INFO:Initializing RandomizedSearchCV
2025-04-19 21:04:00,331:INFO:best_params: {'actual_estimator__lambda_2': 0.005, 'actual_estimator__lambda_1': 1e-06, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': True, 'actual_estimator__alpha_2': 0.3, 'actual_estimator__alpha_1': 0.3}
2025-04-19 21:04:00,331:INFO:Hyperparameter search completed
2025-04-19 21:04:00,331:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:00,331:INFO:Initializing create_model()
2025-04-19 21:04:00,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAB4726E0>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.005, 'lambda_1': 1e-06, 'fit_intercept': True, 'compute_score': True, 'alpha_2': 0.3, 'alpha_1': 0.3})
2025-04-19 21:04:00,331:INFO:Checking exceptions
2025-04-19 21:04:00,331:INFO:Importing libraries
2025-04-19 21:04:00,331:INFO:Copying training dataset
2025-04-19 21:04:00,333:INFO:Defining folds
2025-04-19 21:04:00,333:INFO:Declaring metric variables
2025-04-19 21:04:00,333:INFO:Importing untrained model
2025-04-19 21:04:00,333:INFO:Declaring custom model
2025-04-19 21:04:00,333:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:04:00,333:INFO:Starting cross validation
2025-04-19 21:04:00,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:02,589:INFO:Calculating mean and std
2025-04-19 21:04:02,589:INFO:Creating metrics dataframe
2025-04-19 21:04:02,589:INFO:Finalizing model
2025-04-19 21:04:02,958:INFO:Uploading results into container
2025-04-19 21:04:02,958:INFO:Uploading model into container now
2025-04-19 21:04:02,958:INFO:_master_model_container: 22
2025-04-19 21:04:02,958:INFO:_display_container: 4
2025-04-19 21:04:02,958:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 21:04:02,958:INFO:create_model() successfully completed......................................
2025-04-19 21:04:03,139:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:03,139:INFO:choose_better activated
2025-04-19 21:04:03,139:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:03,139:INFO:Initializing create_model()
2025-04-19 21:04:03,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:04:03,139:INFO:Checking exceptions
2025-04-19 21:04:03,139:INFO:Importing libraries
2025-04-19 21:04:03,139:INFO:Copying training dataset
2025-04-19 21:04:03,139:INFO:Defining folds
2025-04-19 21:04:03,139:INFO:Declaring metric variables
2025-04-19 21:04:03,139:INFO:Importing untrained model
2025-04-19 21:04:03,139:INFO:Declaring custom model
2025-04-19 21:04:03,139:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:04:03,139:INFO:Starting cross validation
2025-04-19 21:04:03,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:05,363:INFO:Calculating mean and std
2025-04-19 21:04:05,363:INFO:Creating metrics dataframe
2025-04-19 21:04:05,363:INFO:Finalizing model
2025-04-19 21:04:05,727:INFO:Uploading results into container
2025-04-19 21:04:05,727:INFO:Uploading model into container now
2025-04-19 21:04:05,727:INFO:_master_model_container: 23
2025-04-19 21:04:05,727:INFO:_display_container: 5
2025-04-19 21:04:05,727:INFO:BayesianRidge()
2025-04-19 21:04:05,727:INFO:create_model() successfully completed......................................
2025-04-19 21:04:05,894:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:05,894:INFO:BayesianRidge() result for R2 is -0.0007
2025-04-19 21:04:05,894:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) result for R2 is -0.0007
2025-04-19 21:04:05,894:INFO:BayesianRidge() is best model
2025-04-19 21:04:05,894:INFO:choose_better completed
2025-04-19 21:04:05,894:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:04:05,894:INFO:_master_model_container: 23
2025-04-19 21:04:05,894:INFO:_display_container: 4
2025-04-19 21:04:05,894:INFO:BayesianRidge()
2025-04-19 21:04:05,894:INFO:tune_model() successfully completed......................................
2025-04-19 21:04:06,265:INFO:Initializing tune_model()
2025-04-19 21:04:06,265:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>)
2025-04-19 21:04:06,265:INFO:Checking exceptions
2025-04-19 21:04:06,265:INFO:Copying training dataset
2025-04-19 21:04:06,265:INFO:Checking base model
2025-04-19 21:04:06,265:INFO:Base model : Linear Regression
2025-04-19 21:04:06,265:INFO:Declaring metric variables
2025-04-19 21:04:06,265:INFO:Defining Hyperparameters
2025-04-19 21:04:06,265:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 21:04:06,447:INFO:Tuning with n_jobs=-1
2025-04-19 21:04:06,447:INFO:Initializing GridSearchCV
2025-04-19 21:04:11,817:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 21:04:11,817:INFO:Hyperparameter search completed
2025-04-19 21:04:11,817:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:11,817:INFO:Initializing create_model()
2025-04-19 21:04:11,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAD5187F0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 21:04:11,817:INFO:Checking exceptions
2025-04-19 21:04:11,817:INFO:Importing libraries
2025-04-19 21:04:11,817:INFO:Copying training dataset
2025-04-19 21:04:11,817:INFO:Defining folds
2025-04-19 21:04:11,817:INFO:Declaring metric variables
2025-04-19 21:04:11,817:INFO:Importing untrained model
2025-04-19 21:04:11,817:INFO:Declaring custom model
2025-04-19 21:04:11,833:INFO:Linear Regression Imported successfully
2025-04-19 21:04:11,833:INFO:Starting cross validation
2025-04-19 21:04:11,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:14,458:INFO:Calculating mean and std
2025-04-19 21:04:14,459:INFO:Creating metrics dataframe
2025-04-19 21:04:14,461:INFO:Finalizing model
2025-04-19 21:04:14,823:INFO:Uploading results into container
2025-04-19 21:04:14,823:INFO:Uploading model into container now
2025-04-19 21:04:14,823:INFO:_master_model_container: 24
2025-04-19 21:04:14,823:INFO:_display_container: 5
2025-04-19 21:04:14,823:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:04:14,823:INFO:create_model() successfully completed......................................
2025-04-19 21:04:15,013:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:15,013:INFO:choose_better activated
2025-04-19 21:04:15,013:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:15,013:INFO:Initializing create_model()
2025-04-19 21:04:15,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:04:15,013:INFO:Checking exceptions
2025-04-19 21:04:15,013:INFO:Importing libraries
2025-04-19 21:04:15,013:INFO:Copying training dataset
2025-04-19 21:04:15,019:INFO:Defining folds
2025-04-19 21:04:15,019:INFO:Declaring metric variables
2025-04-19 21:04:15,019:INFO:Importing untrained model
2025-04-19 21:04:15,019:INFO:Declaring custom model
2025-04-19 21:04:15,021:INFO:Linear Regression Imported successfully
2025-04-19 21:04:15,021:INFO:Starting cross validation
2025-04-19 21:04:15,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:17,233:INFO:Calculating mean and std
2025-04-19 21:04:17,233:INFO:Creating metrics dataframe
2025-04-19 21:04:17,233:INFO:Finalizing model
2025-04-19 21:04:17,590:INFO:Uploading results into container
2025-04-19 21:04:17,596:INFO:Uploading model into container now
2025-04-19 21:04:17,596:INFO:_master_model_container: 25
2025-04-19 21:04:17,596:INFO:_display_container: 6
2025-04-19 21:04:17,596:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:04:17,596:INFO:create_model() successfully completed......................................
2025-04-19 21:04:17,751:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:17,751:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0012
2025-04-19 21:04:17,751:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0012
2025-04-19 21:04:17,751:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 21:04:17,751:INFO:choose_better completed
2025-04-19 21:04:17,754:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:04:17,755:INFO:_master_model_container: 25
2025-04-19 21:04:17,755:INFO:_display_container: 5
2025-04-19 21:04:17,763:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:04:17,763:INFO:tune_model() successfully completed......................................
2025-04-19 21:04:18,143:INFO:Initializing blend_models()
2025-04-19 21:04:18,143:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator_list=[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:04:18,143:INFO:Checking exceptions
2025-04-19 21:04:18,143:INFO:Importing libraries
2025-04-19 21:04:18,143:INFO:Copying training dataset
2025-04-19 21:04:18,143:INFO:Getting model names
2025-04-19 21:04:18,143:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:18,143:INFO:Initializing create_model()
2025-04-19 21:04:18,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAAA589930>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:04:18,143:INFO:Checking exceptions
2025-04-19 21:04:18,143:INFO:Importing libraries
2025-04-19 21:04:18,143:INFO:Copying training dataset
2025-04-19 21:04:18,156:INFO:Defining folds
2025-04-19 21:04:18,156:INFO:Declaring metric variables
2025-04-19 21:04:18,156:INFO:Importing untrained model
2025-04-19 21:04:18,156:INFO:Declaring custom model
2025-04-19 21:04:18,159:INFO:Voting Regressor Imported successfully
2025-04-19 21:04:18,159:INFO:Starting cross validation
2025-04-19 21:04:18,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:20,443:INFO:Calculating mean and std
2025-04-19 21:04:20,443:INFO:Creating metrics dataframe
2025-04-19 21:04:20,443:INFO:Finalizing model
2025-04-19 21:04:20,924:INFO:Uploading results into container
2025-04-19 21:04:20,924:INFO:Uploading model into container now
2025-04-19 21:04:20,924:INFO:_master_model_container: 26
2025-04-19 21:04:20,924:INFO:_display_container: 6
2025-04-19 21:04:20,934:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:04:20,934:INFO:create_model() successfully completed......................................
2025-04-19 21:04:21,111:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:21,118:INFO:_master_model_container: 26
2025-04-19 21:04:21,118:INFO:_display_container: 6
2025-04-19 21:04:21,118:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:04:21,118:INFO:blend_models() successfully completed......................................
2025-04-19 21:04:21,289:INFO:Initializing stack_models()
2025-04-19 21:04:21,289:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator_list=[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:04:21,289:INFO:Checking exceptions
2025-04-19 21:04:21,289:INFO:Defining meta model
2025-04-19 21:04:21,289:INFO:Getting model names
2025-04-19 21:04:21,289:INFO:[('Huber Regressor', HuberRegressor()), ('Bayesian Ridge', BayesianRidge()), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 21:04:21,289:INFO:SubProcess create_model() called ==================================
2025-04-19 21:04:21,289:INFO:Initializing create_model()
2025-04-19 21:04:21,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAA7E692A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:04:21,289:INFO:Checking exceptions
2025-04-19 21:04:21,289:INFO:Importing libraries
2025-04-19 21:04:21,289:INFO:Copying training dataset
2025-04-19 21:04:21,289:INFO:Defining folds
2025-04-19 21:04:21,289:INFO:Declaring metric variables
2025-04-19 21:04:21,289:INFO:Importing untrained model
2025-04-19 21:04:21,289:INFO:Declaring custom model
2025-04-19 21:04:21,289:INFO:Stacking Regressor Imported successfully
2025-04-19 21:04:21,289:INFO:Starting cross validation
2025-04-19 21:04:21,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:04:23,940:INFO:Calculating mean and std
2025-04-19 21:04:23,940:INFO:Creating metrics dataframe
2025-04-19 21:04:23,956:INFO:Finalizing model
2025-04-19 21:04:24,554:INFO:Uploading results into container
2025-04-19 21:04:24,555:INFO:Uploading model into container now
2025-04-19 21:04:24,555:INFO:_master_model_container: 27
2025-04-19 21:04:24,555:INFO:_display_container: 7
2025-04-19 21:04:24,557:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:04:24,557:INFO:create_model() successfully completed......................................
2025-04-19 21:04:24,722:INFO:SubProcess create_model() end ==================================
2025-04-19 21:04:24,722:INFO:_master_model_container: 27
2025-04-19 21:04:24,722:INFO:_display_container: 7
2025-04-19 21:04:24,738:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:04:24,738:INFO:stack_models() successfully completed......................................
2025-04-19 21:04:24,922:INFO:Initializing save_model()
2025-04-19 21:04:24,922:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:04:24,922:INFO:Adding model into prep_pipe
2025-04-19 21:04:24,954:INFO:models/model_1.pkl saved in current working directory
2025-04-19 21:04:24,975:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor()),
                                             ('Bayesian Ridge',
                                              BayesianRidge()),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 21:04:24,975:INFO:save_model() successfully completed......................................
2025-04-19 21:04:25,335:INFO:Initializing plot_model()
2025-04-19 21:04:25,335:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:25,335:INFO:Checking exceptions
2025-04-19 21:04:25,343:INFO:Initializing plot_model()
2025-04-19 21:04:25,343:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:25,343:INFO:Checking exceptions
2025-04-19 21:04:25,343:INFO:Preloading libraries
2025-04-19 21:04:25,343:INFO:Copying training dataset
2025-04-19 21:04:25,343:INFO:Plot type: residuals
2025-04-19 21:04:25,726:INFO:Fitting Model
2025-04-19 21:04:25,726:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:25,766:INFO:Scoring test/hold-out set
2025-04-19 21:04:25,811:INFO:Saving 'Residuals.png'
2025-04-19 21:04:26,848:INFO:Visual Rendered Successfully
2025-04-19 21:04:27,055:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:27,336:INFO:Initializing plot_model()
2025-04-19 21:04:27,336:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:27,336:INFO:Checking exceptions
2025-04-19 21:04:27,336:INFO:Preloading libraries
2025-04-19 21:04:27,336:INFO:Copying training dataset
2025-04-19 21:04:27,336:INFO:Plot type: error
2025-04-19 21:04:27,647:INFO:Fitting Model
2025-04-19 21:04:27,647:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:27,647:INFO:Scoring test/hold-out set
2025-04-19 21:04:27,672:INFO:Saving 'Prediction Error.png'
2025-04-19 21:04:28,097:INFO:Visual Rendered Successfully
2025-04-19 21:04:28,280:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:28,565:INFO:Initializing plot_model()
2025-04-19 21:04:28,565:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:28,565:INFO:Checking exceptions
2025-04-19 21:04:28,568:INFO:Preloading libraries
2025-04-19 21:04:28,568:INFO:Copying training dataset
2025-04-19 21:04:28,568:INFO:Plot type: learning
2025-04-19 21:04:28,880:INFO:Fitting Model
2025-04-19 21:04:29,701:INFO:Saving 'Learning Curve.png'
2025-04-19 21:04:30,134:INFO:Visual Rendered Successfully
2025-04-19 21:04:30,323:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:30,618:INFO:Initializing save_model()
2025-04-19 21:04:30,618:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:04:30,618:INFO:Adding model into prep_pipe
2025-04-19 21:04:30,651:INFO:models/model_2.pkl saved in current working directory
2025-04-19 21:04:30,684:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor()),
                                               ('Bayesian Ridge',
                                                BayesianRidge()),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 21:04:30,684:INFO:save_model() successfully completed......................................
2025-04-19 21:04:31,058:INFO:Initializing plot_model()
2025-04-19 21:04:31,058:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:31,058:INFO:Checking exceptions
2025-04-19 21:04:31,060:INFO:Initializing plot_model()
2025-04-19 21:04:31,060:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:31,060:INFO:Checking exceptions
2025-04-19 21:04:31,060:INFO:Preloading libraries
2025-04-19 21:04:31,060:INFO:Copying training dataset
2025-04-19 21:04:31,060:INFO:Plot type: residuals
2025-04-19 21:04:31,424:INFO:Fitting Model
2025-04-19 21:04:31,424:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:31,461:INFO:Scoring test/hold-out set
2025-04-19 21:04:31,496:INFO:Saving 'Residuals.png'
2025-04-19 21:04:32,235:INFO:Visual Rendered Successfully
2025-04-19 21:04:32,409:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:32,693:INFO:Initializing plot_model()
2025-04-19 21:04:32,693:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:32,693:INFO:Checking exceptions
2025-04-19 21:04:32,693:INFO:Preloading libraries
2025-04-19 21:04:32,693:INFO:Copying training dataset
2025-04-19 21:04:32,693:INFO:Plot type: error
2025-04-19 21:04:32,990:INFO:Fitting Model
2025-04-19 21:04:32,990:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:32,990:INFO:Scoring test/hold-out set
2025-04-19 21:04:33,018:INFO:Saving 'Prediction Error.png'
2025-04-19 21:04:33,374:INFO:Visual Rendered Successfully
2025-04-19 21:04:33,568:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:33,820:INFO:Initializing plot_model()
2025-04-19 21:04:33,820:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge', BayesianRidge()),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:33,820:INFO:Checking exceptions
2025-04-19 21:04:33,822:INFO:Preloading libraries
2025-04-19 21:04:33,822:INFO:Copying training dataset
2025-04-19 21:04:33,822:INFO:Plot type: learning
2025-04-19 21:04:34,118:INFO:Fitting Model
2025-04-19 21:04:35,632:INFO:Saving 'Learning Curve.png'
2025-04-19 21:04:36,036:INFO:Visual Rendered Successfully
2025-04-19 21:04:36,223:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:36,542:INFO:Initializing save_model()
2025-04-19 21:04:36,542:INFO:save_model(model=HuberRegressor(), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:04:36,542:INFO:Adding model into prep_pipe
2025-04-19 21:04:36,589:INFO:models/model_3.pkl saved in current working directory
2025-04-19 21:04:36,606:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor())])
2025-04-19 21:04:36,606:INFO:save_model() successfully completed......................................
2025-04-19 21:04:36,989:INFO:Initializing plot_model()
2025-04-19 21:04:36,989:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:36,989:INFO:Checking exceptions
2025-04-19 21:04:36,989:INFO:Preloading libraries
2025-04-19 21:04:36,989:INFO:Copying training dataset
2025-04-19 21:04:36,989:INFO:Plot type: feature
2025-04-19 21:04:37,178:INFO:Saving 'Feature Importance.png'
2025-04-19 21:04:37,346:INFO:Visual Rendered Successfully
2025-04-19 21:04:37,518:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:37,779:INFO:Initializing plot_model()
2025-04-19 21:04:37,779:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:37,779:INFO:Checking exceptions
2025-04-19 21:04:37,779:INFO:Preloading libraries
2025-04-19 21:04:37,779:INFO:Copying training dataset
2025-04-19 21:04:37,779:INFO:Plot type: residuals
2025-04-19 21:04:38,083:INFO:Fitting Model
2025-04-19 21:04:38,083:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:38,115:INFO:Scoring test/hold-out set
2025-04-19 21:04:38,147:INFO:Saving 'Residuals.png'
2025-04-19 21:04:38,855:INFO:Visual Rendered Successfully
2025-04-19 21:04:39,057:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:39,292:INFO:Initializing plot_model()
2025-04-19 21:04:39,292:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:39,292:INFO:Checking exceptions
2025-04-19 21:04:39,292:INFO:Preloading libraries
2025-04-19 21:04:39,292:INFO:Copying training dataset
2025-04-19 21:04:39,292:INFO:Plot type: error
2025-04-19 21:04:39,590:INFO:Fitting Model
2025-04-19 21:04:39,590:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:04:39,590:INFO:Scoring test/hold-out set
2025-04-19 21:04:39,595:INFO:Saving 'Prediction Error.png'
2025-04-19 21:04:40,018:INFO:Visual Rendered Successfully
2025-04-19 21:04:40,219:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:40,483:INFO:Initializing plot_model()
2025-04-19 21:04:40,483:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:40,483:INFO:Checking exceptions
2025-04-19 21:04:40,483:INFO:Preloading libraries
2025-04-19 21:04:40,483:INFO:Copying training dataset
2025-04-19 21:04:40,483:INFO:Plot type: learning
2025-04-19 21:04:40,805:INFO:Fitting Model
2025-04-19 21:04:41,149:INFO:Saving 'Learning Curve.png'
2025-04-19 21:04:41,551:INFO:Visual Rendered Successfully
2025-04-19 21:04:41,742:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:42,020:INFO:Initializing save_model()
2025-04-19 21:04:42,020:INFO:save_model(model=BayesianRidge(), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:04:42,020:INFO:Adding model into prep_pipe
2025-04-19 21:04:42,056:INFO:models/model_4.pkl saved in current working directory
2025-04-19 21:04:42,068:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', BayesianRidge())])
2025-04-19 21:04:42,068:INFO:save_model() successfully completed......................................
2025-04-19 21:04:42,486:INFO:Initializing plot_model()
2025-04-19 21:04:42,486:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:42,486:INFO:Checking exceptions
2025-04-19 21:04:42,486:INFO:Preloading libraries
2025-04-19 21:04:42,486:INFO:Copying training dataset
2025-04-19 21:04:42,486:INFO:Plot type: feature
2025-04-19 21:04:42,689:INFO:Saving 'Feature Importance.png'
2025-04-19 21:04:42,888:INFO:Visual Rendered Successfully
2025-04-19 21:04:43,050:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:43,308:INFO:Initializing plot_model()
2025-04-19 21:04:43,308:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:43,308:INFO:Checking exceptions
2025-04-19 21:04:43,323:INFO:Preloading libraries
2025-04-19 21:04:43,323:INFO:Copying training dataset
2025-04-19 21:04:43,323:INFO:Plot type: residuals
2025-04-19 21:04:43,642:INFO:Fitting Model
2025-04-19 21:04:43,642:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:04:43,670:INFO:Scoring test/hold-out set
2025-04-19 21:04:43,706:INFO:Saving 'Residuals.png'
2025-04-19 21:04:44,506:INFO:Visual Rendered Successfully
2025-04-19 21:04:44,688:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:44,955:INFO:Initializing plot_model()
2025-04-19 21:04:44,955:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:44,955:INFO:Checking exceptions
2025-04-19 21:04:44,957:INFO:Preloading libraries
2025-04-19 21:04:44,957:INFO:Copying training dataset
2025-04-19 21:04:44,957:INFO:Plot type: error
2025-04-19 21:04:45,269:INFO:Fitting Model
2025-04-19 21:04:45,270:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:04:45,270:INFO:Scoring test/hold-out set
2025-04-19 21:04:45,289:INFO:Saving 'Prediction Error.png'
2025-04-19 21:04:45,651:INFO:Visual Rendered Successfully
2025-04-19 21:04:45,832:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:46,091:INFO:Initializing plot_model()
2025-04-19 21:04:46,091:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:46,091:INFO:Checking exceptions
2025-04-19 21:04:46,091:INFO:Preloading libraries
2025-04-19 21:04:46,091:INFO:Copying training dataset
2025-04-19 21:04:46,091:INFO:Plot type: learning
2025-04-19 21:04:46,399:INFO:Fitting Model
2025-04-19 21:04:46,601:INFO:Saving 'Learning Curve.png'
2025-04-19 21:04:46,966:INFO:Visual Rendered Successfully
2025-04-19 21:04:47,154:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:47,403:INFO:Initializing save_model()
2025-04-19 21:04:47,404:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:04:47,404:INFO:Adding model into prep_pipe
2025-04-19 21:04:47,437:INFO:models/model_5.pkl saved in current working directory
2025-04-19 21:04:47,444:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_11', 'feature_21',
                                             'feature_19', 'feature_55',
                                             'feature_43', 'feature_49',
                                             'fe...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 21:04:47,444:INFO:save_model() successfully completed......................................
2025-04-19 21:04:47,823:INFO:Initializing plot_model()
2025-04-19 21:04:47,823:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:47,823:INFO:Checking exceptions
2025-04-19 21:04:47,823:INFO:Preloading libraries
2025-04-19 21:04:47,823:INFO:Copying training dataset
2025-04-19 21:04:47,823:INFO:Plot type: feature
2025-04-19 21:04:48,005:INFO:Saving 'Feature Importance.png'
2025-04-19 21:04:48,193:INFO:Visual Rendered Successfully
2025-04-19 21:04:48,362:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:48,614:INFO:Initializing plot_model()
2025-04-19 21:04:48,614:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:48,614:INFO:Checking exceptions
2025-04-19 21:04:48,618:INFO:Preloading libraries
2025-04-19 21:04:48,620:INFO:Copying training dataset
2025-04-19 21:04:48,620:INFO:Plot type: residuals
2025-04-19 21:04:48,937:INFO:Fitting Model
2025-04-19 21:04:48,937:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:04:48,966:INFO:Scoring test/hold-out set
2025-04-19 21:04:48,994:INFO:Saving 'Residuals.png'
2025-04-19 21:04:49,705:INFO:Visual Rendered Successfully
2025-04-19 21:04:49,904:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:50,184:INFO:Initializing plot_model()
2025-04-19 21:04:50,184:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:50,184:INFO:Checking exceptions
2025-04-19 21:04:50,187:INFO:Preloading libraries
2025-04-19 21:04:50,188:INFO:Copying training dataset
2025-04-19 21:04:50,188:INFO:Plot type: error
2025-04-19 21:04:50,495:INFO:Fitting Model
2025-04-19 21:04:50,495:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:04:50,495:INFO:Scoring test/hold-out set
2025-04-19 21:04:50,513:INFO:Saving 'Prediction Error.png'
2025-04-19 21:04:50,901:INFO:Visual Rendered Successfully
2025-04-19 21:04:51,093:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:51,367:INFO:Initializing plot_model()
2025-04-19 21:04:51,367:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, system=True)
2025-04-19 21:04:51,367:INFO:Checking exceptions
2025-04-19 21:04:51,370:INFO:Preloading libraries
2025-04-19 21:04:51,370:INFO:Copying training dataset
2025-04-19 21:04:51,370:INFO:Plot type: learning
2025-04-19 21:04:51,672:INFO:Fitting Model
2025-04-19 21:04:51,956:INFO:Saving 'Learning Curve.png'
2025-04-19 21:04:52,340:INFO:Visual Rendered Successfully
2025-04-19 21:04:52,518:INFO:plot_model() successfully completed......................................
2025-04-19 21:04:52,862:INFO:Initializing predict_model()
2025-04-19 21:04:52,862:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FAA4D8E5C0>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FAAADBF910>)
2025-04-19 21:04:52,862:INFO:Checking exceptions
2025-04-19 21:04:52,862:INFO:Preloading libraries
2025-04-19 21:04:52,862:INFO:Set up data.
2025-04-19 21:04:52,862:INFO:Set up index.
2025-04-19 21:05:43,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:05:43,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:05:43,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:05:43,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:06:14,797:INFO:PyCaret RegressionExperiment
2025-04-19 21:06:14,797:INFO:Logging name: agn_modeling
2025-04-19 21:06:14,797:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 21:06:14,797:INFO:version 3.0.4
2025-04-19 21:06:14,797:INFO:Initializing setup()
2025-04-19 21:06:14,797:INFO:self.USI: b0d8
2025-04-19 21:06:14,797:INFO:self._variable_keys: {'n_jobs_param', 'X', 'y_test', 'data', 'gpu_n_jobs_param', 'idx', 'seed', 'X_train', 'memory', 'pipeline', 'exp_id', 'log_plots_param', 'logging_param', 'transform_target_param', 'gpu_param', 'y_train', 'fold_groups_param', 'y', 'target_param', 'html_param', '_available_plots', 'X_test', 'fold_shuffle_param', 'exp_name_log', '_ml_usecase', 'USI', 'fold_generator'}
2025-04-19 21:06:14,797:INFO:Checking environment
2025-04-19 21:06:14,797:INFO:python_version: 3.10.9
2025-04-19 21:06:14,797:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 21:06:14,797:INFO:machine: AMD64
2025-04-19 21:06:14,822:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 21:06:14,826:INFO:Memory: svmem(total=16952647680, available=3934429184, percent=76.8, used=13018218496, free=3934429184)
2025-04-19 21:06:14,828:INFO:Physical Core: 4
2025-04-19 21:06:14,828:INFO:Logical Core: 8
2025-04-19 21:06:14,828:INFO:Checking libraries
2025-04-19 21:06:14,828:INFO:System:
2025-04-19 21:06:14,828:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 21:06:14,828:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 21:06:14,828:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 21:06:14,828:INFO:PyCaret required dependencies:
2025-04-19 21:06:15,572:INFO:                 pip: 25.0.1
2025-04-19 21:06:15,572:INFO:          setuptools: 65.5.0
2025-04-19 21:06:15,572:INFO:             pycaret: 3.0.4
2025-04-19 21:06:15,572:INFO:             IPython: 8.35.0
2025-04-19 21:06:15,572:INFO:          ipywidgets: 8.1.6
2025-04-19 21:06:15,572:INFO:                tqdm: 4.67.1
2025-04-19 21:06:15,572:INFO:               numpy: 1.23.5
2025-04-19 21:06:15,572:INFO:              pandas: 1.5.3
2025-04-19 21:06:15,572:INFO:              jinja2: 3.1.6
2025-04-19 21:06:15,572:INFO:               scipy: 1.11.4
2025-04-19 21:06:15,572:INFO:              joblib: 1.2.0
2025-04-19 21:06:15,572:INFO:             sklearn: 1.2.2
2025-04-19 21:06:15,572:INFO:                pyod: 2.0.4
2025-04-19 21:06:15,572:INFO:            imblearn: 0.12.4
2025-04-19 21:06:15,574:INFO:   category_encoders: 2.7.0
2025-04-19 21:06:15,574:INFO:            lightgbm: 4.6.0
2025-04-19 21:06:15,574:INFO:               numba: 0.58.1
2025-04-19 21:06:15,574:INFO:            requests: 2.32.3
2025-04-19 21:06:15,574:INFO:          matplotlib: 3.7.1
2025-04-19 21:06:15,574:INFO:          scikitplot: 0.3.7
2025-04-19 21:06:15,574:INFO:         yellowbrick: 1.5
2025-04-19 21:06:15,574:INFO:              plotly: 5.24.1
2025-04-19 21:06:15,574:INFO:    plotly-resampler: Not installed
2025-04-19 21:06:15,574:INFO:             kaleido: 0.2.1
2025-04-19 21:06:15,574:INFO:           schemdraw: 0.15
2025-04-19 21:06:15,574:INFO:         statsmodels: 0.14.4
2025-04-19 21:06:15,574:INFO:              sktime: 0.21.1
2025-04-19 21:06:15,574:INFO:               tbats: 1.1.3
2025-04-19 21:06:15,574:INFO:            pmdarima: 2.0.4
2025-04-19 21:06:15,574:INFO:              psutil: 7.0.0
2025-04-19 21:06:15,574:INFO:          markupsafe: 2.1.5
2025-04-19 21:06:15,574:INFO:             pickle5: Not installed
2025-04-19 21:06:15,574:INFO:         cloudpickle: 2.2.1
2025-04-19 21:06:15,574:INFO:         deprecation: 2.1.0
2025-04-19 21:06:15,574:INFO:              xxhash: 3.5.0
2025-04-19 21:06:15,574:INFO:           wurlitzer: Not installed
2025-04-19 21:06:15,574:INFO:PyCaret optional dependencies:
2025-04-19 21:06:17,264:INFO:                shap: 0.47.2
2025-04-19 21:06:17,264:INFO:           interpret: 0.6.6
2025-04-19 21:06:17,264:INFO:                umap: 0.5.7
2025-04-19 21:06:17,264:INFO:    pandas_profiling: 4.6.0
2025-04-19 21:06:17,264:INFO:  explainerdashboard: 0.4.8
2025-04-19 21:06:17,264:INFO:             autoviz: 0.1.902
2025-04-19 21:06:17,264:INFO:           fairlearn: 0.7.0
2025-04-19 21:06:17,264:INFO:          deepchecks: 0.19.1
2025-04-19 21:06:17,264:INFO:             xgboost: 1.6.2
2025-04-19 21:06:17,264:INFO:            catboost: 1.2.8
2025-04-19 21:06:17,264:INFO:              kmodes: 0.12.2
2025-04-19 21:06:17,264:INFO:             mlxtend: 0.23.1
2025-04-19 21:06:17,264:INFO:       statsforecast: 2.0.1
2025-04-19 21:06:17,264:INFO:        tune_sklearn: 0.5.0
2025-04-19 21:06:17,264:INFO:                 ray: 2.44.1
2025-04-19 21:06:17,264:INFO:            hyperopt: 0.2.7
2025-04-19 21:06:17,264:INFO:              optuna: 4.3.0
2025-04-19 21:06:17,264:INFO:               skopt: 0.10.2
2025-04-19 21:06:17,264:INFO:              mlflow: 2.21.3
2025-04-19 21:06:17,264:INFO:              gradio: 3.50.2
2025-04-19 21:06:17,264:INFO:             fastapi: 0.115.12
2025-04-19 21:06:17,264:INFO:             uvicorn: 0.34.2
2025-04-19 21:06:17,264:INFO:              m2cgen: 0.10.0
2025-04-19 21:06:17,264:INFO:           evidently: 0.2.8
2025-04-19 21:06:17,264:INFO:               fugue: 0.8.6
2025-04-19 21:06:17,264:INFO:           streamlit: Not installed
2025-04-19 21:06:17,264:INFO:             prophet: Not installed
2025-04-19 21:06:17,264:INFO:None
2025-04-19 21:06:17,264:INFO:Set up data.
2025-04-19 21:06:17,264:INFO:Set up train/test split.
2025-04-19 21:06:17,264:INFO:Set up index.
2025-04-19 21:06:17,264:INFO:Set up folding strategy.
2025-04-19 21:06:17,264:INFO:Assigning column types.
2025-04-19 21:06:17,264:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 21:06:17,264:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,387:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,413:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,439:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,457:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,520:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,565:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,565:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,565:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 21:06:17,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,660:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,660:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,660:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,725:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,763:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,765:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,765:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 21:06:17,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,849:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,849:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,871:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:17,945:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:17,945:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:17,945:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 21:06:18,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,058:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,058:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,148:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,148:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 21:06:18,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,243:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,307:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:06:18,356:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,356:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,356:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 21:06:18,456:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,457:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,548:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:18,548:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:18,556:INFO:Preparing preprocessing pipeline...
2025-04-19 21:06:18,556:INFO:Set up target transformation.
2025-04-19 21:06:18,556:INFO:Set up simple imputation.
2025-04-19 21:06:18,556:INFO:Set up removing multicollinearity.
2025-04-19 21:06:18,556:INFO:Set up removing outliers.
2025-04-19 21:06:18,556:INFO:Set up feature normalization.
2025-04-19 21:06:18,716:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:19,031:INFO:Finished creating preprocessing pipeline.
2025-04-19 21:06:19,039:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 21:06:19,039:INFO:Creating final display dataframe.
2025-04-19 21:06:19,224:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:19,763:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape    (7999, 10)
4        Transformed data shape    (7719, 10)
5   Transformed train set shape    (5319, 10)
6    Transformed test set shape    (2400, 10)
7              Numeric features             9
8      Rows with missing values         16.8%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          b0d8
2025-04-19 21:06:19,877:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:19,877:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:19,980:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:06:19,983:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:06:19,983:INFO:setup() successfully completed in 5.41s...............
2025-04-19 21:06:19,983:INFO:Initializing compare_models()
2025-04-19 21:06:19,983:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 21:06:19,983:INFO:Checking exceptions
2025-04-19 21:06:19,983:INFO:Preparing display monitor
2025-04-19 21:06:19,991:INFO:Initializing Linear Regression
2025-04-19 21:06:19,991:INFO:Total runtime is 8.829434712727864e-06 minutes
2025-04-19 21:06:19,991:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:19,991:INFO:Initializing create_model()
2025-04-19 21:06:19,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:19,991:INFO:Checking exceptions
2025-04-19 21:06:19,991:INFO:Importing libraries
2025-04-19 21:06:19,991:INFO:Copying training dataset
2025-04-19 21:06:19,996:INFO:Defining folds
2025-04-19 21:06:19,996:INFO:Declaring metric variables
2025-04-19 21:06:19,997:INFO:Importing untrained model
2025-04-19 21:06:19,997:INFO:Linear Regression Imported successfully
2025-04-19 21:06:19,997:INFO:Starting cross validation
2025-04-19 21:06:20,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:27,291:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,318:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,369:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,407:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,426:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,433:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,449:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:27,453:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:28,845:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:28,884:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:06:30,523:INFO:Calculating mean and std
2025-04-19 21:06:30,523:INFO:Creating metrics dataframe
2025-04-19 21:06:30,863:INFO:Uploading results into container
2025-04-19 21:06:30,864:INFO:Uploading model into container now
2025-04-19 21:06:30,864:INFO:_master_model_container: 1
2025-04-19 21:06:30,864:INFO:_display_container: 2
2025-04-19 21:06:30,864:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:06:30,864:INFO:create_model() successfully completed......................................
2025-04-19 21:06:31,109:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:31,109:INFO:Creating metrics dataframe
2025-04-19 21:06:31,115:INFO:Initializing Lasso Regression
2025-04-19 21:06:31,115:INFO:Total runtime is 0.18540906111399333 minutes
2025-04-19 21:06:31,115:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:31,115:INFO:Initializing create_model()
2025-04-19 21:06:31,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:31,115:INFO:Checking exceptions
2025-04-19 21:06:31,115:INFO:Importing libraries
2025-04-19 21:06:31,115:INFO:Copying training dataset
2025-04-19 21:06:31,120:INFO:Defining folds
2025-04-19 21:06:31,120:INFO:Declaring metric variables
2025-04-19 21:06:31,120:INFO:Importing untrained model
2025-04-19 21:06:31,120:INFO:Lasso Regression Imported successfully
2025-04-19 21:06:31,120:INFO:Starting cross validation
2025-04-19 21:06:31,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:33,439:INFO:Calculating mean and std
2025-04-19 21:06:33,439:INFO:Creating metrics dataframe
2025-04-19 21:06:33,772:INFO:Uploading results into container
2025-04-19 21:06:33,772:INFO:Uploading model into container now
2025-04-19 21:06:33,772:INFO:_master_model_container: 2
2025-04-19 21:06:33,772:INFO:_display_container: 2
2025-04-19 21:06:33,772:INFO:Lasso(random_state=42)
2025-04-19 21:06:33,772:INFO:create_model() successfully completed......................................
2025-04-19 21:06:33,868:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:33,868:INFO:Creating metrics dataframe
2025-04-19 21:06:33,884:INFO:Initializing Ridge Regression
2025-04-19 21:06:33,884:INFO:Total runtime is 0.2315656542778015 minutes
2025-04-19 21:06:33,884:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:33,884:INFO:Initializing create_model()
2025-04-19 21:06:33,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:33,884:INFO:Checking exceptions
2025-04-19 21:06:33,884:INFO:Importing libraries
2025-04-19 21:06:33,884:INFO:Copying training dataset
2025-04-19 21:06:33,892:INFO:Defining folds
2025-04-19 21:06:33,892:INFO:Declaring metric variables
2025-04-19 21:06:33,892:INFO:Importing untrained model
2025-04-19 21:06:33,892:INFO:Ridge Regression Imported successfully
2025-04-19 21:06:33,892:INFO:Starting cross validation
2025-04-19 21:06:33,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:36,177:INFO:Calculating mean and std
2025-04-19 21:06:36,177:INFO:Creating metrics dataframe
2025-04-19 21:06:36,571:INFO:Uploading results into container
2025-04-19 21:06:36,571:INFO:Uploading model into container now
2025-04-19 21:06:36,571:INFO:_master_model_container: 3
2025-04-19 21:06:36,571:INFO:_display_container: 2
2025-04-19 21:06:36,571:INFO:Ridge(random_state=42)
2025-04-19 21:06:36,571:INFO:create_model() successfully completed......................................
2025-04-19 21:06:36,680:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:36,680:INFO:Creating metrics dataframe
2025-04-19 21:06:36,689:INFO:Initializing Elastic Net
2025-04-19 21:06:36,689:INFO:Total runtime is 0.2783070206642151 minutes
2025-04-19 21:06:36,689:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:36,689:INFO:Initializing create_model()
2025-04-19 21:06:36,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:36,689:INFO:Checking exceptions
2025-04-19 21:06:36,689:INFO:Importing libraries
2025-04-19 21:06:36,689:INFO:Copying training dataset
2025-04-19 21:06:36,689:INFO:Defining folds
2025-04-19 21:06:36,689:INFO:Declaring metric variables
2025-04-19 21:06:36,689:INFO:Importing untrained model
2025-04-19 21:06:36,689:INFO:Elastic Net Imported successfully
2025-04-19 21:06:36,689:INFO:Starting cross validation
2025-04-19 21:06:36,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:38,987:INFO:Calculating mean and std
2025-04-19 21:06:38,987:INFO:Creating metrics dataframe
2025-04-19 21:06:39,371:INFO:Uploading results into container
2025-04-19 21:06:39,371:INFO:Uploading model into container now
2025-04-19 21:06:39,371:INFO:_master_model_container: 4
2025-04-19 21:06:39,371:INFO:_display_container: 2
2025-04-19 21:06:39,371:INFO:ElasticNet(random_state=42)
2025-04-19 21:06:39,371:INFO:create_model() successfully completed......................................
2025-04-19 21:06:39,485:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:39,485:INFO:Creating metrics dataframe
2025-04-19 21:06:39,485:INFO:Initializing Least Angle Regression
2025-04-19 21:06:39,485:INFO:Total runtime is 0.3249096393585205 minutes
2025-04-19 21:06:39,485:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:39,485:INFO:Initializing create_model()
2025-04-19 21:06:39,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:39,485:INFO:Checking exceptions
2025-04-19 21:06:39,485:INFO:Importing libraries
2025-04-19 21:06:39,485:INFO:Copying training dataset
2025-04-19 21:06:39,501:INFO:Defining folds
2025-04-19 21:06:39,501:INFO:Declaring metric variables
2025-04-19 21:06:39,501:INFO:Importing untrained model
2025-04-19 21:06:39,501:INFO:Least Angle Regression Imported successfully
2025-04-19 21:06:39,501:INFO:Starting cross validation
2025-04-19 21:06:39,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:41,734:INFO:Calculating mean and std
2025-04-19 21:06:41,734:INFO:Creating metrics dataframe
2025-04-19 21:06:42,132:INFO:Uploading results into container
2025-04-19 21:06:42,132:INFO:Uploading model into container now
2025-04-19 21:06:42,132:INFO:_master_model_container: 5
2025-04-19 21:06:42,132:INFO:_display_container: 2
2025-04-19 21:06:42,132:INFO:Lars(random_state=42)
2025-04-19 21:06:42,132:INFO:create_model() successfully completed......................................
2025-04-19 21:06:42,246:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:42,246:INFO:Creating metrics dataframe
2025-04-19 21:06:42,252:INFO:Initializing Lasso Least Angle Regression
2025-04-19 21:06:42,252:INFO:Total runtime is 0.3710386355717977 minutes
2025-04-19 21:06:42,252:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:42,252:INFO:Initializing create_model()
2025-04-19 21:06:42,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:42,252:INFO:Checking exceptions
2025-04-19 21:06:42,252:INFO:Importing libraries
2025-04-19 21:06:42,252:INFO:Copying training dataset
2025-04-19 21:06:42,258:INFO:Defining folds
2025-04-19 21:06:42,258:INFO:Declaring metric variables
2025-04-19 21:06:42,258:INFO:Importing untrained model
2025-04-19 21:06:42,258:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 21:06:42,258:INFO:Starting cross validation
2025-04-19 21:06:42,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:44,496:INFO:Calculating mean and std
2025-04-19 21:06:44,496:INFO:Creating metrics dataframe
2025-04-19 21:06:44,886:INFO:Uploading results into container
2025-04-19 21:06:44,886:INFO:Uploading model into container now
2025-04-19 21:06:44,886:INFO:_master_model_container: 6
2025-04-19 21:06:44,886:INFO:_display_container: 2
2025-04-19 21:06:44,886:INFO:LassoLars(random_state=42)
2025-04-19 21:06:44,886:INFO:create_model() successfully completed......................................
2025-04-19 21:06:44,996:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:44,996:INFO:Creating metrics dataframe
2025-04-19 21:06:45,000:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 21:06:45,000:INFO:Total runtime is 0.41682763497034714 minutes
2025-04-19 21:06:45,000:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:45,000:INFO:Initializing create_model()
2025-04-19 21:06:45,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:45,000:INFO:Checking exceptions
2025-04-19 21:06:45,000:INFO:Importing libraries
2025-04-19 21:06:45,000:INFO:Copying training dataset
2025-04-19 21:06:45,004:INFO:Defining folds
2025-04-19 21:06:45,004:INFO:Declaring metric variables
2025-04-19 21:06:45,004:INFO:Importing untrained model
2025-04-19 21:06:45,004:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 21:06:45,004:INFO:Starting cross validation
2025-04-19 21:06:45,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:47,272:INFO:Calculating mean and std
2025-04-19 21:06:47,272:INFO:Creating metrics dataframe
2025-04-19 21:06:47,581:INFO:Uploading results into container
2025-04-19 21:06:47,597:INFO:Uploading model into container now
2025-04-19 21:06:47,597:INFO:_master_model_container: 7
2025-04-19 21:06:47,597:INFO:_display_container: 2
2025-04-19 21:06:47,597:INFO:OrthogonalMatchingPursuit()
2025-04-19 21:06:47,597:INFO:create_model() successfully completed......................................
2025-04-19 21:06:47,704:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:47,704:INFO:Creating metrics dataframe
2025-04-19 21:06:47,704:INFO:Initializing Bayesian Ridge
2025-04-19 21:06:47,704:INFO:Total runtime is 0.4618910233179729 minutes
2025-04-19 21:06:47,704:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:47,704:INFO:Initializing create_model()
2025-04-19 21:06:47,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:47,704:INFO:Checking exceptions
2025-04-19 21:06:47,704:INFO:Importing libraries
2025-04-19 21:06:47,704:INFO:Copying training dataset
2025-04-19 21:06:47,704:INFO:Defining folds
2025-04-19 21:06:47,704:INFO:Declaring metric variables
2025-04-19 21:06:47,704:INFO:Importing untrained model
2025-04-19 21:06:47,704:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:06:47,704:INFO:Starting cross validation
2025-04-19 21:06:47,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:50,044:INFO:Calculating mean and std
2025-04-19 21:06:50,044:INFO:Creating metrics dataframe
2025-04-19 21:06:50,374:INFO:Uploading results into container
2025-04-19 21:06:50,374:INFO:Uploading model into container now
2025-04-19 21:06:50,374:INFO:_master_model_container: 8
2025-04-19 21:06:50,374:INFO:_display_container: 2
2025-04-19 21:06:50,374:INFO:BayesianRidge()
2025-04-19 21:06:50,374:INFO:create_model() successfully completed......................................
2025-04-19 21:06:50,484:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:50,484:INFO:Creating metrics dataframe
2025-04-19 21:06:50,488:INFO:Initializing Passive Aggressive Regressor
2025-04-19 21:06:50,488:INFO:Total runtime is 0.5082982341448467 minutes
2025-04-19 21:06:50,488:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:50,488:INFO:Initializing create_model()
2025-04-19 21:06:50,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:50,488:INFO:Checking exceptions
2025-04-19 21:06:50,490:INFO:Importing libraries
2025-04-19 21:06:50,490:INFO:Copying training dataset
2025-04-19 21:06:50,492:INFO:Defining folds
2025-04-19 21:06:50,492:INFO:Declaring metric variables
2025-04-19 21:06:50,492:INFO:Importing untrained model
2025-04-19 21:06:50,492:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 21:06:50,492:INFO:Starting cross validation
2025-04-19 21:06:50,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:52,724:INFO:Calculating mean and std
2025-04-19 21:06:52,724:INFO:Creating metrics dataframe
2025-04-19 21:06:53,047:INFO:Uploading results into container
2025-04-19 21:06:53,048:INFO:Uploading model into container now
2025-04-19 21:06:53,048:INFO:_master_model_container: 9
2025-04-19 21:06:53,048:INFO:_display_container: 2
2025-04-19 21:06:53,048:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 21:06:53,048:INFO:create_model() successfully completed......................................
2025-04-19 21:06:53,154:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:53,154:INFO:Creating metrics dataframe
2025-04-19 21:06:53,160:INFO:Initializing Huber Regressor
2025-04-19 21:06:53,160:INFO:Total runtime is 0.5528360446294149 minutes
2025-04-19 21:06:53,160:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:53,160:INFO:Initializing create_model()
2025-04-19 21:06:53,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:53,160:INFO:Checking exceptions
2025-04-19 21:06:53,160:INFO:Importing libraries
2025-04-19 21:06:53,160:INFO:Copying training dataset
2025-04-19 21:06:53,160:INFO:Defining folds
2025-04-19 21:06:53,160:INFO:Declaring metric variables
2025-04-19 21:06:53,160:INFO:Importing untrained model
2025-04-19 21:06:53,160:INFO:Huber Regressor Imported successfully
2025-04-19 21:06:53,160:INFO:Starting cross validation
2025-04-19 21:06:53,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:55,451:INFO:Calculating mean and std
2025-04-19 21:06:55,451:INFO:Creating metrics dataframe
2025-04-19 21:06:55,777:INFO:Uploading results into container
2025-04-19 21:06:55,777:INFO:Uploading model into container now
2025-04-19 21:06:55,777:INFO:_master_model_container: 10
2025-04-19 21:06:55,777:INFO:_display_container: 2
2025-04-19 21:06:55,777:INFO:HuberRegressor()
2025-04-19 21:06:55,777:INFO:create_model() successfully completed......................................
2025-04-19 21:06:55,891:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:55,891:INFO:Creating metrics dataframe
2025-04-19 21:06:55,894:INFO:Initializing K Neighbors Regressor
2025-04-19 21:06:55,894:INFO:Total runtime is 0.5984028577804567 minutes
2025-04-19 21:06:55,894:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:55,894:INFO:Initializing create_model()
2025-04-19 21:06:55,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:55,894:INFO:Checking exceptions
2025-04-19 21:06:55,894:INFO:Importing libraries
2025-04-19 21:06:55,894:INFO:Copying training dataset
2025-04-19 21:06:55,894:INFO:Defining folds
2025-04-19 21:06:55,894:INFO:Declaring metric variables
2025-04-19 21:06:55,894:INFO:Importing untrained model
2025-04-19 21:06:55,894:INFO:K Neighbors Regressor Imported successfully
2025-04-19 21:06:55,894:INFO:Starting cross validation
2025-04-19 21:06:55,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:06:58,314:INFO:Calculating mean and std
2025-04-19 21:06:58,316:INFO:Creating metrics dataframe
2025-04-19 21:06:58,657:INFO:Uploading results into container
2025-04-19 21:06:58,665:INFO:Uploading model into container now
2025-04-19 21:06:58,665:INFO:_master_model_container: 11
2025-04-19 21:06:58,665:INFO:_display_container: 2
2025-04-19 21:06:58,666:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 21:06:58,666:INFO:create_model() successfully completed......................................
2025-04-19 21:06:58,784:INFO:SubProcess create_model() end ==================================
2025-04-19 21:06:58,784:INFO:Creating metrics dataframe
2025-04-19 21:06:58,785:INFO:Initializing Decision Tree Regressor
2025-04-19 21:06:58,785:INFO:Total runtime is 0.6465843002001446 minutes
2025-04-19 21:06:58,785:INFO:SubProcess create_model() called ==================================
2025-04-19 21:06:58,785:INFO:Initializing create_model()
2025-04-19 21:06:58,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:06:58,785:INFO:Checking exceptions
2025-04-19 21:06:58,785:INFO:Importing libraries
2025-04-19 21:06:58,785:INFO:Copying training dataset
2025-04-19 21:06:58,785:INFO:Defining folds
2025-04-19 21:06:58,785:INFO:Declaring metric variables
2025-04-19 21:06:58,785:INFO:Importing untrained model
2025-04-19 21:06:58,785:INFO:Decision Tree Regressor Imported successfully
2025-04-19 21:06:58,785:INFO:Starting cross validation
2025-04-19 21:06:58,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:01,261:INFO:Calculating mean and std
2025-04-19 21:07:01,262:INFO:Creating metrics dataframe
2025-04-19 21:07:01,636:INFO:Uploading results into container
2025-04-19 21:07:01,636:INFO:Uploading model into container now
2025-04-19 21:07:01,637:INFO:_master_model_container: 12
2025-04-19 21:07:01,637:INFO:_display_container: 2
2025-04-19 21:07:01,637:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 21:07:01,637:INFO:create_model() successfully completed......................................
2025-04-19 21:07:01,751:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:01,751:INFO:Creating metrics dataframe
2025-04-19 21:07:01,755:INFO:Initializing Random Forest Regressor
2025-04-19 21:07:01,755:INFO:Total runtime is 0.6960789680480958 minutes
2025-04-19 21:07:01,755:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:01,755:INFO:Initializing create_model()
2025-04-19 21:07:01,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:01,755:INFO:Checking exceptions
2025-04-19 21:07:01,755:INFO:Importing libraries
2025-04-19 21:07:01,755:INFO:Copying training dataset
2025-04-19 21:07:01,759:INFO:Defining folds
2025-04-19 21:07:01,759:INFO:Declaring metric variables
2025-04-19 21:07:01,759:INFO:Importing untrained model
2025-04-19 21:07:01,761:INFO:Random Forest Regressor Imported successfully
2025-04-19 21:07:01,761:INFO:Starting cross validation
2025-04-19 21:07:01,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:09,727:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:07:10,212:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:07:15,430:INFO:Calculating mean and std
2025-04-19 21:07:15,430:INFO:Creating metrics dataframe
2025-04-19 21:07:15,813:INFO:Uploading results into container
2025-04-19 21:07:15,813:INFO:Uploading model into container now
2025-04-19 21:07:15,813:INFO:_master_model_container: 13
2025-04-19 21:07:15,813:INFO:_display_container: 2
2025-04-19 21:07:15,813:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:07:15,813:INFO:create_model() successfully completed......................................
2025-04-19 21:07:15,931:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:15,931:INFO:Creating metrics dataframe
2025-04-19 21:07:15,942:INFO:Initializing Extra Trees Regressor
2025-04-19 21:07:15,942:INFO:Total runtime is 0.9325316190719606 minutes
2025-04-19 21:07:15,942:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:15,942:INFO:Initializing create_model()
2025-04-19 21:07:15,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:15,942:INFO:Checking exceptions
2025-04-19 21:07:15,942:INFO:Importing libraries
2025-04-19 21:07:15,942:INFO:Copying training dataset
2025-04-19 21:07:15,947:INFO:Defining folds
2025-04-19 21:07:15,947:INFO:Declaring metric variables
2025-04-19 21:07:15,947:INFO:Importing untrained model
2025-04-19 21:07:15,947:INFO:Extra Trees Regressor Imported successfully
2025-04-19 21:07:15,947:INFO:Starting cross validation
2025-04-19 21:07:15,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:17,719:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:07:18,272:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:07:21,146:INFO:Calculating mean and std
2025-04-19 21:07:21,146:INFO:Creating metrics dataframe
2025-04-19 21:07:21,479:INFO:Uploading results into container
2025-04-19 21:07:21,479:INFO:Uploading model into container now
2025-04-19 21:07:21,479:INFO:_master_model_container: 14
2025-04-19 21:07:21,479:INFO:_display_container: 2
2025-04-19 21:07:21,479:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:07:21,479:INFO:create_model() successfully completed......................................
2025-04-19 21:07:21,587:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:21,587:INFO:Creating metrics dataframe
2025-04-19 21:07:21,587:INFO:Initializing AdaBoost Regressor
2025-04-19 21:07:21,587:INFO:Total runtime is 1.0266208291053773 minutes
2025-04-19 21:07:21,587:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:21,587:INFO:Initializing create_model()
2025-04-19 21:07:21,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:21,587:INFO:Checking exceptions
2025-04-19 21:07:21,587:INFO:Importing libraries
2025-04-19 21:07:21,587:INFO:Copying training dataset
2025-04-19 21:07:21,601:INFO:Defining folds
2025-04-19 21:07:21,601:INFO:Declaring metric variables
2025-04-19 21:07:21,601:INFO:Importing untrained model
2025-04-19 21:07:21,601:INFO:AdaBoost Regressor Imported successfully
2025-04-19 21:07:21,601:INFO:Starting cross validation
2025-04-19 21:07:21,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:24,312:INFO:Calculating mean and std
2025-04-19 21:07:24,312:INFO:Creating metrics dataframe
2025-04-19 21:07:24,718:INFO:Uploading results into container
2025-04-19 21:07:24,718:INFO:Uploading model into container now
2025-04-19 21:07:24,718:INFO:_master_model_container: 15
2025-04-19 21:07:24,718:INFO:_display_container: 2
2025-04-19 21:07:24,718:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 21:07:24,718:INFO:create_model() successfully completed......................................
2025-04-19 21:07:24,830:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:24,830:INFO:Creating metrics dataframe
2025-04-19 21:07:24,834:INFO:Initializing Gradient Boosting Regressor
2025-04-19 21:07:24,836:INFO:Total runtime is 1.080768132209778 minutes
2025-04-19 21:07:24,836:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:24,836:INFO:Initializing create_model()
2025-04-19 21:07:24,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:24,836:INFO:Checking exceptions
2025-04-19 21:07:24,836:INFO:Importing libraries
2025-04-19 21:07:24,836:INFO:Copying training dataset
2025-04-19 21:07:24,840:INFO:Defining folds
2025-04-19 21:07:24,840:INFO:Declaring metric variables
2025-04-19 21:07:24,840:INFO:Importing untrained model
2025-04-19 21:07:24,840:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 21:07:24,840:INFO:Starting cross validation
2025-04-19 21:07:24,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:29,379:INFO:Calculating mean and std
2025-04-19 21:07:29,380:INFO:Creating metrics dataframe
2025-04-19 21:07:29,829:INFO:Uploading results into container
2025-04-19 21:07:29,829:INFO:Uploading model into container now
2025-04-19 21:07:29,829:INFO:_master_model_container: 16
2025-04-19 21:07:29,829:INFO:_display_container: 2
2025-04-19 21:07:29,829:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 21:07:29,829:INFO:create_model() successfully completed......................................
2025-04-19 21:07:29,930:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:29,930:INFO:Creating metrics dataframe
2025-04-19 21:07:29,930:INFO:Initializing Extreme Gradient Boosting
2025-04-19 21:07:29,930:INFO:Total runtime is 1.165666464964549 minutes
2025-04-19 21:07:29,930:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:29,930:INFO:Initializing create_model()
2025-04-19 21:07:29,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:29,930:INFO:Checking exceptions
2025-04-19 21:07:29,930:INFO:Importing libraries
2025-04-19 21:07:29,944:INFO:Copying training dataset
2025-04-19 21:07:29,946:INFO:Defining folds
2025-04-19 21:07:29,946:INFO:Declaring metric variables
2025-04-19 21:07:29,946:INFO:Importing untrained model
2025-04-19 21:07:29,946:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:07:29,946:INFO:Starting cross validation
2025-04-19 21:07:29,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:33,945:INFO:Calculating mean and std
2025-04-19 21:07:33,945:INFO:Creating metrics dataframe
2025-04-19 21:07:34,309:INFO:Uploading results into container
2025-04-19 21:07:34,309:INFO:Uploading model into container now
2025-04-19 21:07:34,309:INFO:_master_model_container: 17
2025-04-19 21:07:34,309:INFO:_display_container: 2
2025-04-19 21:07:34,325:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2025-04-19 21:07:34,325:INFO:create_model() successfully completed......................................
2025-04-19 21:07:34,429:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:34,429:INFO:Creating metrics dataframe
2025-04-19 21:07:34,429:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 21:07:34,429:INFO:Total runtime is 1.240650788942973 minutes
2025-04-19 21:07:34,429:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:34,429:INFO:Initializing create_model()
2025-04-19 21:07:34,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:34,429:INFO:Checking exceptions
2025-04-19 21:07:34,429:INFO:Importing libraries
2025-04-19 21:07:34,429:INFO:Copying training dataset
2025-04-19 21:07:34,429:INFO:Defining folds
2025-04-19 21:07:34,429:INFO:Declaring metric variables
2025-04-19 21:07:34,429:INFO:Importing untrained model
2025-04-19 21:07:34,429:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:07:34,429:INFO:Starting cross validation
2025-04-19 21:07:34,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:38,090:INFO:Calculating mean and std
2025-04-19 21:07:38,090:INFO:Creating metrics dataframe
2025-04-19 21:07:38,512:INFO:Uploading results into container
2025-04-19 21:07:38,512:INFO:Uploading model into container now
2025-04-19 21:07:38,512:INFO:_master_model_container: 18
2025-04-19 21:07:38,512:INFO:_display_container: 2
2025-04-19 21:07:38,512:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:07:38,512:INFO:create_model() successfully completed......................................
2025-04-19 21:07:38,635:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:38,635:INFO:Creating metrics dataframe
2025-04-19 21:07:38,635:INFO:Initializing Dummy Regressor
2025-04-19 21:07:38,635:INFO:Total runtime is 1.310750206311544 minutes
2025-04-19 21:07:38,635:INFO:SubProcess create_model() called ==================================
2025-04-19 21:07:38,635:INFO:Initializing create_model()
2025-04-19 21:07:38,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AC079CC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:38,635:INFO:Checking exceptions
2025-04-19 21:07:38,635:INFO:Importing libraries
2025-04-19 21:07:38,635:INFO:Copying training dataset
2025-04-19 21:07:38,635:INFO:Defining folds
2025-04-19 21:07:38,635:INFO:Declaring metric variables
2025-04-19 21:07:38,635:INFO:Importing untrained model
2025-04-19 21:07:38,635:INFO:Dummy Regressor Imported successfully
2025-04-19 21:07:38,635:INFO:Starting cross validation
2025-04-19 21:07:38,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:07:41,230:INFO:Calculating mean and std
2025-04-19 21:07:41,230:INFO:Creating metrics dataframe
2025-04-19 21:07:41,689:INFO:Uploading results into container
2025-04-19 21:07:41,689:INFO:Uploading model into container now
2025-04-19 21:07:41,689:INFO:_master_model_container: 19
2025-04-19 21:07:41,689:INFO:_display_container: 2
2025-04-19 21:07:41,689:INFO:DummyRegressor()
2025-04-19 21:07:41,689:INFO:create_model() successfully completed......................................
2025-04-19 21:07:41,825:INFO:SubProcess create_model() end ==================================
2025-04-19 21:07:41,825:INFO:Creating metrics dataframe
2025-04-19 21:07:41,834:INFO:Initializing create_model()
2025-04-19 21:07:41,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:41,834:INFO:Checking exceptions
2025-04-19 21:07:41,838:INFO:Importing libraries
2025-04-19 21:07:41,838:INFO:Copying training dataset
2025-04-19 21:07:41,844:INFO:Defining folds
2025-04-19 21:07:41,844:INFO:Declaring metric variables
2025-04-19 21:07:41,848:INFO:Importing untrained model
2025-04-19 21:07:41,848:INFO:Declaring custom model
2025-04-19 21:07:41,849:INFO:Huber Regressor Imported successfully
2025-04-19 21:07:41,859:INFO:Cross validation set to False
2025-04-19 21:07:41,859:INFO:Fitting Model
2025-04-19 21:07:42,251:INFO:HuberRegressor()
2025-04-19 21:07:42,251:INFO:create_model() successfully completed......................................
2025-04-19 21:07:42,362:INFO:Initializing create_model()
2025-04-19 21:07:42,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:42,362:INFO:Checking exceptions
2025-04-19 21:07:42,362:INFO:Importing libraries
2025-04-19 21:07:42,362:INFO:Copying training dataset
2025-04-19 21:07:42,362:INFO:Defining folds
2025-04-19 21:07:42,362:INFO:Declaring metric variables
2025-04-19 21:07:42,362:INFO:Importing untrained model
2025-04-19 21:07:42,362:INFO:Declaring custom model
2025-04-19 21:07:42,362:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:07:42,386:INFO:Cross validation set to False
2025-04-19 21:07:42,386:INFO:Fitting Model
2025-04-19 21:07:42,682:INFO:BayesianRidge()
2025-04-19 21:07:42,682:INFO:create_model() successfully completed......................................
2025-04-19 21:07:42,803:INFO:Initializing create_model()
2025-04-19 21:07:42,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:07:42,803:INFO:Checking exceptions
2025-04-19 21:07:42,807:INFO:Importing libraries
2025-04-19 21:07:42,807:INFO:Copying training dataset
2025-04-19 21:07:42,811:INFO:Defining folds
2025-04-19 21:07:42,811:INFO:Declaring metric variables
2025-04-19 21:07:42,811:INFO:Importing untrained model
2025-04-19 21:07:42,811:INFO:Declaring custom model
2025-04-19 21:07:42,811:INFO:Linear Regression Imported successfully
2025-04-19 21:07:42,822:INFO:Cross validation set to False
2025-04-19 21:07:42,822:INFO:Fitting Model
2025-04-19 21:07:43,207:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:07:43,207:INFO:create_model() successfully completed......................................
2025-04-19 21:07:43,354:INFO:_master_model_container: 19
2025-04-19 21:07:43,354:INFO:_display_container: 2
2025-04-19 21:07:43,356:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 21:07:43,356:INFO:compare_models() successfully completed......................................
2025-04-19 21:07:43,356:INFO:Initializing tune_model()
2025-04-19 21:07:43,356:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>)
2025-04-19 21:07:43,356:INFO:Checking exceptions
2025-04-19 21:07:43,361:INFO:Copying training dataset
2025-04-19 21:07:43,372:INFO:Checking base model
2025-04-19 21:07:43,372:INFO:Base model : Huber Regressor
2025-04-19 21:07:43,372:INFO:Declaring metric variables
2025-04-19 21:07:43,372:INFO:Defining Hyperparameters
2025-04-19 21:07:43,537:INFO:Tuning with n_jobs=-1
2025-04-19 21:07:43,537:INFO:Initializing RandomizedSearchCV
2025-04-19 21:08:10,761:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.01}
2025-04-19 21:08:10,761:INFO:Hyperparameter search completed
2025-04-19 21:08:10,761:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:10,761:INFO:Initializing create_model()
2025-04-19 21:08:10,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190A877A200>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.4, 'alpha': 0.01})
2025-04-19 21:08:10,761:INFO:Checking exceptions
2025-04-19 21:08:10,761:INFO:Importing libraries
2025-04-19 21:08:10,761:INFO:Copying training dataset
2025-04-19 21:08:10,761:INFO:Defining folds
2025-04-19 21:08:10,761:INFO:Declaring metric variables
2025-04-19 21:08:10,761:INFO:Importing untrained model
2025-04-19 21:08:10,761:INFO:Declaring custom model
2025-04-19 21:08:10,761:INFO:Huber Regressor Imported successfully
2025-04-19 21:08:10,761:INFO:Starting cross validation
2025-04-19 21:08:10,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:08:13,159:INFO:Calculating mean and std
2025-04-19 21:08:13,159:INFO:Creating metrics dataframe
2025-04-19 21:08:13,170:INFO:Finalizing model
2025-04-19 21:08:13,566:INFO:Uploading results into container
2025-04-19 21:08:13,566:INFO:Uploading model into container now
2025-04-19 21:08:13,566:INFO:_master_model_container: 20
2025-04-19 21:08:13,566:INFO:_display_container: 3
2025-04-19 21:08:13,566:INFO:HuberRegressor(alpha=0.01, epsilon=1.4)
2025-04-19 21:08:13,566:INFO:create_model() successfully completed......................................
2025-04-19 21:08:13,679:INFO:SubProcess create_model() end ==================================
2025-04-19 21:08:13,679:INFO:choose_better activated
2025-04-19 21:08:13,679:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:13,679:INFO:Initializing create_model()
2025-04-19 21:08:13,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:08:13,679:INFO:Checking exceptions
2025-04-19 21:08:13,695:INFO:Importing libraries
2025-04-19 21:08:13,695:INFO:Copying training dataset
2025-04-19 21:08:13,696:INFO:Defining folds
2025-04-19 21:08:13,696:INFO:Declaring metric variables
2025-04-19 21:08:13,696:INFO:Importing untrained model
2025-04-19 21:08:13,696:INFO:Declaring custom model
2025-04-19 21:08:13,696:INFO:Huber Regressor Imported successfully
2025-04-19 21:08:13,696:INFO:Starting cross validation
2025-04-19 21:08:13,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:08:16,180:INFO:Calculating mean and std
2025-04-19 21:08:16,181:INFO:Creating metrics dataframe
2025-04-19 21:08:16,183:INFO:Finalizing model
2025-04-19 21:08:16,643:INFO:Uploading results into container
2025-04-19 21:08:16,646:INFO:Uploading model into container now
2025-04-19 21:08:16,646:INFO:_master_model_container: 21
2025-04-19 21:08:16,646:INFO:_display_container: 4
2025-04-19 21:08:16,647:INFO:HuberRegressor()
2025-04-19 21:08:16,647:INFO:create_model() successfully completed......................................
2025-04-19 21:08:16,751:INFO:SubProcess create_model() end ==================================
2025-04-19 21:08:16,752:INFO:HuberRegressor() result for R2 is 0.0034
2025-04-19 21:08:16,752:INFO:HuberRegressor(alpha=0.01, epsilon=1.4) result for R2 is 0.0034
2025-04-19 21:08:16,752:INFO:HuberRegressor() is best model
2025-04-19 21:08:16,752:INFO:choose_better completed
2025-04-19 21:08:16,753:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:08:16,757:INFO:_master_model_container: 21
2025-04-19 21:08:16,757:INFO:_display_container: 3
2025-04-19 21:08:16,757:INFO:HuberRegressor()
2025-04-19 21:08:16,757:INFO:tune_model() successfully completed......................................
2025-04-19 21:08:17,191:INFO:Initializing tune_model()
2025-04-19 21:08:17,191:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>)
2025-04-19 21:08:17,191:INFO:Checking exceptions
2025-04-19 21:08:17,194:INFO:Copying training dataset
2025-04-19 21:08:17,198:INFO:Checking base model
2025-04-19 21:08:17,198:INFO:Base model : Bayesian Ridge
2025-04-19 21:08:17,199:INFO:Declaring metric variables
2025-04-19 21:08:17,199:INFO:Defining Hyperparameters
2025-04-19 21:08:17,333:INFO:Tuning with n_jobs=-1
2025-04-19 21:08:17,335:INFO:Initializing RandomizedSearchCV
2025-04-19 21:08:43,738:INFO:best_params: {'actual_estimator__lambda_2': 0.05, 'actual_estimator__lambda_1': 0.0005, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': False, 'actual_estimator__alpha_2': 0.01, 'actual_estimator__alpha_1': 0.005}
2025-04-19 21:08:43,738:INFO:Hyperparameter search completed
2025-04-19 21:08:43,738:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:43,740:INFO:Initializing create_model()
2025-04-19 21:08:43,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190A4408370>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.05, 'lambda_1': 0.0005, 'fit_intercept': True, 'compute_score': False, 'alpha_2': 0.01, 'alpha_1': 0.005})
2025-04-19 21:08:43,740:INFO:Checking exceptions
2025-04-19 21:08:43,740:INFO:Importing libraries
2025-04-19 21:08:43,740:INFO:Copying training dataset
2025-04-19 21:08:43,740:INFO:Defining folds
2025-04-19 21:08:43,740:INFO:Declaring metric variables
2025-04-19 21:08:43,740:INFO:Importing untrained model
2025-04-19 21:08:43,740:INFO:Declaring custom model
2025-04-19 21:08:43,740:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:08:43,740:INFO:Starting cross validation
2025-04-19 21:08:43,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:08:46,136:INFO:Calculating mean and std
2025-04-19 21:08:46,136:INFO:Creating metrics dataframe
2025-04-19 21:08:46,139:INFO:Finalizing model
2025-04-19 21:08:46,614:INFO:Uploading results into container
2025-04-19 21:08:46,622:INFO:Uploading model into container now
2025-04-19 21:08:46,622:INFO:_master_model_container: 22
2025-04-19 21:08:46,622:INFO:_display_container: 4
2025-04-19 21:08:46,622:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)
2025-04-19 21:08:46,622:INFO:create_model() successfully completed......................................
2025-04-19 21:08:46,751:INFO:SubProcess create_model() end ==================================
2025-04-19 21:08:46,751:INFO:choose_better activated
2025-04-19 21:08:46,751:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:46,751:INFO:Initializing create_model()
2025-04-19 21:08:46,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:08:46,751:INFO:Checking exceptions
2025-04-19 21:08:46,751:INFO:Importing libraries
2025-04-19 21:08:46,751:INFO:Copying training dataset
2025-04-19 21:08:46,751:INFO:Defining folds
2025-04-19 21:08:46,751:INFO:Declaring metric variables
2025-04-19 21:08:46,751:INFO:Importing untrained model
2025-04-19 21:08:46,760:INFO:Declaring custom model
2025-04-19 21:08:46,760:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:08:46,760:INFO:Starting cross validation
2025-04-19 21:08:46,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:08:49,177:INFO:Calculating mean and std
2025-04-19 21:08:49,177:INFO:Creating metrics dataframe
2025-04-19 21:08:49,177:INFO:Finalizing model
2025-04-19 21:08:49,581:INFO:Uploading results into container
2025-04-19 21:08:49,581:INFO:Uploading model into container now
2025-04-19 21:08:49,581:INFO:_master_model_container: 23
2025-04-19 21:08:49,581:INFO:_display_container: 5
2025-04-19 21:08:49,581:INFO:BayesianRidge()
2025-04-19 21:08:49,581:INFO:create_model() successfully completed......................................
2025-04-19 21:08:49,678:INFO:SubProcess create_model() end ==================================
2025-04-19 21:08:49,678:INFO:BayesianRidge() result for R2 is -0.0005
2025-04-19 21:08:49,680:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05) result for R2 is -0.0004
2025-04-19 21:08:49,680:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05) is best model
2025-04-19 21:08:49,680:INFO:choose_better completed
2025-04-19 21:08:49,682:INFO:_master_model_container: 23
2025-04-19 21:08:49,682:INFO:_display_container: 4
2025-04-19 21:08:49,682:INFO:BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)
2025-04-19 21:08:49,682:INFO:tune_model() successfully completed......................................
2025-04-19 21:08:50,004:INFO:Initializing tune_model()
2025-04-19 21:08:50,004:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>)
2025-04-19 21:08:50,004:INFO:Checking exceptions
2025-04-19 21:08:50,020:INFO:Copying training dataset
2025-04-19 21:08:50,020:INFO:Checking base model
2025-04-19 21:08:50,020:INFO:Base model : Linear Regression
2025-04-19 21:08:50,020:INFO:Declaring metric variables
2025-04-19 21:08:50,020:INFO:Defining Hyperparameters
2025-04-19 21:08:50,020:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 21:08:50,135:INFO:Tuning with n_jobs=-1
2025-04-19 21:08:50,135:INFO:Initializing GridSearchCV
2025-04-19 21:08:55,544:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 21:08:55,544:INFO:Hyperparameter search completed
2025-04-19 21:08:55,544:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:55,544:INFO:Initializing create_model()
2025-04-19 21:08:55,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190A8AEBB80>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 21:08:55,544:INFO:Checking exceptions
2025-04-19 21:08:55,544:INFO:Importing libraries
2025-04-19 21:08:55,544:INFO:Copying training dataset
2025-04-19 21:08:55,554:INFO:Defining folds
2025-04-19 21:08:55,554:INFO:Declaring metric variables
2025-04-19 21:08:55,554:INFO:Importing untrained model
2025-04-19 21:08:55,554:INFO:Declaring custom model
2025-04-19 21:08:55,554:INFO:Linear Regression Imported successfully
2025-04-19 21:08:55,559:INFO:Starting cross validation
2025-04-19 21:08:55,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:08:58,001:INFO:Calculating mean and std
2025-04-19 21:08:58,001:INFO:Creating metrics dataframe
2025-04-19 21:08:58,001:INFO:Finalizing model
2025-04-19 21:08:58,388:INFO:Uploading results into container
2025-04-19 21:08:58,388:INFO:Uploading model into container now
2025-04-19 21:08:58,388:INFO:_master_model_container: 24
2025-04-19 21:08:58,388:INFO:_display_container: 5
2025-04-19 21:08:58,388:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:08:58,388:INFO:create_model() successfully completed......................................
2025-04-19 21:08:58,502:INFO:SubProcess create_model() end ==================================
2025-04-19 21:08:58,502:INFO:choose_better activated
2025-04-19 21:08:58,502:INFO:SubProcess create_model() called ==================================
2025-04-19 21:08:58,502:INFO:Initializing create_model()
2025-04-19 21:08:58,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:08:58,502:INFO:Checking exceptions
2025-04-19 21:08:58,511:INFO:Importing libraries
2025-04-19 21:08:58,511:INFO:Copying training dataset
2025-04-19 21:08:58,511:INFO:Defining folds
2025-04-19 21:08:58,511:INFO:Declaring metric variables
2025-04-19 21:08:58,511:INFO:Importing untrained model
2025-04-19 21:08:58,511:INFO:Declaring custom model
2025-04-19 21:08:58,511:INFO:Linear Regression Imported successfully
2025-04-19 21:08:58,511:INFO:Starting cross validation
2025-04-19 21:08:58,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:09:00,894:INFO:Calculating mean and std
2025-04-19 21:09:00,894:INFO:Creating metrics dataframe
2025-04-19 21:09:00,894:INFO:Finalizing model
2025-04-19 21:09:01,287:INFO:Uploading results into container
2025-04-19 21:09:01,294:INFO:Uploading model into container now
2025-04-19 21:09:01,294:INFO:_master_model_container: 25
2025-04-19 21:09:01,294:INFO:_display_container: 6
2025-04-19 21:09:01,294:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:09:01,294:INFO:create_model() successfully completed......................................
2025-04-19 21:09:01,391:INFO:SubProcess create_model() end ==================================
2025-04-19 21:09:01,393:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0007
2025-04-19 21:09:01,393:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0007
2025-04-19 21:09:01,393:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 21:09:01,393:INFO:choose_better completed
2025-04-19 21:09:01,393:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:09:01,401:INFO:_master_model_container: 25
2025-04-19 21:09:01,401:INFO:_display_container: 5
2025-04-19 21:09:01,401:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:09:01,401:INFO:tune_model() successfully completed......................................
2025-04-19 21:09:01,733:INFO:Initializing blend_models()
2025-04-19 21:09:01,733:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:09:01,733:INFO:Checking exceptions
2025-04-19 21:09:01,741:INFO:Importing libraries
2025-04-19 21:09:01,741:INFO:Copying training dataset
2025-04-19 21:09:01,741:INFO:Getting model names
2025-04-19 21:09:01,741:INFO:SubProcess create_model() called ==================================
2025-04-19 21:09:01,745:INFO:Initializing create_model()
2025-04-19 21:09:01,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AB5BD5D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:09:01,745:INFO:Checking exceptions
2025-04-19 21:09:01,745:INFO:Importing libraries
2025-04-19 21:09:01,745:INFO:Copying training dataset
2025-04-19 21:09:01,749:INFO:Defining folds
2025-04-19 21:09:01,749:INFO:Declaring metric variables
2025-04-19 21:09:01,749:INFO:Importing untrained model
2025-04-19 21:09:01,749:INFO:Declaring custom model
2025-04-19 21:09:01,749:INFO:Voting Regressor Imported successfully
2025-04-19 21:09:01,749:INFO:Starting cross validation
2025-04-19 21:09:01,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:09:04,182:INFO:Calculating mean and std
2025-04-19 21:09:04,182:INFO:Creating metrics dataframe
2025-04-19 21:09:04,182:INFO:Finalizing model
2025-04-19 21:09:04,693:INFO:Uploading results into container
2025-04-19 21:09:04,693:INFO:Uploading model into container now
2025-04-19 21:09:04,703:INFO:_master_model_container: 26
2025-04-19 21:09:04,703:INFO:_display_container: 6
2025-04-19 21:09:04,705:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:09:04,705:INFO:create_model() successfully completed......................................
2025-04-19 21:09:04,818:INFO:SubProcess create_model() end ==================================
2025-04-19 21:09:04,833:INFO:_master_model_container: 26
2025-04-19 21:09:04,833:INFO:_display_container: 6
2025-04-19 21:09:04,833:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:09:04,833:INFO:blend_models() successfully completed......................................
2025-04-19 21:09:04,951:INFO:Initializing stack_models()
2025-04-19 21:09:04,951:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:09:04,951:INFO:Checking exceptions
2025-04-19 21:09:04,953:INFO:Defining meta model
2025-04-19 21:09:04,953:INFO:Getting model names
2025-04-19 21:09:04,953:INFO:[('Huber Regressor', HuberRegressor()), ('Bayesian Ridge', BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05)), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 21:09:04,953:INFO:SubProcess create_model() called ==================================
2025-04-19 21:09:04,958:INFO:Initializing create_model()
2025-04-19 21:09:04,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000190AB5BD5D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:09:04,958:INFO:Checking exceptions
2025-04-19 21:09:04,958:INFO:Importing libraries
2025-04-19 21:09:04,958:INFO:Copying training dataset
2025-04-19 21:09:04,964:INFO:Defining folds
2025-04-19 21:09:04,964:INFO:Declaring metric variables
2025-04-19 21:09:04,964:INFO:Importing untrained model
2025-04-19 21:09:04,964:INFO:Declaring custom model
2025-04-19 21:09:04,964:INFO:Stacking Regressor Imported successfully
2025-04-19 21:09:04,964:INFO:Starting cross validation
2025-04-19 21:09:04,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:09:07,718:INFO:Calculating mean and std
2025-04-19 21:09:07,718:INFO:Creating metrics dataframe
2025-04-19 21:09:07,718:INFO:Finalizing model
2025-04-19 21:09:08,346:INFO:Uploading results into container
2025-04-19 21:09:08,346:INFO:Uploading model into container now
2025-04-19 21:09:08,346:INFO:_master_model_container: 27
2025-04-19 21:09:08,346:INFO:_display_container: 7
2025-04-19 21:09:08,356:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:09:08,356:INFO:create_model() successfully completed......................................
2025-04-19 21:09:08,607:INFO:SubProcess create_model() end ==================================
2025-04-19 21:09:08,617:INFO:_master_model_container: 27
2025-04-19 21:09:08,617:INFO:_display_container: 7
2025-04-19 21:09:08,617:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:09:08,623:INFO:stack_models() successfully completed......................................
2025-04-19 21:09:08,773:INFO:Initializing save_model()
2025-04-19 21:09:08,773:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:09:08,773:INFO:Adding model into prep_pipe
2025-04-19 21:09:08,828:INFO:models/model_1.pkl saved in current working directory
2025-04-19 21:09:08,846:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor()),
                                             ('Bayesian Ridge',
                                              BayesianRidge(alpha_1=0.005,
                                                            alpha_2=0.01,
                                                            lambda_1=0.0005,
                                                            lambda_2=0.05)),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 21:09:08,846:INFO:save_model() successfully completed......................................
2025-04-19 21:09:09,230:INFO:Initializing plot_model()
2025-04-19 21:09:09,230:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:09,230:INFO:Checking exceptions
2025-04-19 21:09:09,230:INFO:Initializing plot_model()
2025-04-19 21:09:09,230:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:09,230:INFO:Checking exceptions
2025-04-19 21:09:09,230:INFO:Preloading libraries
2025-04-19 21:09:09,230:INFO:Copying training dataset
2025-04-19 21:09:09,230:INFO:Plot type: residuals
2025-04-19 21:09:09,694:INFO:Fitting Model
2025-04-19 21:09:09,694:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:09,738:INFO:Scoring test/hold-out set
2025-04-19 21:09:09,814:INFO:Saving 'Residuals.png'
2025-04-19 21:09:10,806:INFO:Visual Rendered Successfully
2025-04-19 21:09:10,921:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:11,173:INFO:Initializing plot_model()
2025-04-19 21:09:11,173:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:11,173:INFO:Checking exceptions
2025-04-19 21:09:11,173:INFO:Preloading libraries
2025-04-19 21:09:11,173:INFO:Copying training dataset
2025-04-19 21:09:11,173:INFO:Plot type: error
2025-04-19 21:09:11,463:INFO:Fitting Model
2025-04-19 21:09:11,463:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:11,463:INFO:Scoring test/hold-out set
2025-04-19 21:09:11,486:INFO:Saving 'Prediction Error.png'
2025-04-19 21:09:11,826:INFO:Visual Rendered Successfully
2025-04-19 21:09:11,940:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:12,231:INFO:Initializing plot_model()
2025-04-19 21:09:12,231:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:12,231:INFO:Checking exceptions
2025-04-19 21:09:12,232:INFO:Preloading libraries
2025-04-19 21:09:12,232:INFO:Copying training dataset
2025-04-19 21:09:12,232:INFO:Plot type: learning
2025-04-19 21:09:12,502:INFO:Fitting Model
2025-04-19 21:09:13,365:INFO:Saving 'Learning Curve.png'
2025-04-19 21:09:14,079:INFO:Visual Rendered Successfully
2025-04-19 21:09:14,264:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:14,565:INFO:Initializing save_model()
2025-04-19 21:09:14,565:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:09:14,565:INFO:Adding model into prep_pipe
2025-04-19 21:09:14,606:INFO:models/model_2.pkl saved in current working directory
2025-04-19 21:09:14,631:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor()),
                                               ('Bayesian Ridge',
                                                BayesianRidge(alpha_1=0.005,
                                                              alpha_2=0.01,
                                                              lambda_1=0.0005,
                                                              lambda_2=0.05)),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 21:09:14,631:INFO:save_model() successfully completed......................................
2025-04-19 21:09:14,994:INFO:Initializing plot_model()
2025-04-19 21:09:14,994:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:14,994:INFO:Checking exceptions
2025-04-19 21:09:14,997:INFO:Initializing plot_model()
2025-04-19 21:09:14,997:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:14,997:INFO:Checking exceptions
2025-04-19 21:09:14,999:INFO:Preloading libraries
2025-04-19 21:09:14,999:INFO:Copying training dataset
2025-04-19 21:09:14,999:INFO:Plot type: residuals
2025-04-19 21:09:15,310:INFO:Fitting Model
2025-04-19 21:09:15,310:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:15,348:INFO:Scoring test/hold-out set
2025-04-19 21:09:15,392:INFO:Saving 'Residuals.png'
2025-04-19 21:09:16,260:INFO:Visual Rendered Successfully
2025-04-19 21:09:16,400:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:16,700:INFO:Initializing plot_model()
2025-04-19 21:09:16,700:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:16,700:INFO:Checking exceptions
2025-04-19 21:09:16,700:INFO:Preloading libraries
2025-04-19 21:09:16,700:INFO:Copying training dataset
2025-04-19 21:09:16,700:INFO:Plot type: error
2025-04-19 21:09:16,987:INFO:Fitting Model
2025-04-19 21:09:16,987:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:16,987:INFO:Scoring test/hold-out set
2025-04-19 21:09:17,019:INFO:Saving 'Prediction Error.png'
2025-04-19 21:09:17,409:INFO:Visual Rendered Successfully
2025-04-19 21:09:17,533:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:17,819:INFO:Initializing plot_model()
2025-04-19 21:09:17,819:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                             lambda_1=0.0005, lambda_2=0.05)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:17,819:INFO:Checking exceptions
2025-04-19 21:09:17,821:INFO:Preloading libraries
2025-04-19 21:09:17,821:INFO:Copying training dataset
2025-04-19 21:09:17,821:INFO:Plot type: learning
2025-04-19 21:09:18,121:INFO:Fitting Model
2025-04-19 21:09:19,677:INFO:Saving 'Learning Curve.png'
2025-04-19 21:09:20,182:INFO:Visual Rendered Successfully
2025-04-19 21:09:20,370:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:20,741:INFO:Initializing save_model()
2025-04-19 21:09:20,741:INFO:save_model(model=HuberRegressor(), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:09:20,741:INFO:Adding model into prep_pipe
2025-04-19 21:09:20,799:INFO:models/model_3.pkl saved in current working directory
2025-04-19 21:09:20,811:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor())])
2025-04-19 21:09:20,811:INFO:save_model() successfully completed......................................
2025-04-19 21:09:21,256:INFO:Initializing plot_model()
2025-04-19 21:09:21,256:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:21,256:INFO:Checking exceptions
2025-04-19 21:09:21,256:INFO:Preloading libraries
2025-04-19 21:09:21,256:INFO:Copying training dataset
2025-04-19 21:09:21,256:INFO:Plot type: feature
2025-04-19 21:09:21,481:INFO:Saving 'Feature Importance.png'
2025-04-19 21:09:21,692:INFO:Visual Rendered Successfully
2025-04-19 21:09:21,846:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:22,196:INFO:Initializing plot_model()
2025-04-19 21:09:22,196:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:22,196:INFO:Checking exceptions
2025-04-19 21:09:22,198:INFO:Preloading libraries
2025-04-19 21:09:22,198:INFO:Copying training dataset
2025-04-19 21:09:22,198:INFO:Plot type: residuals
2025-04-19 21:09:22,692:INFO:Fitting Model
2025-04-19 21:09:22,692:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:22,743:INFO:Scoring test/hold-out set
2025-04-19 21:09:22,770:INFO:Saving 'Residuals.png'
2025-04-19 21:09:23,533:INFO:Visual Rendered Successfully
2025-04-19 21:09:23,664:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:23,928:INFO:Initializing plot_model()
2025-04-19 21:09:23,928:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:23,928:INFO:Checking exceptions
2025-04-19 21:09:23,930:INFO:Preloading libraries
2025-04-19 21:09:23,930:INFO:Copying training dataset
2025-04-19 21:09:23,930:INFO:Plot type: error
2025-04-19 21:09:24,221:INFO:Fitting Model
2025-04-19 21:09:24,221:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:09:24,221:INFO:Scoring test/hold-out set
2025-04-19 21:09:24,245:INFO:Saving 'Prediction Error.png'
2025-04-19 21:09:24,638:INFO:Visual Rendered Successfully
2025-04-19 21:09:24,765:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:25,044:INFO:Initializing plot_model()
2025-04-19 21:09:25,044:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:25,044:INFO:Checking exceptions
2025-04-19 21:09:25,046:INFO:Preloading libraries
2025-04-19 21:09:25,046:INFO:Copying training dataset
2025-04-19 21:09:25,046:INFO:Plot type: learning
2025-04-19 21:09:25,342:INFO:Fitting Model
2025-04-19 21:09:25,677:INFO:Saving 'Learning Curve.png'
2025-04-19 21:09:26,150:INFO:Visual Rendered Successfully
2025-04-19 21:09:26,293:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:26,580:INFO:Initializing save_model()
2025-04-19 21:09:26,580:INFO:save_model(model=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:09:26,580:INFO:Adding model into prep_pipe
2025-04-19 21:09:26,625:INFO:models/model_4.pkl saved in current working directory
2025-04-19 21:09:26,639:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005,
                               lambda_2=0.05))])
2025-04-19 21:09:26,639:INFO:save_model() successfully completed......................................
2025-04-19 21:09:26,972:INFO:Initializing plot_model()
2025-04-19 21:09:26,972:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:26,972:INFO:Checking exceptions
2025-04-19 21:09:26,974:INFO:Preloading libraries
2025-04-19 21:09:26,974:INFO:Copying training dataset
2025-04-19 21:09:26,974:INFO:Plot type: feature
2025-04-19 21:09:27,153:INFO:Saving 'Feature Importance.png'
2025-04-19 21:09:27,301:INFO:Visual Rendered Successfully
2025-04-19 21:09:27,406:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:27,681:INFO:Initializing plot_model()
2025-04-19 21:09:27,681:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:27,681:INFO:Checking exceptions
2025-04-19 21:09:27,681:INFO:Preloading libraries
2025-04-19 21:09:27,683:INFO:Copying training dataset
2025-04-19 21:09:27,683:INFO:Plot type: residuals
2025-04-19 21:09:27,990:INFO:Fitting Model
2025-04-19 21:09:27,990:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:09:28,017:INFO:Scoring test/hold-out set
2025-04-19 21:09:28,049:INFO:Saving 'Residuals.png'
2025-04-19 21:09:28,857:INFO:Visual Rendered Successfully
2025-04-19 21:09:28,974:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:29,256:INFO:Initializing plot_model()
2025-04-19 21:09:29,256:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:29,256:INFO:Checking exceptions
2025-04-19 21:09:29,258:INFO:Preloading libraries
2025-04-19 21:09:29,258:INFO:Copying training dataset
2025-04-19 21:09:29,258:INFO:Plot type: error
2025-04-19 21:09:29,537:INFO:Fitting Model
2025-04-19 21:09:29,537:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:09:29,537:INFO:Scoring test/hold-out set
2025-04-19 21:09:29,549:INFO:Saving 'Prediction Error.png'
2025-04-19 21:09:29,949:INFO:Visual Rendered Successfully
2025-04-19 21:09:30,063:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:30,338:INFO:Initializing plot_model()
2025-04-19 21:09:30,338:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.005, alpha_2=0.01, lambda_1=0.0005, lambda_2=0.05), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:30,338:INFO:Checking exceptions
2025-04-19 21:09:30,343:INFO:Preloading libraries
2025-04-19 21:09:30,343:INFO:Copying training dataset
2025-04-19 21:09:30,343:INFO:Plot type: learning
2025-04-19 21:09:30,628:INFO:Fitting Model
2025-04-19 21:09:30,885:INFO:Saving 'Learning Curve.png'
2025-04-19 21:09:31,252:INFO:Visual Rendered Successfully
2025-04-19 21:09:31,379:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:31,663:INFO:Initializing save_model()
2025-04-19 21:09:31,663:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:09:31,663:INFO:Adding model into prep_pipe
2025-04-19 21:09:31,712:INFO:models/model_5.pkl saved in current working directory
2025-04-19 21:09:31,723:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_19', 'feature_21',
                                             'feature_11', 'feature_55',
                                             'feature_49', 'feature_20',
                                             'fe...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 21:09:31,723:INFO:save_model() successfully completed......................................
2025-04-19 21:09:32,044:INFO:Initializing plot_model()
2025-04-19 21:09:32,044:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:32,044:INFO:Checking exceptions
2025-04-19 21:09:32,044:INFO:Preloading libraries
2025-04-19 21:09:32,044:INFO:Copying training dataset
2025-04-19 21:09:32,044:INFO:Plot type: feature
2025-04-19 21:09:32,220:INFO:Saving 'Feature Importance.png'
2025-04-19 21:09:32,404:INFO:Visual Rendered Successfully
2025-04-19 21:09:32,515:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:32,806:INFO:Initializing plot_model()
2025-04-19 21:09:32,806:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:32,806:INFO:Checking exceptions
2025-04-19 21:09:32,806:INFO:Preloading libraries
2025-04-19 21:09:32,806:INFO:Copying training dataset
2025-04-19 21:09:32,806:INFO:Plot type: residuals
2025-04-19 21:09:33,180:INFO:Fitting Model
2025-04-19 21:09:33,180:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:09:33,219:INFO:Scoring test/hold-out set
2025-04-19 21:09:33,263:INFO:Saving 'Residuals.png'
2025-04-19 21:09:34,080:INFO:Visual Rendered Successfully
2025-04-19 21:09:34,253:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:34,519:INFO:Initializing plot_model()
2025-04-19 21:09:34,526:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:34,526:INFO:Checking exceptions
2025-04-19 21:09:34,526:INFO:Preloading libraries
2025-04-19 21:09:34,526:INFO:Copying training dataset
2025-04-19 21:09:34,526:INFO:Plot type: error
2025-04-19 21:09:34,816:INFO:Fitting Model
2025-04-19 21:09:34,816:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:09:34,816:INFO:Scoring test/hold-out set
2025-04-19 21:09:34,842:INFO:Saving 'Prediction Error.png'
2025-04-19 21:09:35,256:INFO:Visual Rendered Successfully
2025-04-19 21:09:35,395:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:35,688:INFO:Initializing plot_model()
2025-04-19 21:09:35,692:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, system=True)
2025-04-19 21:09:35,692:INFO:Checking exceptions
2025-04-19 21:09:35,692:INFO:Preloading libraries
2025-04-19 21:09:35,692:INFO:Copying training dataset
2025-04-19 21:09:35,692:INFO:Plot type: learning
2025-04-19 21:09:36,006:INFO:Fitting Model
2025-04-19 21:09:36,262:INFO:Saving 'Learning Curve.png'
2025-04-19 21:09:36,768:INFO:Visual Rendered Successfully
2025-04-19 21:09:36,911:INFO:plot_model() successfully completed......................................
2025-04-19 21:09:37,275:INFO:Initializing predict_model()
2025-04-19 21:09:37,275:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000190A23A92A0>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.005, alpha_2=0.01,
                                           lambda_1=0.0005, lambda_2=0.05)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000190AC094430>)
2025-04-19 21:09:37,275:INFO:Checking exceptions
2025-04-19 21:09:37,275:INFO:Preloading libraries
2025-04-19 21:09:37,275:INFO:Set up data.
2025-04-19 21:09:37,275:INFO:Set up index.
2025-04-19 21:10:33,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:10:33,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:10:33,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:10:33,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:11:04,957:INFO:PyCaret RegressionExperiment
2025-04-19 21:11:04,957:INFO:Logging name: agn_modeling
2025-04-19 21:11:04,957:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 21:11:04,957:INFO:version 3.0.4
2025-04-19 21:11:04,957:INFO:Initializing setup()
2025-04-19 21:11:04,957:INFO:self.USI: 58df
2025-04-19 21:11:04,957:INFO:self._variable_keys: {'target_param', 'X_train', 'fold_generator', 'exp_name_log', 'y_test', 'exp_id', 'fold_groups_param', 'X_test', 'log_plots_param', 'seed', 'memory', '_available_plots', 'data', 'gpu_n_jobs_param', 'transform_target_param', 'n_jobs_param', 'y', 'logging_param', 'X', 'gpu_param', 'y_train', 'html_param', 'idx', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'USI'}
2025-04-19 21:11:04,957:INFO:Checking environment
2025-04-19 21:11:04,957:INFO:python_version: 3.10.9
2025-04-19 21:11:04,957:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 21:11:04,957:INFO:machine: AMD64
2025-04-19 21:11:04,964:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 21:11:04,975:INFO:Memory: svmem(total=16952647680, available=4238589952, percent=75.0, used=12714057728, free=4238589952)
2025-04-19 21:11:04,975:INFO:Physical Core: 4
2025-04-19 21:11:04,975:INFO:Logical Core: 8
2025-04-19 21:11:04,975:INFO:Checking libraries
2025-04-19 21:11:04,975:INFO:System:
2025-04-19 21:11:04,975:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 21:11:04,975:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 21:11:04,975:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 21:11:04,975:INFO:PyCaret required dependencies:
2025-04-19 21:11:05,684:INFO:                 pip: 25.0.1
2025-04-19 21:11:05,684:INFO:          setuptools: 65.5.0
2025-04-19 21:11:05,684:INFO:             pycaret: 3.0.4
2025-04-19 21:11:05,684:INFO:             IPython: 8.35.0
2025-04-19 21:11:05,684:INFO:          ipywidgets: 8.1.6
2025-04-19 21:11:05,684:INFO:                tqdm: 4.67.1
2025-04-19 21:11:05,684:INFO:               numpy: 1.23.5
2025-04-19 21:11:05,684:INFO:              pandas: 1.5.3
2025-04-19 21:11:05,684:INFO:              jinja2: 3.1.6
2025-04-19 21:11:05,684:INFO:               scipy: 1.11.4
2025-04-19 21:11:05,684:INFO:              joblib: 1.2.0
2025-04-19 21:11:05,684:INFO:             sklearn: 1.2.2
2025-04-19 21:11:05,684:INFO:                pyod: 2.0.4
2025-04-19 21:11:05,684:INFO:            imblearn: 0.12.4
2025-04-19 21:11:05,684:INFO:   category_encoders: 2.7.0
2025-04-19 21:11:05,684:INFO:            lightgbm: 4.6.0
2025-04-19 21:11:05,684:INFO:               numba: 0.58.1
2025-04-19 21:11:05,684:INFO:            requests: 2.32.3
2025-04-19 21:11:05,684:INFO:          matplotlib: 3.7.1
2025-04-19 21:11:05,684:INFO:          scikitplot: 0.3.7
2025-04-19 21:11:05,684:INFO:         yellowbrick: 1.5
2025-04-19 21:11:05,684:INFO:              plotly: 5.24.1
2025-04-19 21:11:05,684:INFO:    plotly-resampler: Not installed
2025-04-19 21:11:05,684:INFO:             kaleido: 0.2.1
2025-04-19 21:11:05,684:INFO:           schemdraw: 0.15
2025-04-19 21:11:05,684:INFO:         statsmodels: 0.14.4
2025-04-19 21:11:05,684:INFO:              sktime: 0.21.1
2025-04-19 21:11:05,684:INFO:               tbats: 1.1.3
2025-04-19 21:11:05,684:INFO:            pmdarima: 2.0.4
2025-04-19 21:11:05,684:INFO:              psutil: 7.0.0
2025-04-19 21:11:05,684:INFO:          markupsafe: 2.1.5
2025-04-19 21:11:05,684:INFO:             pickle5: Not installed
2025-04-19 21:11:05,684:INFO:         cloudpickle: 2.2.1
2025-04-19 21:11:05,684:INFO:         deprecation: 2.1.0
2025-04-19 21:11:05,684:INFO:              xxhash: 3.5.0
2025-04-19 21:11:05,684:INFO:           wurlitzer: Not installed
2025-04-19 21:11:05,684:INFO:PyCaret optional dependencies:
2025-04-19 21:11:06,596:INFO:                shap: 0.47.2
2025-04-19 21:11:06,596:INFO:           interpret: 0.6.6
2025-04-19 21:11:06,596:INFO:                umap: 0.5.7
2025-04-19 21:11:06,596:INFO:    pandas_profiling: 4.6.0
2025-04-19 21:11:06,596:INFO:  explainerdashboard: 0.4.8
2025-04-19 21:11:06,596:INFO:             autoviz: 0.1.902
2025-04-19 21:11:06,596:INFO:           fairlearn: 0.7.0
2025-04-19 21:11:06,596:INFO:          deepchecks: 0.19.1
2025-04-19 21:11:06,596:INFO:             xgboost: 1.6.2
2025-04-19 21:11:06,596:INFO:            catboost: 1.2.8
2025-04-19 21:11:06,596:INFO:              kmodes: 0.12.2
2025-04-19 21:11:06,596:INFO:             mlxtend: 0.23.1
2025-04-19 21:11:06,596:INFO:       statsforecast: 2.0.1
2025-04-19 21:11:06,596:INFO:        tune_sklearn: 0.5.0
2025-04-19 21:11:06,596:INFO:                 ray: 2.44.1
2025-04-19 21:11:06,596:INFO:            hyperopt: 0.2.7
2025-04-19 21:11:06,596:INFO:              optuna: 4.3.0
2025-04-19 21:11:06,596:INFO:               skopt: 0.10.2
2025-04-19 21:11:06,596:INFO:              mlflow: 2.21.3
2025-04-19 21:11:06,596:INFO:              gradio: 3.50.2
2025-04-19 21:11:06,596:INFO:             fastapi: 0.115.12
2025-04-19 21:11:06,596:INFO:             uvicorn: 0.34.2
2025-04-19 21:11:06,596:INFO:              m2cgen: 0.10.0
2025-04-19 21:11:06,596:INFO:           evidently: 0.2.8
2025-04-19 21:11:06,596:INFO:               fugue: 0.8.6
2025-04-19 21:11:06,596:INFO:           streamlit: Not installed
2025-04-19 21:11:06,596:INFO:             prophet: Not installed
2025-04-19 21:11:06,596:INFO:None
2025-04-19 21:11:06,596:INFO:Set up data.
2025-04-19 21:11:06,612:INFO:Set up train/test split.
2025-04-19 21:11:06,612:INFO:Set up index.
2025-04-19 21:11:06,612:INFO:Set up folding strategy.
2025-04-19 21:11:06,612:INFO:Assigning column types.
2025-04-19 21:11:06,612:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 21:11:06,612:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,612:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,707:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:06,755:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:06,785:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,785:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,785:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,879:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:06,880:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:06,880:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 21:11:06,886:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:06,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,000:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,002:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,010:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,101:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,103:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,105:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 21:11:07,112:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,207:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,211:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,339:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,343:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,343:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 21:11:07,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,441:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,441:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,546:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,555:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,555:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 21:11:07,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,644:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,644:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:11:07,746:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,748:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,750:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 21:11:07,833:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,833:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,929:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:07,929:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:07,929:INFO:Preparing preprocessing pipeline...
2025-04-19 21:11:07,929:INFO:Set up target transformation.
2025-04-19 21:11:07,929:INFO:Set up simple imputation.
2025-04-19 21:11:07,929:INFO:Set up removing multicollinearity.
2025-04-19 21:11:07,929:INFO:Set up removing outliers.
2025-04-19 21:11:07,929:INFO:Set up feature normalization.
2025-04-19 21:11:08,081:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:08,381:INFO:Finished creating preprocessing pipeline.
2025-04-19 21:11:08,381:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_55', 'feature_43',
                                             'feature_21', 'feature_19',
                                             'feature_8', 'feature_49',
                                             'fea...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 21:11:08,381:INFO:Creating final display dataframe.
2025-04-19 21:11:08,562:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:09,122:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape    (7999, 12)
4        Transformed data shape    (7719, 11)
5   Transformed train set shape    (5319, 11)
6    Transformed test set shape    (2400, 11)
7              Numeric features            11
8      Rows with missing values         20.3%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          58df
2025-04-19 21:11:09,230:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:09,238:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:09,326:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:11:09,326:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:11:09,326:INFO:setup() successfully completed in 4.62s...............
2025-04-19 21:11:09,326:INFO:Initializing compare_models()
2025-04-19 21:11:09,326:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B49EFFBA30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B49EFFBA30>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 21:11:09,326:INFO:Checking exceptions
2025-04-19 21:11:09,343:INFO:Preparing display monitor
2025-04-19 21:11:09,343:INFO:Initializing Linear Regression
2025-04-19 21:11:09,343:INFO:Total runtime is 0.0 minutes
2025-04-19 21:11:09,343:INFO:SubProcess create_model() called ==================================
2025-04-19 21:11:09,343:INFO:Initializing create_model()
2025-04-19 21:11:09,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B49EFFBA30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4A025F3A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:11:09,343:INFO:Checking exceptions
2025-04-19 21:11:09,343:INFO:Importing libraries
2025-04-19 21:11:09,343:INFO:Copying training dataset
2025-04-19 21:11:09,343:INFO:Defining folds
2025-04-19 21:11:09,343:INFO:Declaring metric variables
2025-04-19 21:11:09,343:INFO:Importing untrained model
2025-04-19 21:11:09,343:INFO:Linear Regression Imported successfully
2025-04-19 21:11:09,343:INFO:Starting cross validation
2025-04-19 21:11:09,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:11:16,355:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,376:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,395:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,419:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,438:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,549:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,689:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:16,797:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:17,927:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:17,939:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:11:20,303:WARNING:Exception ignored in: <function Image.__del__ at 0x000001B496B8AD40>
2025-04-19 21:11:20,303:WARNING:Traceback (most recent call last):
2025-04-19 21:11:20,303:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 4056, in __del__
2025-04-19 21:11:20,307:WARNING:    self.tk.call('image', 'delete', self.name)
2025-04-19 21:11:20,307:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:21,410:WARNING:Exception ignored in: <function Image.__del__ at 0x000001B496B8AD40>
2025-04-19 21:11:21,410:WARNING:Traceback (most recent call last):
2025-04-19 21:11:21,410:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 4056, in __del__
2025-04-19 21:11:21,410:WARNING:    self.tk.call('image', 'delete', self.name)
2025-04-19 21:11:21,410:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:22,525:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:22,526:WARNING:Traceback (most recent call last):
2025-04-19 21:11:22,526:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:22,526:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:22,526:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:24,731:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:24,731:WARNING:Traceback (most recent call last):
2025-04-19 21:11:24,731:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:24,731:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:24,731:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:25,834:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:25,834:WARNING:Traceback (most recent call last):
2025-04-19 21:11:25,834:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:25,834:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:25,834:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:28,065:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:28,065:WARNING:Traceback (most recent call last):
2025-04-19 21:11:28,065:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:28,066:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:28,066:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:35,771:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:35,771:WARNING:Traceback (most recent call last):
2025-04-19 21:11:35,771:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:35,771:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:35,772:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:39,042:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:39,042:WARNING:Traceback (most recent call last):
2025-04-19 21:11:39,042:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:39,044:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:39,044:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:53,426:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:53,426:WARNING:Traceback (most recent call last):
2025-04-19 21:11:53,426:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:53,426:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:53,426:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:11:56,770:WARNING:Exception ignored in: <function Variable.__del__ at 0x000001B496AFF5B0>
2025-04-19 21:11:56,770:WARNING:Traceback (most recent call last):
2025-04-19 21:11:56,770:WARNING:  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python310\lib\tkinter\__init__.py", line 388, in __del__
2025-04-19 21:11:56,771:WARNING:    if self._tk.getboolean(self._tk.call("info", "exists", self._name)):
2025-04-19 21:11:56,771:WARNING:RuntimeError: main thread is not in main loop
2025-04-19 21:12:35,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:12:35,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:12:35,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:12:35,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:13:14,207:INFO:PyCaret RegressionExperiment
2025-04-19 21:13:14,207:INFO:Logging name: agn_modeling
2025-04-19 21:13:14,207:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-19 21:13:14,207:INFO:version 3.0.4
2025-04-19 21:13:14,207:INFO:Initializing setup()
2025-04-19 21:13:14,207:INFO:self.USI: 5de3
2025-04-19 21:13:14,207:INFO:self._variable_keys: {'data', 'fold_generator', 'exp_id', 'X_test', 'pipeline', 'X', 'log_plots_param', 'fold_groups_param', 'transform_target_param', 'memory', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', '_ml_usecase', 'y_test', 'n_jobs_param', 'idx', 'y_train', 'USI', 'html_param', 'target_param', 'logging_param', 'fold_shuffle_param', 'seed', 'gpu_param', 'y', '_available_plots'}
2025-04-19 21:13:14,207:INFO:Checking environment
2025-04-19 21:13:14,207:INFO:python_version: 3.10.9
2025-04-19 21:13:14,207:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 21:13:14,207:INFO:machine: AMD64
2025-04-19 21:13:14,220:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 21:13:14,227:INFO:Memory: svmem(total=16952647680, available=2740379648, percent=83.8, used=14212268032, free=2740379648)
2025-04-19 21:13:14,227:INFO:Physical Core: 4
2025-04-19 21:13:14,227:INFO:Logical Core: 8
2025-04-19 21:13:14,227:INFO:Checking libraries
2025-04-19 21:13:14,227:INFO:System:
2025-04-19 21:13:14,227:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 21:13:14,227:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 21:13:14,227:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 21:13:14,227:INFO:PyCaret required dependencies:
2025-04-19 21:13:15,033:INFO:                 pip: 25.0.1
2025-04-19 21:13:15,033:INFO:          setuptools: 65.5.0
2025-04-19 21:13:15,033:INFO:             pycaret: 3.0.4
2025-04-19 21:13:15,033:INFO:             IPython: 8.35.0
2025-04-19 21:13:15,033:INFO:          ipywidgets: 8.1.6
2025-04-19 21:13:15,033:INFO:                tqdm: 4.67.1
2025-04-19 21:13:15,033:INFO:               numpy: 1.23.5
2025-04-19 21:13:15,033:INFO:              pandas: 1.5.3
2025-04-19 21:13:15,033:INFO:              jinja2: 3.1.6
2025-04-19 21:13:15,033:INFO:               scipy: 1.11.4
2025-04-19 21:13:15,033:INFO:              joblib: 1.2.0
2025-04-19 21:13:15,033:INFO:             sklearn: 1.2.2
2025-04-19 21:13:15,033:INFO:                pyod: 2.0.4
2025-04-19 21:13:15,033:INFO:            imblearn: 0.12.4
2025-04-19 21:13:15,033:INFO:   category_encoders: 2.7.0
2025-04-19 21:13:15,033:INFO:            lightgbm: 4.6.0
2025-04-19 21:13:15,033:INFO:               numba: 0.58.1
2025-04-19 21:13:15,033:INFO:            requests: 2.32.3
2025-04-19 21:13:15,033:INFO:          matplotlib: 3.7.1
2025-04-19 21:13:15,033:INFO:          scikitplot: 0.3.7
2025-04-19 21:13:15,033:INFO:         yellowbrick: 1.5
2025-04-19 21:13:15,033:INFO:              plotly: 5.24.1
2025-04-19 21:13:15,033:INFO:    plotly-resampler: Not installed
2025-04-19 21:13:15,033:INFO:             kaleido: 0.2.1
2025-04-19 21:13:15,033:INFO:           schemdraw: 0.15
2025-04-19 21:13:15,033:INFO:         statsmodels: 0.14.4
2025-04-19 21:13:15,033:INFO:              sktime: 0.21.1
2025-04-19 21:13:15,033:INFO:               tbats: 1.1.3
2025-04-19 21:13:15,033:INFO:            pmdarima: 2.0.4
2025-04-19 21:13:15,033:INFO:              psutil: 7.0.0
2025-04-19 21:13:15,033:INFO:          markupsafe: 2.1.5
2025-04-19 21:13:15,033:INFO:             pickle5: Not installed
2025-04-19 21:13:15,033:INFO:         cloudpickle: 2.2.1
2025-04-19 21:13:15,033:INFO:         deprecation: 2.1.0
2025-04-19 21:13:15,033:INFO:              xxhash: 3.5.0
2025-04-19 21:13:15,033:INFO:           wurlitzer: Not installed
2025-04-19 21:13:15,033:INFO:PyCaret optional dependencies:
2025-04-19 21:13:16,492:INFO:                shap: 0.47.2
2025-04-19 21:13:16,492:INFO:           interpret: 0.6.6
2025-04-19 21:13:16,492:INFO:                umap: 0.5.7
2025-04-19 21:13:16,492:INFO:    pandas_profiling: 4.6.0
2025-04-19 21:13:16,492:INFO:  explainerdashboard: 0.4.8
2025-04-19 21:13:16,492:INFO:             autoviz: 0.1.902
2025-04-19 21:13:16,492:INFO:           fairlearn: 0.7.0
2025-04-19 21:13:16,492:INFO:          deepchecks: 0.19.1
2025-04-19 21:13:16,492:INFO:             xgboost: 1.6.2
2025-04-19 21:13:16,492:INFO:            catboost: 1.2.8
2025-04-19 21:13:16,492:INFO:              kmodes: 0.12.2
2025-04-19 21:13:16,492:INFO:             mlxtend: 0.23.1
2025-04-19 21:13:16,492:INFO:       statsforecast: 2.0.1
2025-04-19 21:13:16,492:INFO:        tune_sklearn: 0.5.0
2025-04-19 21:13:16,492:INFO:                 ray: 2.44.1
2025-04-19 21:13:16,492:INFO:            hyperopt: 0.2.7
2025-04-19 21:13:16,492:INFO:              optuna: 4.3.0
2025-04-19 21:13:16,492:INFO:               skopt: 0.10.2
2025-04-19 21:13:16,492:INFO:              mlflow: 2.21.3
2025-04-19 21:13:16,492:INFO:              gradio: 3.50.2
2025-04-19 21:13:16,492:INFO:             fastapi: 0.115.12
2025-04-19 21:13:16,492:INFO:             uvicorn: 0.34.2
2025-04-19 21:13:16,492:INFO:              m2cgen: 0.10.0
2025-04-19 21:13:16,492:INFO:           evidently: 0.2.8
2025-04-19 21:13:16,492:INFO:               fugue: 0.8.6
2025-04-19 21:13:16,492:INFO:           streamlit: Not installed
2025-04-19 21:13:16,492:INFO:             prophet: Not installed
2025-04-19 21:13:16,492:INFO:None
2025-04-19 21:13:16,492:INFO:Set up data.
2025-04-19 21:13:16,501:INFO:Set up train/test split.
2025-04-19 21:13:16,507:INFO:Set up index.
2025-04-19 21:13:16,507:INFO:Set up folding strategy.
2025-04-19 21:13:16,507:INFO:Assigning column types.
2025-04-19 21:13:16,511:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 21:13:16,511:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,511:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,633:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:16,663:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:16,692:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,807:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:16,809:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:16,809:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-19 21:13:16,811:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,818:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,911:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:16,911:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:16,918:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-19 21:13:16,957:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,074:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,074:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,074:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-19 21:13:17,091:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,188:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,188:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,286:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,299:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,299:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-19 21:13:17,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,402:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,406:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,513:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,513:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,513:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 21:13:17,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,626:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,633:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-19 21:13:17,745:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,747:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,747:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-19 21:13:17,852:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,852:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,970:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:17,970:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:17,970:INFO:Preparing preprocessing pipeline...
2025-04-19 21:13:17,970:INFO:Set up target transformation.
2025-04-19 21:13:17,970:INFO:Set up simple imputation.
2025-04-19 21:13:17,970:INFO:Set up removing multicollinearity.
2025-04-19 21:13:17,970:INFO:Set up removing outliers.
2025-04-19 21:13:17,970:INFO:Set up feature normalization.
2025-04-19 21:13:18,169:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:18,536:INFO:Finished creating preprocessing pipeline.
2025-04-19 21:13:18,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-04-19 21:13:18,545:INFO:Creating final display dataframe.
2025-04-19 21:13:18,782:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:19,466:INFO:Setup _display_container:                     Description         Value
0                    Session id            42
1                        Target        target
2                   Target type    Regression
3           Original data shape    (7999, 12)
4        Transformed data shape    (7719, 11)
5   Transformed train set shape    (5319, 11)
6    Transformed test set shape    (2400, 11)
7              Numeric features            11
8      Rows with missing values         20.3%
9                    Preprocess          True
10              Imputation type        simple
11           Numeric imputation          mean
12       Categorical imputation          mode
13     Remove multicollinearity          True
14  Multicollinearity threshold           0.9
15              Remove outliers          True
16           Outliers threshold          0.05
17                    Normalize          True
18             Normalize method        zscore
19             Transform target          True
20      Transform target method   yeo-johnson
21               Fold Generator         KFold
22                  Fold Number            10
23                     CPU Jobs            -1
24                      Use GPU         False
25               Log Experiment         False
26              Experiment Name  agn_modeling
27                          USI          5de3
2025-04-19 21:13:19,587:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:19,599:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:19,701:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:13:19,701:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:13:19,714:INFO:setup() successfully completed in 5.76s...............
2025-04-19 21:13:19,714:INFO:Initializing compare_models()
2025-04-19 21:13:19,714:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2025-04-19 21:13:19,714:INFO:Checking exceptions
2025-04-19 21:13:19,716:INFO:Preparing display monitor
2025-04-19 21:13:19,722:INFO:Initializing Linear Regression
2025-04-19 21:13:19,722:INFO:Total runtime is 0.0 minutes
2025-04-19 21:13:19,722:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:19,722:INFO:Initializing create_model()
2025-04-19 21:13:19,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:19,722:INFO:Checking exceptions
2025-04-19 21:13:19,722:INFO:Importing libraries
2025-04-19 21:13:19,722:INFO:Copying training dataset
2025-04-19 21:13:19,725:INFO:Defining folds
2025-04-19 21:13:19,725:INFO:Declaring metric variables
2025-04-19 21:13:19,725:INFO:Importing untrained model
2025-04-19 21:13:19,725:INFO:Linear Regression Imported successfully
2025-04-19 21:13:19,725:INFO:Starting cross validation
2025-04-19 21:13:19,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:27,191:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,203:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,230:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,272:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,293:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,337:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,442:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:27,606:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:28,678:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:28,712:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:13:30,489:INFO:Calculating mean and std
2025-04-19 21:13:30,489:INFO:Creating metrics dataframe
2025-04-19 21:13:30,866:INFO:Uploading results into container
2025-04-19 21:13:30,866:INFO:Uploading model into container now
2025-04-19 21:13:30,866:INFO:_master_model_container: 1
2025-04-19 21:13:30,866:INFO:_display_container: 2
2025-04-19 21:13:30,866:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:13:30,866:INFO:create_model() successfully completed......................................
2025-04-19 21:13:31,102:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:31,102:INFO:Creating metrics dataframe
2025-04-19 21:13:31,111:INFO:Initializing Lasso Regression
2025-04-19 21:13:31,111:INFO:Total runtime is 0.18981490929921468 minutes
2025-04-19 21:13:31,111:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:31,111:INFO:Initializing create_model()
2025-04-19 21:13:31,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:31,111:INFO:Checking exceptions
2025-04-19 21:13:31,111:INFO:Importing libraries
2025-04-19 21:13:31,111:INFO:Copying training dataset
2025-04-19 21:13:31,117:INFO:Defining folds
2025-04-19 21:13:31,118:INFO:Declaring metric variables
2025-04-19 21:13:31,118:INFO:Importing untrained model
2025-04-19 21:13:31,118:INFO:Lasso Regression Imported successfully
2025-04-19 21:13:31,118:INFO:Starting cross validation
2025-04-19 21:13:31,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:33,815:INFO:Calculating mean and std
2025-04-19 21:13:33,815:INFO:Creating metrics dataframe
2025-04-19 21:13:34,204:INFO:Uploading results into container
2025-04-19 21:13:34,204:INFO:Uploading model into container now
2025-04-19 21:13:34,204:INFO:_master_model_container: 2
2025-04-19 21:13:34,204:INFO:_display_container: 2
2025-04-19 21:13:34,204:INFO:Lasso(random_state=42)
2025-04-19 21:13:34,204:INFO:create_model() successfully completed......................................
2025-04-19 21:13:34,320:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:34,320:INFO:Creating metrics dataframe
2025-04-19 21:13:34,329:INFO:Initializing Ridge Regression
2025-04-19 21:13:34,329:INFO:Total runtime is 0.24344178040822348 minutes
2025-04-19 21:13:34,329:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:34,329:INFO:Initializing create_model()
2025-04-19 21:13:34,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:34,329:INFO:Checking exceptions
2025-04-19 21:13:34,329:INFO:Importing libraries
2025-04-19 21:13:34,329:INFO:Copying training dataset
2025-04-19 21:13:34,329:INFO:Defining folds
2025-04-19 21:13:34,329:INFO:Declaring metric variables
2025-04-19 21:13:34,329:INFO:Importing untrained model
2025-04-19 21:13:34,335:INFO:Ridge Regression Imported successfully
2025-04-19 21:13:34,335:INFO:Starting cross validation
2025-04-19 21:13:34,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:36,993:INFO:Calculating mean and std
2025-04-19 21:13:36,993:INFO:Creating metrics dataframe
2025-04-19 21:13:37,383:INFO:Uploading results into container
2025-04-19 21:13:37,384:INFO:Uploading model into container now
2025-04-19 21:13:37,384:INFO:_master_model_container: 3
2025-04-19 21:13:37,384:INFO:_display_container: 2
2025-04-19 21:13:37,384:INFO:Ridge(random_state=42)
2025-04-19 21:13:37,384:INFO:create_model() successfully completed......................................
2025-04-19 21:13:37,509:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:37,509:INFO:Creating metrics dataframe
2025-04-19 21:13:37,516:INFO:Initializing Elastic Net
2025-04-19 21:13:37,517:INFO:Total runtime is 0.29656031529108684 minutes
2025-04-19 21:13:37,517:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:37,517:INFO:Initializing create_model()
2025-04-19 21:13:37,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:37,517:INFO:Checking exceptions
2025-04-19 21:13:37,517:INFO:Importing libraries
2025-04-19 21:13:37,517:INFO:Copying training dataset
2025-04-19 21:13:37,523:INFO:Defining folds
2025-04-19 21:13:37,523:INFO:Declaring metric variables
2025-04-19 21:13:37,523:INFO:Importing untrained model
2025-04-19 21:13:37,523:INFO:Elastic Net Imported successfully
2025-04-19 21:13:37,523:INFO:Starting cross validation
2025-04-19 21:13:37,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:40,412:INFO:Calculating mean and std
2025-04-19 21:13:40,412:INFO:Creating metrics dataframe
2025-04-19 21:13:40,957:INFO:Uploading results into container
2025-04-19 21:13:40,965:INFO:Uploading model into container now
2025-04-19 21:13:40,965:INFO:_master_model_container: 4
2025-04-19 21:13:40,965:INFO:_display_container: 2
2025-04-19 21:13:40,965:INFO:ElasticNet(random_state=42)
2025-04-19 21:13:40,965:INFO:create_model() successfully completed......................................
2025-04-19 21:13:41,068:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:41,068:INFO:Creating metrics dataframe
2025-04-19 21:13:41,083:INFO:Initializing Least Angle Regression
2025-04-19 21:13:41,083:INFO:Total runtime is 0.3560152689615885 minutes
2025-04-19 21:13:41,083:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:41,083:INFO:Initializing create_model()
2025-04-19 21:13:41,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:41,083:INFO:Checking exceptions
2025-04-19 21:13:41,083:INFO:Importing libraries
2025-04-19 21:13:41,083:INFO:Copying training dataset
2025-04-19 21:13:41,083:INFO:Defining folds
2025-04-19 21:13:41,083:INFO:Declaring metric variables
2025-04-19 21:13:41,083:INFO:Importing untrained model
2025-04-19 21:13:41,083:INFO:Least Angle Regression Imported successfully
2025-04-19 21:13:41,083:INFO:Starting cross validation
2025-04-19 21:13:41,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:44,301:INFO:Calculating mean and std
2025-04-19 21:13:44,302:INFO:Creating metrics dataframe
2025-04-19 21:13:44,769:INFO:Uploading results into container
2025-04-19 21:13:44,774:INFO:Uploading model into container now
2025-04-19 21:13:44,775:INFO:_master_model_container: 5
2025-04-19 21:13:44,775:INFO:_display_container: 2
2025-04-19 21:13:44,775:INFO:Lars(random_state=42)
2025-04-19 21:13:44,776:INFO:create_model() successfully completed......................................
2025-04-19 21:13:44,894:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:44,894:INFO:Creating metrics dataframe
2025-04-19 21:13:44,903:INFO:Initializing Lasso Least Angle Regression
2025-04-19 21:13:44,903:INFO:Total runtime is 0.41967914501825965 minutes
2025-04-19 21:13:44,903:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:44,904:INFO:Initializing create_model()
2025-04-19 21:13:44,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:44,904:INFO:Checking exceptions
2025-04-19 21:13:44,904:INFO:Importing libraries
2025-04-19 21:13:44,904:INFO:Copying training dataset
2025-04-19 21:13:44,910:INFO:Defining folds
2025-04-19 21:13:44,910:INFO:Declaring metric variables
2025-04-19 21:13:44,910:INFO:Importing untrained model
2025-04-19 21:13:44,910:INFO:Lasso Least Angle Regression Imported successfully
2025-04-19 21:13:44,911:INFO:Starting cross validation
2025-04-19 21:13:44,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:47,845:INFO:Calculating mean and std
2025-04-19 21:13:47,846:INFO:Creating metrics dataframe
2025-04-19 21:13:48,248:INFO:Uploading results into container
2025-04-19 21:13:48,251:INFO:Uploading model into container now
2025-04-19 21:13:48,252:INFO:_master_model_container: 6
2025-04-19 21:13:48,252:INFO:_display_container: 2
2025-04-19 21:13:48,252:INFO:LassoLars(random_state=42)
2025-04-19 21:13:48,252:INFO:create_model() successfully completed......................................
2025-04-19 21:13:48,395:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:48,395:INFO:Creating metrics dataframe
2025-04-19 21:13:48,402:INFO:Initializing Orthogonal Matching Pursuit
2025-04-19 21:13:48,403:INFO:Total runtime is 0.47800908486048377 minutes
2025-04-19 21:13:48,403:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:48,404:INFO:Initializing create_model()
2025-04-19 21:13:48,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:48,404:INFO:Checking exceptions
2025-04-19 21:13:48,404:INFO:Importing libraries
2025-04-19 21:13:48,404:INFO:Copying training dataset
2025-04-19 21:13:48,410:INFO:Defining folds
2025-04-19 21:13:48,410:INFO:Declaring metric variables
2025-04-19 21:13:48,410:INFO:Importing untrained model
2025-04-19 21:13:48,411:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-19 21:13:48,411:INFO:Starting cross validation
2025-04-19 21:13:48,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:51,886:INFO:Calculating mean and std
2025-04-19 21:13:51,888:INFO:Creating metrics dataframe
2025-04-19 21:13:52,285:INFO:Uploading results into container
2025-04-19 21:13:52,285:INFO:Uploading model into container now
2025-04-19 21:13:52,285:INFO:_master_model_container: 7
2025-04-19 21:13:52,285:INFO:_display_container: 2
2025-04-19 21:13:52,285:INFO:OrthogonalMatchingPursuit()
2025-04-19 21:13:52,285:INFO:create_model() successfully completed......................................
2025-04-19 21:13:52,402:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:52,402:INFO:Creating metrics dataframe
2025-04-19 21:13:52,406:INFO:Initializing Bayesian Ridge
2025-04-19 21:13:52,406:INFO:Total runtime is 0.5447282115618387 minutes
2025-04-19 21:13:52,406:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:52,406:INFO:Initializing create_model()
2025-04-19 21:13:52,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:52,406:INFO:Checking exceptions
2025-04-19 21:13:52,406:INFO:Importing libraries
2025-04-19 21:13:52,406:INFO:Copying training dataset
2025-04-19 21:13:52,409:INFO:Defining folds
2025-04-19 21:13:52,409:INFO:Declaring metric variables
2025-04-19 21:13:52,409:INFO:Importing untrained model
2025-04-19 21:13:52,409:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:13:52,409:INFO:Starting cross validation
2025-04-19 21:13:52,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:55,416:INFO:Calculating mean and std
2025-04-19 21:13:55,416:INFO:Creating metrics dataframe
2025-04-19 21:13:55,847:INFO:Uploading results into container
2025-04-19 21:13:55,847:INFO:Uploading model into container now
2025-04-19 21:13:55,847:INFO:_master_model_container: 8
2025-04-19 21:13:55,847:INFO:_display_container: 2
2025-04-19 21:13:55,847:INFO:BayesianRidge()
2025-04-19 21:13:55,847:INFO:create_model() successfully completed......................................
2025-04-19 21:13:55,987:INFO:SubProcess create_model() end ==================================
2025-04-19 21:13:55,987:INFO:Creating metrics dataframe
2025-04-19 21:13:56,000:INFO:Initializing Passive Aggressive Regressor
2025-04-19 21:13:56,000:INFO:Total runtime is 0.6046225070953368 minutes
2025-04-19 21:13:56,003:INFO:SubProcess create_model() called ==================================
2025-04-19 21:13:56,003:INFO:Initializing create_model()
2025-04-19 21:13:56,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:13:56,003:INFO:Checking exceptions
2025-04-19 21:13:56,003:INFO:Importing libraries
2025-04-19 21:13:56,003:INFO:Copying training dataset
2025-04-19 21:13:56,003:INFO:Defining folds
2025-04-19 21:13:56,003:INFO:Declaring metric variables
2025-04-19 21:13:56,003:INFO:Importing untrained model
2025-04-19 21:13:56,003:INFO:Passive Aggressive Regressor Imported successfully
2025-04-19 21:13:56,003:INFO:Starting cross validation
2025-04-19 21:13:56,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:13:59,701:INFO:Calculating mean and std
2025-04-19 21:13:59,701:INFO:Creating metrics dataframe
2025-04-19 21:14:00,153:INFO:Uploading results into container
2025-04-19 21:14:00,153:INFO:Uploading model into container now
2025-04-19 21:14:00,153:INFO:_master_model_container: 9
2025-04-19 21:14:00,153:INFO:_display_container: 2
2025-04-19 21:14:00,153:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-19 21:14:00,153:INFO:create_model() successfully completed......................................
2025-04-19 21:14:00,309:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:00,311:INFO:Creating metrics dataframe
2025-04-19 21:14:00,317:INFO:Initializing Huber Regressor
2025-04-19 21:14:00,317:INFO:Total runtime is 0.6765837947527567 minutes
2025-04-19 21:14:00,318:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:00,318:INFO:Initializing create_model()
2025-04-19 21:14:00,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:00,318:INFO:Checking exceptions
2025-04-19 21:14:00,318:INFO:Importing libraries
2025-04-19 21:14:00,318:INFO:Copying training dataset
2025-04-19 21:14:00,324:INFO:Defining folds
2025-04-19 21:14:00,324:INFO:Declaring metric variables
2025-04-19 21:14:00,324:INFO:Importing untrained model
2025-04-19 21:14:00,324:INFO:Huber Regressor Imported successfully
2025-04-19 21:14:00,324:INFO:Starting cross validation
2025-04-19 21:14:00,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:04,519:INFO:Calculating mean and std
2025-04-19 21:14:04,519:INFO:Creating metrics dataframe
2025-04-19 21:14:05,019:INFO:Uploading results into container
2025-04-19 21:14:05,019:INFO:Uploading model into container now
2025-04-19 21:14:05,019:INFO:_master_model_container: 10
2025-04-19 21:14:05,019:INFO:_display_container: 2
2025-04-19 21:14:05,019:INFO:HuberRegressor()
2025-04-19 21:14:05,019:INFO:create_model() successfully completed......................................
2025-04-19 21:14:05,182:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:05,182:INFO:Creating metrics dataframe
2025-04-19 21:14:05,190:INFO:Initializing K Neighbors Regressor
2025-04-19 21:14:05,190:INFO:Total runtime is 0.7578019618988037 minutes
2025-04-19 21:14:05,190:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:05,190:INFO:Initializing create_model()
2025-04-19 21:14:05,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:05,190:INFO:Checking exceptions
2025-04-19 21:14:05,190:INFO:Importing libraries
2025-04-19 21:14:05,190:INFO:Copying training dataset
2025-04-19 21:14:05,195:INFO:Defining folds
2025-04-19 21:14:05,195:INFO:Declaring metric variables
2025-04-19 21:14:05,195:INFO:Importing untrained model
2025-04-19 21:14:05,201:INFO:K Neighbors Regressor Imported successfully
2025-04-19 21:14:05,202:INFO:Starting cross validation
2025-04-19 21:14:05,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:09,352:INFO:Calculating mean and std
2025-04-19 21:14:09,352:INFO:Creating metrics dataframe
2025-04-19 21:14:09,818:INFO:Uploading results into container
2025-04-19 21:14:09,818:INFO:Uploading model into container now
2025-04-19 21:14:09,818:INFO:_master_model_container: 11
2025-04-19 21:14:09,818:INFO:_display_container: 2
2025-04-19 21:14:09,818:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-19 21:14:09,818:INFO:create_model() successfully completed......................................
2025-04-19 21:14:09,941:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:09,941:INFO:Creating metrics dataframe
2025-04-19 21:14:09,941:INFO:Initializing Decision Tree Regressor
2025-04-19 21:14:09,941:INFO:Total runtime is 0.8369801481564839 minutes
2025-04-19 21:14:09,941:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:09,941:INFO:Initializing create_model()
2025-04-19 21:14:09,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:09,941:INFO:Checking exceptions
2025-04-19 21:14:09,941:INFO:Importing libraries
2025-04-19 21:14:09,941:INFO:Copying training dataset
2025-04-19 21:14:09,954:INFO:Defining folds
2025-04-19 21:14:09,954:INFO:Declaring metric variables
2025-04-19 21:14:09,954:INFO:Importing untrained model
2025-04-19 21:14:09,954:INFO:Decision Tree Regressor Imported successfully
2025-04-19 21:14:09,954:INFO:Starting cross validation
2025-04-19 21:14:09,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:13,407:INFO:Calculating mean and std
2025-04-19 21:14:13,411:INFO:Creating metrics dataframe
2025-04-19 21:14:13,868:INFO:Uploading results into container
2025-04-19 21:14:13,868:INFO:Uploading model into container now
2025-04-19 21:14:13,868:INFO:_master_model_container: 12
2025-04-19 21:14:13,868:INFO:_display_container: 2
2025-04-19 21:14:13,868:INFO:DecisionTreeRegressor(random_state=42)
2025-04-19 21:14:13,868:INFO:create_model() successfully completed......................................
2025-04-19 21:14:14,015:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:14,015:INFO:Creating metrics dataframe
2025-04-19 21:14:14,022:INFO:Initializing Random Forest Regressor
2025-04-19 21:14:14,022:INFO:Total runtime is 0.9050012509028116 minutes
2025-04-19 21:14:14,022:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:14,022:INFO:Initializing create_model()
2025-04-19 21:14:14,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:14,022:INFO:Checking exceptions
2025-04-19 21:14:14,022:INFO:Importing libraries
2025-04-19 21:14:14,022:INFO:Copying training dataset
2025-04-19 21:14:14,026:INFO:Defining folds
2025-04-19 21:14:14,028:INFO:Declaring metric variables
2025-04-19 21:14:14,028:INFO:Importing untrained model
2025-04-19 21:14:14,028:INFO:Random Forest Regressor Imported successfully
2025-04-19 21:14:14,029:INFO:Starting cross validation
2025-04-19 21:14:14,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:24,006:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,278:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,309:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,436:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,714:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,863:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:24,902:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:14:25,358:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:14:31,793:INFO:Calculating mean and std
2025-04-19 21:14:31,795:INFO:Creating metrics dataframe
2025-04-19 21:14:32,374:INFO:Uploading results into container
2025-04-19 21:14:32,374:INFO:Uploading model into container now
2025-04-19 21:14:32,374:INFO:_master_model_container: 13
2025-04-19 21:14:32,374:INFO:_display_container: 2
2025-04-19 21:14:32,374:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:14:32,374:INFO:create_model() successfully completed......................................
2025-04-19 21:14:32,537:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:32,537:INFO:Creating metrics dataframe
2025-04-19 21:14:32,553:INFO:Initializing Extra Trees Regressor
2025-04-19 21:14:32,553:INFO:Total runtime is 1.2138402462005615 minutes
2025-04-19 21:14:32,553:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:32,555:INFO:Initializing create_model()
2025-04-19 21:14:32,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:32,555:INFO:Checking exceptions
2025-04-19 21:14:32,555:INFO:Importing libraries
2025-04-19 21:14:32,555:INFO:Copying training dataset
2025-04-19 21:14:32,559:INFO:Defining folds
2025-04-19 21:14:32,559:INFO:Declaring metric variables
2025-04-19 21:14:32,559:INFO:Importing untrained model
2025-04-19 21:14:32,559:INFO:Extra Trees Regressor Imported successfully
2025-04-19 21:14:32,559:INFO:Starting cross validation
2025-04-19 21:14:32,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:35,702:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:35,776:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:36,060:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:14:41,245:INFO:Calculating mean and std
2025-04-19 21:14:41,245:INFO:Creating metrics dataframe
2025-04-19 21:14:41,793:INFO:Uploading results into container
2025-04-19 21:14:41,793:INFO:Uploading model into container now
2025-04-19 21:14:41,793:INFO:_master_model_container: 14
2025-04-19 21:14:41,793:INFO:_display_container: 2
2025-04-19 21:14:41,793:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:14:41,793:INFO:create_model() successfully completed......................................
2025-04-19 21:14:41,936:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:41,936:INFO:Creating metrics dataframe
2025-04-19 21:14:41,942:INFO:Initializing AdaBoost Regressor
2025-04-19 21:14:41,942:INFO:Total runtime is 1.3703348835309346 minutes
2025-04-19 21:14:41,947:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:41,947:INFO:Initializing create_model()
2025-04-19 21:14:41,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:41,947:INFO:Checking exceptions
2025-04-19 21:14:41,947:INFO:Importing libraries
2025-04-19 21:14:41,947:INFO:Copying training dataset
2025-04-19 21:14:41,952:INFO:Defining folds
2025-04-19 21:14:41,952:INFO:Declaring metric variables
2025-04-19 21:14:41,955:INFO:Importing untrained model
2025-04-19 21:14:41,955:INFO:AdaBoost Regressor Imported successfully
2025-04-19 21:14:41,955:INFO:Starting cross validation
2025-04-19 21:14:41,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:46,468:INFO:Calculating mean and std
2025-04-19 21:14:46,470:INFO:Creating metrics dataframe
2025-04-19 21:14:47,117:INFO:Uploading results into container
2025-04-19 21:14:47,117:INFO:Uploading model into container now
2025-04-19 21:14:47,117:INFO:_master_model_container: 15
2025-04-19 21:14:47,117:INFO:_display_container: 2
2025-04-19 21:14:47,117:INFO:AdaBoostRegressor(random_state=42)
2025-04-19 21:14:47,117:INFO:create_model() successfully completed......................................
2025-04-19 21:14:47,277:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:47,277:INFO:Creating metrics dataframe
2025-04-19 21:14:47,289:INFO:Initializing Gradient Boosting Regressor
2025-04-19 21:14:47,289:INFO:Total runtime is 1.4594444115956624 minutes
2025-04-19 21:14:47,289:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:47,289:INFO:Initializing create_model()
2025-04-19 21:14:47,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:47,289:INFO:Checking exceptions
2025-04-19 21:14:47,289:INFO:Importing libraries
2025-04-19 21:14:47,289:INFO:Copying training dataset
2025-04-19 21:14:47,291:INFO:Defining folds
2025-04-19 21:14:47,291:INFO:Declaring metric variables
2025-04-19 21:14:47,291:INFO:Importing untrained model
2025-04-19 21:14:47,298:INFO:Gradient Boosting Regressor Imported successfully
2025-04-19 21:14:47,298:INFO:Starting cross validation
2025-04-19 21:14:47,305:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:14:55,223:INFO:Calculating mean and std
2025-04-19 21:14:55,224:INFO:Creating metrics dataframe
2025-04-19 21:14:55,994:INFO:Uploading results into container
2025-04-19 21:14:55,994:INFO:Uploading model into container now
2025-04-19 21:14:55,995:INFO:_master_model_container: 16
2025-04-19 21:14:55,995:INFO:_display_container: 2
2025-04-19 21:14:55,996:INFO:GradientBoostingRegressor(random_state=42)
2025-04-19 21:14:55,996:INFO:create_model() successfully completed......................................
2025-04-19 21:14:56,195:INFO:SubProcess create_model() end ==================================
2025-04-19 21:14:56,195:INFO:Creating metrics dataframe
2025-04-19 21:14:56,205:INFO:Initializing Extreme Gradient Boosting
2025-04-19 21:14:56,205:INFO:Total runtime is 1.6080391923586528 minutes
2025-04-19 21:14:56,205:INFO:SubProcess create_model() called ==================================
2025-04-19 21:14:56,205:INFO:Initializing create_model()
2025-04-19 21:14:56,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:14:56,205:INFO:Checking exceptions
2025-04-19 21:14:56,205:INFO:Importing libraries
2025-04-19 21:14:56,206:INFO:Copying training dataset
2025-04-19 21:14:56,214:INFO:Defining folds
2025-04-19 21:14:56,214:INFO:Declaring metric variables
2025-04-19 21:14:56,214:INFO:Importing untrained model
2025-04-19 21:14:56,217:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:14:56,218:INFO:Starting cross validation
2025-04-19 21:14:56,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:15:02,267:INFO:Calculating mean and std
2025-04-19 21:15:02,267:INFO:Creating metrics dataframe
2025-04-19 21:15:02,808:INFO:Uploading results into container
2025-04-19 21:15:02,808:INFO:Uploading model into container now
2025-04-19 21:15:02,808:INFO:_master_model_container: 17
2025-04-19 21:15:02,808:INFO:_display_container: 2
2025-04-19 21:15:02,808:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2025-04-19 21:15:02,808:INFO:create_model() successfully completed......................................
2025-04-19 21:15:02,952:INFO:SubProcess create_model() end ==================================
2025-04-19 21:15:02,952:INFO:Creating metrics dataframe
2025-04-19 21:15:02,958:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 21:15:02,959:INFO:Total runtime is 1.7206109404563905 minutes
2025-04-19 21:15:02,959:INFO:SubProcess create_model() called ==================================
2025-04-19 21:15:02,959:INFO:Initializing create_model()
2025-04-19 21:15:02,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:15:02,959:INFO:Checking exceptions
2025-04-19 21:15:02,959:INFO:Importing libraries
2025-04-19 21:15:02,959:INFO:Copying training dataset
2025-04-19 21:15:02,963:INFO:Defining folds
2025-04-19 21:15:02,963:INFO:Declaring metric variables
2025-04-19 21:15:02,963:INFO:Importing untrained model
2025-04-19 21:15:02,965:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:15:02,965:INFO:Starting cross validation
2025-04-19 21:15:02,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:15:13,344:INFO:Calculating mean and std
2025-04-19 21:15:13,345:INFO:Creating metrics dataframe
2025-04-19 21:15:14,275:INFO:Uploading results into container
2025-04-19 21:15:14,275:INFO:Uploading model into container now
2025-04-19 21:15:14,277:INFO:_master_model_container: 18
2025-04-19 21:15:14,277:INFO:_display_container: 2
2025-04-19 21:15:14,277:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-19 21:15:14,277:INFO:create_model() successfully completed......................................
2025-04-19 21:15:14,485:INFO:SubProcess create_model() end ==================================
2025-04-19 21:15:14,485:INFO:Creating metrics dataframe
2025-04-19 21:15:14,492:INFO:Initializing Dummy Regressor
2025-04-19 21:15:14,492:INFO:Total runtime is 1.9128268877665202 minutes
2025-04-19 21:15:14,492:INFO:SubProcess create_model() called ==================================
2025-04-19 21:15:14,492:INFO:Initializing create_model()
2025-04-19 21:15:14,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E6FF400>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:15:14,494:INFO:Checking exceptions
2025-04-19 21:15:14,494:INFO:Importing libraries
2025-04-19 21:15:14,494:INFO:Copying training dataset
2025-04-19 21:15:14,506:INFO:Defining folds
2025-04-19 21:15:14,506:INFO:Declaring metric variables
2025-04-19 21:15:14,511:INFO:Importing untrained model
2025-04-19 21:15:14,511:INFO:Dummy Regressor Imported successfully
2025-04-19 21:15:14,511:INFO:Starting cross validation
2025-04-19 21:15:14,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:15:19,166:INFO:Calculating mean and std
2025-04-19 21:15:19,166:INFO:Creating metrics dataframe
2025-04-19 21:15:19,762:INFO:Uploading results into container
2025-04-19 21:15:19,762:INFO:Uploading model into container now
2025-04-19 21:15:19,764:INFO:_master_model_container: 19
2025-04-19 21:15:19,764:INFO:_display_container: 2
2025-04-19 21:15:19,766:INFO:DummyRegressor()
2025-04-19 21:15:19,766:INFO:create_model() successfully completed......................................
2025-04-19 21:15:19,920:INFO:SubProcess create_model() end ==================================
2025-04-19 21:15:19,921:INFO:Creating metrics dataframe
2025-04-19 21:15:19,926:INFO:Initializing create_model()
2025-04-19 21:15:19,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:15:19,928:INFO:Checking exceptions
2025-04-19 21:15:19,928:INFO:Importing libraries
2025-04-19 21:15:19,928:INFO:Copying training dataset
2025-04-19 21:15:19,935:INFO:Defining folds
2025-04-19 21:15:19,935:INFO:Declaring metric variables
2025-04-19 21:15:19,939:INFO:Importing untrained model
2025-04-19 21:15:19,939:INFO:Declaring custom model
2025-04-19 21:15:19,940:INFO:Huber Regressor Imported successfully
2025-04-19 21:15:19,950:INFO:Cross validation set to False
2025-04-19 21:15:19,950:INFO:Fitting Model
2025-04-19 21:15:20,458:INFO:HuberRegressor()
2025-04-19 21:15:20,458:INFO:create_model() successfully completed......................................
2025-04-19 21:15:20,604:INFO:Initializing create_model()
2025-04-19 21:15:20,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:15:20,604:INFO:Checking exceptions
2025-04-19 21:15:20,604:INFO:Importing libraries
2025-04-19 21:15:20,604:INFO:Copying training dataset
2025-04-19 21:15:20,617:INFO:Defining folds
2025-04-19 21:15:20,617:INFO:Declaring metric variables
2025-04-19 21:15:20,617:INFO:Importing untrained model
2025-04-19 21:15:20,617:INFO:Declaring custom model
2025-04-19 21:15:20,617:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:15:20,633:INFO:Cross validation set to False
2025-04-19 21:15:20,633:INFO:Fitting Model
2025-04-19 21:15:21,075:INFO:BayesianRidge()
2025-04-19 21:15:21,075:INFO:create_model() successfully completed......................................
2025-04-19 21:15:21,208:INFO:Initializing create_model()
2025-04-19 21:15:21,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:15:21,208:INFO:Checking exceptions
2025-04-19 21:15:21,208:INFO:Importing libraries
2025-04-19 21:15:21,208:INFO:Copying training dataset
2025-04-19 21:15:21,216:INFO:Defining folds
2025-04-19 21:15:21,217:INFO:Declaring metric variables
2025-04-19 21:15:21,217:INFO:Importing untrained model
2025-04-19 21:15:21,217:INFO:Declaring custom model
2025-04-19 21:15:21,217:INFO:Linear Regression Imported successfully
2025-04-19 21:15:21,222:INFO:Cross validation set to False
2025-04-19 21:15:21,222:INFO:Fitting Model
2025-04-19 21:15:21,677:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:15:21,677:INFO:create_model() successfully completed......................................
2025-04-19 21:15:21,833:INFO:_master_model_container: 19
2025-04-19 21:15:21,833:INFO:_display_container: 2
2025-04-19 21:15:21,833:INFO:[HuberRegressor(), BayesianRidge(), LinearRegression(n_jobs=-1)]
2025-04-19 21:15:21,833:INFO:compare_models() successfully completed......................................
2025-04-19 21:15:21,833:INFO:Initializing tune_model()
2025-04-19 21:15:21,833:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>)
2025-04-19 21:15:21,833:INFO:Checking exceptions
2025-04-19 21:15:21,838:INFO:Copying training dataset
2025-04-19 21:15:21,845:INFO:Checking base model
2025-04-19 21:15:21,845:INFO:Base model : Huber Regressor
2025-04-19 21:15:21,845:INFO:Declaring metric variables
2025-04-19 21:15:21,845:INFO:Defining Hyperparameters
2025-04-19 21:15:22,017:INFO:Tuning with n_jobs=-1
2025-04-19 21:15:22,017:INFO:Initializing RandomizedSearchCV
2025-04-19 21:16:09,115:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.01}
2025-04-19 21:16:09,115:INFO:Hyperparameter search completed
2025-04-19 21:16:09,115:INFO:SubProcess create_model() called ==================================
2025-04-19 21:16:09,115:INFO:Initializing create_model()
2025-04-19 21:16:09,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311DDAC850>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True, 'epsilon': 1.4, 'alpha': 0.01})
2025-04-19 21:16:09,115:INFO:Checking exceptions
2025-04-19 21:16:09,115:INFO:Importing libraries
2025-04-19 21:16:09,115:INFO:Copying training dataset
2025-04-19 21:16:09,131:INFO:Defining folds
2025-04-19 21:16:09,131:INFO:Declaring metric variables
2025-04-19 21:16:09,131:INFO:Importing untrained model
2025-04-19 21:16:09,131:INFO:Declaring custom model
2025-04-19 21:16:09,135:INFO:Huber Regressor Imported successfully
2025-04-19 21:16:09,135:INFO:Starting cross validation
2025-04-19 21:16:09,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:16:13,815:INFO:Calculating mean and std
2025-04-19 21:16:13,815:INFO:Creating metrics dataframe
2025-04-19 21:16:13,815:INFO:Finalizing model
2025-04-19 21:16:14,615:INFO:Uploading results into container
2025-04-19 21:16:14,616:INFO:Uploading model into container now
2025-04-19 21:16:14,618:INFO:_master_model_container: 20
2025-04-19 21:16:14,618:INFO:_display_container: 3
2025-04-19 21:16:14,618:INFO:HuberRegressor(alpha=0.01, epsilon=1.4)
2025-04-19 21:16:14,618:INFO:create_model() successfully completed......................................
2025-04-19 21:16:14,791:INFO:SubProcess create_model() end ==================================
2025-04-19 21:16:14,791:INFO:choose_better activated
2025-04-19 21:16:14,791:INFO:SubProcess create_model() called ==================================
2025-04-19 21:16:14,791:INFO:Initializing create_model()
2025-04-19 21:16:14,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:16:14,791:INFO:Checking exceptions
2025-04-19 21:16:14,791:INFO:Importing libraries
2025-04-19 21:16:14,791:INFO:Copying training dataset
2025-04-19 21:16:14,800:INFO:Defining folds
2025-04-19 21:16:14,800:INFO:Declaring metric variables
2025-04-19 21:16:14,803:INFO:Importing untrained model
2025-04-19 21:16:14,803:INFO:Declaring custom model
2025-04-19 21:16:14,803:INFO:Huber Regressor Imported successfully
2025-04-19 21:16:14,803:INFO:Starting cross validation
2025-04-19 21:16:14,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:16:19,789:INFO:Calculating mean and std
2025-04-19 21:16:19,789:INFO:Creating metrics dataframe
2025-04-19 21:16:19,791:INFO:Finalizing model
2025-04-19 21:16:20,540:INFO:Uploading results into container
2025-04-19 21:16:20,540:INFO:Uploading model into container now
2025-04-19 21:16:20,540:INFO:_master_model_container: 21
2025-04-19 21:16:20,540:INFO:_display_container: 4
2025-04-19 21:16:20,540:INFO:HuberRegressor()
2025-04-19 21:16:20,540:INFO:create_model() successfully completed......................................
2025-04-19 21:16:20,704:INFO:SubProcess create_model() end ==================================
2025-04-19 21:16:20,704:INFO:HuberRegressor() result for R2 is 0.0034
2025-04-19 21:16:20,704:INFO:HuberRegressor(alpha=0.01, epsilon=1.4) result for R2 is 0.0033
2025-04-19 21:16:20,704:INFO:HuberRegressor() is best model
2025-04-19 21:16:20,704:INFO:choose_better completed
2025-04-19 21:16:20,704:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:16:20,726:INFO:_master_model_container: 21
2025-04-19 21:16:20,727:INFO:_display_container: 3
2025-04-19 21:16:20,727:INFO:HuberRegressor()
2025-04-19 21:16:20,727:INFO:tune_model() successfully completed......................................
2025-04-19 21:16:21,306:INFO:Initializing tune_model()
2025-04-19 21:16:21,306:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>)
2025-04-19 21:16:21,306:INFO:Checking exceptions
2025-04-19 21:16:21,317:INFO:Copying training dataset
2025-04-19 21:16:21,319:INFO:Checking base model
2025-04-19 21:16:21,319:INFO:Base model : Bayesian Ridge
2025-04-19 21:16:21,319:INFO:Declaring metric variables
2025-04-19 21:16:21,319:INFO:Defining Hyperparameters
2025-04-19 21:16:21,506:INFO:Tuning with n_jobs=-1
2025-04-19 21:16:21,506:INFO:Initializing RandomizedSearchCV
2025-04-19 21:17:12,391:INFO:best_params: {'actual_estimator__lambda_2': 0.005, 'actual_estimator__lambda_1': 1e-06, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': True, 'actual_estimator__alpha_2': 0.3, 'actual_estimator__alpha_1': 0.3}
2025-04-19 21:17:12,391:INFO:Hyperparameter search completed
2025-04-19 21:17:12,391:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:12,391:INFO:Initializing create_model()
2025-04-19 21:17:12,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311E18A6E0>, model_only=True, return_train_score=False, kwargs={'lambda_2': 0.005, 'lambda_1': 1e-06, 'fit_intercept': True, 'compute_score': True, 'alpha_2': 0.3, 'alpha_1': 0.3})
2025-04-19 21:17:12,391:INFO:Checking exceptions
2025-04-19 21:17:12,391:INFO:Importing libraries
2025-04-19 21:17:12,391:INFO:Copying training dataset
2025-04-19 21:17:12,398:INFO:Defining folds
2025-04-19 21:17:12,403:INFO:Declaring metric variables
2025-04-19 21:17:12,403:INFO:Importing untrained model
2025-04-19 21:17:12,403:INFO:Declaring custom model
2025-04-19 21:17:12,403:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:17:12,403:INFO:Starting cross validation
2025-04-19 21:17:12,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:16,850:INFO:Calculating mean and std
2025-04-19 21:17:16,850:INFO:Creating metrics dataframe
2025-04-19 21:17:16,850:INFO:Finalizing model
2025-04-19 21:17:17,538:INFO:Uploading results into container
2025-04-19 21:17:17,538:INFO:Uploading model into container now
2025-04-19 21:17:17,538:INFO:_master_model_container: 22
2025-04-19 21:17:17,538:INFO:_display_container: 4
2025-04-19 21:17:17,538:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 21:17:17,538:INFO:create_model() successfully completed......................................
2025-04-19 21:17:17,712:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:17,715:INFO:choose_better activated
2025-04-19 21:17:17,715:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:17,715:INFO:Initializing create_model()
2025-04-19 21:17:17,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:17:17,715:INFO:Checking exceptions
2025-04-19 21:17:17,715:INFO:Importing libraries
2025-04-19 21:17:17,715:INFO:Copying training dataset
2025-04-19 21:17:17,715:INFO:Defining folds
2025-04-19 21:17:17,715:INFO:Declaring metric variables
2025-04-19 21:17:17,715:INFO:Importing untrained model
2025-04-19 21:17:17,715:INFO:Declaring custom model
2025-04-19 21:17:17,723:INFO:Bayesian Ridge Imported successfully
2025-04-19 21:17:17,723:INFO:Starting cross validation
2025-04-19 21:17:17,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:21,865:INFO:Calculating mean and std
2025-04-19 21:17:21,865:INFO:Creating metrics dataframe
2025-04-19 21:17:21,867:INFO:Finalizing model
2025-04-19 21:17:22,520:INFO:Uploading results into container
2025-04-19 21:17:22,520:INFO:Uploading model into container now
2025-04-19 21:17:22,520:INFO:_master_model_container: 23
2025-04-19 21:17:22,520:INFO:_display_container: 5
2025-04-19 21:17:22,520:INFO:BayesianRidge()
2025-04-19 21:17:22,520:INFO:create_model() successfully completed......................................
2025-04-19 21:17:22,663:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:22,663:INFO:BayesianRidge() result for R2 is -0.0008
2025-04-19 21:17:22,663:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) result for R2 is -0.0007
2025-04-19 21:17:22,663:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005) is best model
2025-04-19 21:17:22,663:INFO:choose_better completed
2025-04-19 21:17:22,679:INFO:_master_model_container: 23
2025-04-19 21:17:22,680:INFO:_display_container: 4
2025-04-19 21:17:22,680:INFO:BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)
2025-04-19 21:17:22,680:INFO:tune_model() successfully completed......................................
2025-04-19 21:17:23,212:INFO:Initializing tune_model()
2025-04-19 21:17:23,213:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>)
2025-04-19 21:17:23,213:INFO:Checking exceptions
2025-04-19 21:17:23,213:INFO:Copying training dataset
2025-04-19 21:17:23,213:INFO:Checking base model
2025-04-19 21:17:23,213:INFO:Base model : Linear Regression
2025-04-19 21:17:23,213:INFO:Declaring metric variables
2025-04-19 21:17:23,213:INFO:Defining Hyperparameters
2025-04-19 21:17:23,213:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-04-19 21:17:23,379:INFO:Tuning with n_jobs=-1
2025-04-19 21:17:23,379:INFO:Initializing GridSearchCV
2025-04-19 21:17:34,835:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-04-19 21:17:34,835:INFO:Hyperparameter search completed
2025-04-19 21:17:34,835:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:34,835:INFO:Initializing create_model()
2025-04-19 21:17:34,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002311DDAC850>, model_only=True, return_train_score=False, kwargs={'fit_intercept': True})
2025-04-19 21:17:34,835:INFO:Checking exceptions
2025-04-19 21:17:34,835:INFO:Importing libraries
2025-04-19 21:17:34,835:INFO:Copying training dataset
2025-04-19 21:17:34,847:INFO:Defining folds
2025-04-19 21:17:34,847:INFO:Declaring metric variables
2025-04-19 21:17:34,847:INFO:Importing untrained model
2025-04-19 21:17:34,847:INFO:Declaring custom model
2025-04-19 21:17:34,847:INFO:Linear Regression Imported successfully
2025-04-19 21:17:34,847:INFO:Starting cross validation
2025-04-19 21:17:34,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:39,112:INFO:Calculating mean and std
2025-04-19 21:17:39,112:INFO:Creating metrics dataframe
2025-04-19 21:17:39,112:INFO:Finalizing model
2025-04-19 21:17:39,770:INFO:Uploading results into container
2025-04-19 21:17:39,770:INFO:Uploading model into container now
2025-04-19 21:17:39,771:INFO:_master_model_container: 24
2025-04-19 21:17:39,771:INFO:_display_container: 5
2025-04-19 21:17:39,771:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:17:39,771:INFO:create_model() successfully completed......................................
2025-04-19 21:17:39,937:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:39,937:INFO:choose_better activated
2025-04-19 21:17:39,937:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:39,939:INFO:Initializing create_model()
2025-04-19 21:17:39,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:17:39,939:INFO:Checking exceptions
2025-04-19 21:17:39,941:INFO:Importing libraries
2025-04-19 21:17:39,941:INFO:Copying training dataset
2025-04-19 21:17:39,949:INFO:Defining folds
2025-04-19 21:17:39,949:INFO:Declaring metric variables
2025-04-19 21:17:39,949:INFO:Importing untrained model
2025-04-19 21:17:39,949:INFO:Declaring custom model
2025-04-19 21:17:39,949:INFO:Linear Regression Imported successfully
2025-04-19 21:17:39,949:INFO:Starting cross validation
2025-04-19 21:17:39,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:44,185:INFO:Calculating mean and std
2025-04-19 21:17:44,186:INFO:Creating metrics dataframe
2025-04-19 21:17:44,186:INFO:Finalizing model
2025-04-19 21:17:44,820:INFO:Uploading results into container
2025-04-19 21:17:44,820:INFO:Uploading model into container now
2025-04-19 21:17:44,823:INFO:_master_model_container: 25
2025-04-19 21:17:44,823:INFO:_display_container: 6
2025-04-19 21:17:44,823:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:17:44,823:INFO:create_model() successfully completed......................................
2025-04-19 21:17:44,962:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:44,962:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0011
2025-04-19 21:17:44,962:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.0011
2025-04-19 21:17:44,962:INFO:LinearRegression(n_jobs=-1) is best model
2025-04-19 21:17:44,962:INFO:choose_better completed
2025-04-19 21:17:44,975:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:17:44,988:INFO:_master_model_container: 25
2025-04-19 21:17:44,989:INFO:_display_container: 5
2025-04-19 21:17:44,989:INFO:LinearRegression(n_jobs=-1)
2025-04-19 21:17:44,990:INFO:tune_model() successfully completed......................................
2025-04-19 21:17:45,522:INFO:Initializing blend_models()
2025-04-19 21:17:45,522:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), LinearRegression(n_jobs=-1)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:17:45,522:INFO:Checking exceptions
2025-04-19 21:17:45,528:INFO:Importing libraries
2025-04-19 21:17:45,528:INFO:Copying training dataset
2025-04-19 21:17:45,528:INFO:Getting model names
2025-04-19 21:17:45,528:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:45,528:INFO:Initializing create_model()
2025-04-19 21:17:45,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000231140AE980>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:17:45,528:INFO:Checking exceptions
2025-04-19 21:17:45,528:INFO:Importing libraries
2025-04-19 21:17:45,528:INFO:Copying training dataset
2025-04-19 21:17:45,539:INFO:Defining folds
2025-04-19 21:17:45,539:INFO:Declaring metric variables
2025-04-19 21:17:45,539:INFO:Importing untrained model
2025-04-19 21:17:45,542:INFO:Declaring custom model
2025-04-19 21:17:45,546:INFO:Voting Regressor Imported successfully
2025-04-19 21:17:45,547:INFO:Starting cross validation
2025-04-19 21:17:45,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:49,855:INFO:Calculating mean and std
2025-04-19 21:17:49,856:INFO:Creating metrics dataframe
2025-04-19 21:17:49,859:INFO:Finalizing model
2025-04-19 21:17:50,821:INFO:Uploading results into container
2025-04-19 21:17:50,821:INFO:Uploading model into container now
2025-04-19 21:17:50,821:INFO:_master_model_container: 26
2025-04-19 21:17:50,823:INFO:_display_container: 6
2025-04-19 21:17:50,826:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:17:50,828:INFO:create_model() successfully completed......................................
2025-04-19 21:17:51,112:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:51,124:INFO:_master_model_container: 26
2025-04-19 21:17:51,124:INFO:_display_container: 6
2025-04-19 21:17:51,128:INFO:VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1)
2025-04-19 21:17:51,128:INFO:blend_models() successfully completed......................................
2025-04-19 21:17:51,299:INFO:Initializing stack_models()
2025-04-19 21:17:51,299:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator_list=[HuberRegressor(), BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), LinearRegression(n_jobs=-1)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:17:51,299:INFO:Checking exceptions
2025-04-19 21:17:51,299:INFO:Defining meta model
2025-04-19 21:17:51,304:INFO:Getting model names
2025-04-19 21:17:51,304:INFO:[('Huber Regressor', HuberRegressor()), ('Bayesian Ridge', BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005)), ('Linear Regression', LinearRegression(n_jobs=-1))]
2025-04-19 21:17:51,304:INFO:SubProcess create_model() called ==================================
2025-04-19 21:17:51,313:INFO:Initializing create_model()
2025-04-19 21:17:51,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000231140AD660>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:17:51,313:INFO:Checking exceptions
2025-04-19 21:17:51,313:INFO:Importing libraries
2025-04-19 21:17:51,313:INFO:Copying training dataset
2025-04-19 21:17:51,320:INFO:Defining folds
2025-04-19 21:17:51,320:INFO:Declaring metric variables
2025-04-19 21:17:51,320:INFO:Importing untrained model
2025-04-19 21:17:51,320:INFO:Declaring custom model
2025-04-19 21:17:51,320:INFO:Stacking Regressor Imported successfully
2025-04-19 21:17:51,320:INFO:Starting cross validation
2025-04-19 21:17:51,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:17:56,248:INFO:Calculating mean and std
2025-04-19 21:17:56,248:INFO:Creating metrics dataframe
2025-04-19 21:17:56,250:INFO:Finalizing model
2025-04-19 21:17:57,256:INFO:Uploading results into container
2025-04-19 21:17:57,257:INFO:Uploading model into container now
2025-04-19 21:17:57,257:INFO:_master_model_container: 27
2025-04-19 21:17:57,257:INFO:_display_container: 7
2025-04-19 21:17:57,261:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:17:57,261:INFO:create_model() successfully completed......................................
2025-04-19 21:17:57,420:INFO:SubProcess create_model() end ==================================
2025-04-19 21:17:57,431:INFO:_master_model_container: 27
2025-04-19 21:17:57,431:INFO:_display_container: 7
2025-04-19 21:17:57,431:INFO:StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True)
2025-04-19 21:17:57,431:INFO:stack_models() successfully completed......................................
2025-04-19 21:17:57,601:INFO:Initializing save_model()
2025-04-19 21:17:57,601:INFO:save_model(model=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), model_name=models/model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:17:57,601:INFO:Adding model into prep_pipe
2025-04-19 21:17:57,661:INFO:models/model_1.pkl saved in current working directory
2025-04-19 21:17:57,700:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 VotingRegressor(estimators=[('Huber Regressor',
                                              HuberRegressor()),
                                             ('Bayesian Ridge',
                                              BayesianRidge(alpha_1=0.3,
                                                            alpha_2=0.3,
                                                            compute_score=True,
                                                            lambda_2=0.005)),
                                             ('Linear Regression',
                                              LinearRegression(n_jobs=-1))],
                                 n_jobs=-1))])
2025-04-19 21:17:57,700:INFO:save_model() successfully completed......................................
2025-04-19 21:17:58,268:INFO:Initializing plot_model()
2025-04-19 21:17:58,268:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:17:58,268:INFO:Checking exceptions
2025-04-19 21:17:58,272:INFO:Initializing plot_model()
2025-04-19 21:17:58,272:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:17:58,272:INFO:Checking exceptions
2025-04-19 21:17:58,278:INFO:Preloading libraries
2025-04-19 21:17:58,278:INFO:Copying training dataset
2025-04-19 21:17:58,278:INFO:Plot type: residuals
2025-04-19 21:17:58,795:INFO:Fitting Model
2025-04-19 21:17:58,795:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:17:58,856:INFO:Scoring test/hold-out set
2025-04-19 21:17:58,935:INFO:Saving 'Residuals.png'
2025-04-19 21:18:00,238:INFO:Visual Rendered Successfully
2025-04-19 21:18:00,423:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:00,789:INFO:Initializing plot_model()
2025-04-19 21:18:00,789:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:00,789:INFO:Checking exceptions
2025-04-19 21:18:00,797:INFO:Preloading libraries
2025-04-19 21:18:00,797:INFO:Copying training dataset
2025-04-19 21:18:00,797:INFO:Plot type: error
2025-04-19 21:18:01,245:INFO:Fitting Model
2025-04-19 21:18:01,245:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:18:01,245:INFO:Scoring test/hold-out set
2025-04-19 21:18:01,279:INFO:Saving 'Prediction Error.png'
2025-04-19 21:18:01,844:INFO:Visual Rendered Successfully
2025-04-19 21:18:02,014:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:02,400:INFO:Initializing plot_model()
2025-04-19 21:18:02,400:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:02,400:INFO:Checking exceptions
2025-04-19 21:18:02,404:INFO:Preloading libraries
2025-04-19 21:18:02,405:INFO:Copying training dataset
2025-04-19 21:18:02,405:INFO:Plot type: learning
2025-04-19 21:18:02,836:INFO:Fitting Model
2025-04-19 21:18:04,362:INFO:Saving 'Learning Curve.png'
2025-04-19 21:18:05,094:INFO:Visual Rendered Successfully
2025-04-19 21:18:05,257:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:05,723:INFO:Initializing save_model()
2025-04-19 21:18:05,725:INFO:save_model(model=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), model_name=models/model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:18:05,725:INFO:Adding model into prep_pipe
2025-04-19 21:18:05,794:INFO:models/model_2.pkl saved in current working directory
2025-04-19 21:18:05,817:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 StackingRegressor(cv=5,
                                   estimators=[('Huber Regressor',
                                                HuberRegressor()),
                                               ('Bayesian Ridge',
                                                BayesianRidge(alpha_1=0.3,
                                                              alpha_2=0.3,
                                                              compute_score=True,
                                                              lambda_2=0.005)),
                                               ('Linear Regression',
                                                LinearRegression(n_jobs=-1))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1, passthrough=True))])
2025-04-19 21:18:05,817:INFO:save_model() successfully completed......................................
2025-04-19 21:18:06,538:INFO:Initializing plot_model()
2025-04-19 21:18:06,540:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:06,540:INFO:Checking exceptions
2025-04-19 21:18:06,546:INFO:Initializing plot_model()
2025-04-19 21:18:06,546:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:06,548:INFO:Checking exceptions
2025-04-19 21:18:06,551:INFO:Preloading libraries
2025-04-19 21:18:06,551:INFO:Copying training dataset
2025-04-19 21:18:06,551:INFO:Plot type: residuals
2025-04-19 21:18:07,228:INFO:Fitting Model
2025-04-19 21:18:07,230:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:18:07,294:INFO:Scoring test/hold-out set
2025-04-19 21:18:07,361:INFO:Saving 'Residuals.png'
2025-04-19 21:18:08,594:INFO:Visual Rendered Successfully
2025-04-19 21:18:08,820:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:09,244:INFO:Initializing plot_model()
2025-04-19 21:18:09,244:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:09,244:INFO:Checking exceptions
2025-04-19 21:18:09,244:INFO:Preloading libraries
2025-04-19 21:18:09,244:INFO:Copying training dataset
2025-04-19 21:18:09,244:INFO:Plot type: error
2025-04-19 21:18:09,780:INFO:Fitting Model
2025-04-19 21:18:09,780:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:18:09,780:INFO:Scoring test/hold-out set
2025-04-19 21:18:09,817:INFO:Saving 'Prediction Error.png'
2025-04-19 21:18:10,519:INFO:Visual Rendered Successfully
2025-04-19 21:18:10,677:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:11,175:INFO:Initializing plot_model()
2025-04-19 21:18:11,175:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:11,177:INFO:Checking exceptions
2025-04-19 21:18:11,177:INFO:Preloading libraries
2025-04-19 21:18:11,177:INFO:Copying training dataset
2025-04-19 21:18:11,177:INFO:Plot type: learning
2025-04-19 21:18:11,660:INFO:Fitting Model
2025-04-19 21:18:14,220:INFO:Saving 'Learning Curve.png'
2025-04-19 21:18:14,927:INFO:Visual Rendered Successfully
2025-04-19 21:18:15,144:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:15,577:INFO:Initializing save_model()
2025-04-19 21:18:15,577:INFO:save_model(model=HuberRegressor(), model_name=models/model_3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:18:15,577:INFO:Adding model into prep_pipe
2025-04-19 21:18:15,690:INFO:models/model_3.pkl saved in current working directory
2025-04-19 21:18:15,721:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', HuberRegressor())])
2025-04-19 21:18:15,721:INFO:save_model() successfully completed......................................
2025-04-19 21:18:16,419:INFO:Initializing plot_model()
2025-04-19 21:18:16,419:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:16,419:INFO:Checking exceptions
2025-04-19 21:18:16,421:INFO:Preloading libraries
2025-04-19 21:18:16,423:INFO:Copying training dataset
2025-04-19 21:18:16,423:INFO:Plot type: feature
2025-04-19 21:18:16,765:INFO:Saving 'Feature Importance.png'
2025-04-19 21:18:17,111:INFO:Visual Rendered Successfully
2025-04-19 21:18:17,307:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:17,740:INFO:Initializing plot_model()
2025-04-19 21:18:17,740:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:17,740:INFO:Checking exceptions
2025-04-19 21:18:17,747:INFO:Preloading libraries
2025-04-19 21:18:17,747:INFO:Copying training dataset
2025-04-19 21:18:17,747:INFO:Plot type: residuals
2025-04-19 21:18:18,397:INFO:Fitting Model
2025-04-19 21:18:18,397:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:18:18,477:INFO:Scoring test/hold-out set
2025-04-19 21:18:18,529:INFO:Saving 'Residuals.png'
2025-04-19 21:18:19,988:INFO:Visual Rendered Successfully
2025-04-19 21:18:20,241:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:20,736:INFO:Initializing plot_model()
2025-04-19 21:18:20,736:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:20,736:INFO:Checking exceptions
2025-04-19 21:18:20,739:INFO:Preloading libraries
2025-04-19 21:18:20,739:INFO:Copying training dataset
2025-04-19 21:18:20,739:INFO:Plot type: error
2025-04-19 21:18:21,351:INFO:Fitting Model
2025-04-19 21:18:21,351:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2025-04-19 21:18:21,352:INFO:Scoring test/hold-out set
2025-04-19 21:18:21,387:INFO:Saving 'Prediction Error.png'
2025-04-19 21:18:22,144:INFO:Visual Rendered Successfully
2025-04-19 21:18:22,411:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:22,844:INFO:Initializing plot_model()
2025-04-19 21:18:22,844:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:22,844:INFO:Checking exceptions
2025-04-19 21:18:22,844:INFO:Preloading libraries
2025-04-19 21:18:22,847:INFO:Copying training dataset
2025-04-19 21:18:22,847:INFO:Plot type: learning
2025-04-19 21:18:23,287:INFO:Fitting Model
2025-04-19 21:18:23,867:INFO:Saving 'Learning Curve.png'
2025-04-19 21:18:24,553:INFO:Visual Rendered Successfully
2025-04-19 21:18:24,727:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:25,197:INFO:Initializing save_model()
2025-04-19 21:18:25,197:INFO:save_model(model=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), model_name=models/model_4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:18:25,197:INFO:Adding model into prep_pipe
2025-04-19 21:18:25,288:INFO:models/model_4.pkl saved in current working directory
2025-04-19 21:18:25,305:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True,
                               lambda_2=0.005))])
2025-04-19 21:18:25,305:INFO:save_model() successfully completed......................................
2025-04-19 21:18:25,977:INFO:Initializing plot_model()
2025-04-19 21:18:25,977:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:25,977:INFO:Checking exceptions
2025-04-19 21:18:25,991:INFO:Preloading libraries
2025-04-19 21:18:25,993:INFO:Copying training dataset
2025-04-19 21:18:25,993:INFO:Plot type: feature
2025-04-19 21:18:26,336:INFO:Saving 'Feature Importance.png'
2025-04-19 21:18:26,620:INFO:Visual Rendered Successfully
2025-04-19 21:18:26,766:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:27,210:INFO:Initializing plot_model()
2025-04-19 21:18:27,210:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:27,210:INFO:Checking exceptions
2025-04-19 21:18:27,210:INFO:Preloading libraries
2025-04-19 21:18:27,210:INFO:Copying training dataset
2025-04-19 21:18:27,210:INFO:Plot type: residuals
2025-04-19 21:18:27,827:INFO:Fitting Model
2025-04-19 21:18:27,827:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:18:27,860:INFO:Scoring test/hold-out set
2025-04-19 21:18:27,915:INFO:Saving 'Residuals.png'
2025-04-19 21:18:29,610:INFO:Visual Rendered Successfully
2025-04-19 21:18:29,836:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:30,278:INFO:Initializing plot_model()
2025-04-19 21:18:30,278:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:30,278:INFO:Checking exceptions
2025-04-19 21:18:30,278:INFO:Preloading libraries
2025-04-19 21:18:30,278:INFO:Copying training dataset
2025-04-19 21:18:30,278:INFO:Plot type: error
2025-04-19 21:18:30,710:INFO:Fitting Model
2025-04-19 21:18:30,710:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2025-04-19 21:18:30,710:INFO:Scoring test/hold-out set
2025-04-19 21:18:30,766:INFO:Saving 'Prediction Error.png'
2025-04-19 21:18:31,577:INFO:Visual Rendered Successfully
2025-04-19 21:18:31,827:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:32,199:INFO:Initializing plot_model()
2025-04-19 21:18:32,199:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:32,199:INFO:Checking exceptions
2025-04-19 21:18:32,199:INFO:Preloading libraries
2025-04-19 21:18:32,199:INFO:Copying training dataset
2025-04-19 21:18:32,199:INFO:Plot type: learning
2025-04-19 21:18:32,689:INFO:Fitting Model
2025-04-19 21:18:33,131:INFO:Saving 'Learning Curve.png'
2025-04-19 21:18:33,793:INFO:Visual Rendered Successfully
2025-04-19 21:18:34,043:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:34,560:INFO:Initializing save_model()
2025-04-19 21:18:34,560:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=models/model_5, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-19 21:18:34,560:INFO:Adding model into prep_pipe
2025-04-19 21:18:34,644:INFO:models/model_5.pkl saved in current working directory
2025-04-19 21:18:34,665:INFO:Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['feature_21', 'feature_55',
                                             'feature_11', 'feature_19',
                                             'feature_63', 'feature_49',
                                             'fe...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=42))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-04-19 21:18:34,665:INFO:save_model() successfully completed......................................
2025-04-19 21:18:35,277:INFO:Initializing plot_model()
2025-04-19 21:18:35,277:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:35,277:INFO:Checking exceptions
2025-04-19 21:18:35,279:INFO:Preloading libraries
2025-04-19 21:18:35,281:INFO:Copying training dataset
2025-04-19 21:18:35,281:INFO:Plot type: feature
2025-04-19 21:18:35,568:INFO:Saving 'Feature Importance.png'
2025-04-19 21:18:35,963:INFO:Visual Rendered Successfully
2025-04-19 21:18:36,144:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:36,627:INFO:Initializing plot_model()
2025-04-19 21:18:36,627:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:36,627:INFO:Checking exceptions
2025-04-19 21:18:36,627:INFO:Preloading libraries
2025-04-19 21:18:36,627:INFO:Copying training dataset
2025-04-19 21:18:36,627:INFO:Plot type: residuals
2025-04-19 21:18:37,110:INFO:Fitting Model
2025-04-19 21:18:37,110:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:18:37,222:INFO:Scoring test/hold-out set
2025-04-19 21:18:37,294:INFO:Saving 'Residuals.png'
2025-04-19 21:18:38,393:INFO:Visual Rendered Successfully
2025-04-19 21:18:38,654:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:39,027:INFO:Initializing plot_model()
2025-04-19 21:18:39,027:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:39,027:INFO:Checking exceptions
2025-04-19 21:18:39,027:INFO:Preloading libraries
2025-04-19 21:18:39,027:INFO:Copying training dataset
2025-04-19 21:18:39,027:INFO:Plot type: error
2025-04-19 21:18:39,543:INFO:Fitting Model
2025-04-19 21:18:39,543:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-04-19 21:18:39,543:INFO:Scoring test/hold-out set
2025-04-19 21:18:39,582:INFO:Saving 'Prediction Error.png'
2025-04-19 21:18:40,286:INFO:Visual Rendered Successfully
2025-04-19 21:18:40,511:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:40,860:INFO:Initializing plot_model()
2025-04-19 21:18:40,860:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, system=True)
2025-04-19 21:18:40,860:INFO:Checking exceptions
2025-04-19 21:18:40,877:INFO:Preloading libraries
2025-04-19 21:18:40,877:INFO:Copying training dataset
2025-04-19 21:18:40,877:INFO:Plot type: learning
2025-04-19 21:18:41,477:INFO:Fitting Model
2025-04-19 21:18:41,927:INFO:Saving 'Learning Curve.png'
2025-04-19 21:18:42,712:INFO:Visual Rendered Successfully
2025-04-19 21:18:42,913:INFO:plot_model() successfully completed......................................
2025-04-19 21:18:43,461:INFO:Initializing predict_model()
2025-04-19 21:18:43,461:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=VotingRegressor(estimators=[('Huber Regressor', HuberRegressor()),
                            ('Bayesian Ridge',
                             BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                           compute_score=True,
                                           lambda_2=0.005)),
                            ('Linear Regression', LinearRegression(n_jobs=-1))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311E5E7B50>)
2025-04-19 21:18:43,461:INFO:Checking exceptions
2025-04-19 21:18:43,461:INFO:Preloading libraries
2025-04-19 21:18:43,461:INFO:Set up data.
2025-04-19 21:18:43,478:INFO:Set up index.
2025-04-19 21:18:43,834:INFO:Initializing predict_model()
2025-04-19 21:18:43,834:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=StackingRegressor(cv=5,
                  estimators=[('Huber Regressor', HuberRegressor()),
                              ('Bayesian Ridge',
                               BayesianRidge(alpha_1=0.3, alpha_2=0.3,
                                             compute_score=True,
                                             lambda_2=0.005)),
                              ('Linear Regression',
                               LinearRegression(n_jobs=-1))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1,
                  passthrough=True), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311705F5B0>)
2025-04-19 21:18:43,834:INFO:Checking exceptions
2025-04-19 21:18:43,834:INFO:Preloading libraries
2025-04-19 21:18:43,834:INFO:Set up data.
2025-04-19 21:18:43,834:INFO:Set up index.
2025-04-19 21:18:44,147:INFO:Initializing predict_model()
2025-04-19 21:18:44,147:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311705F5B0>)
2025-04-19 21:18:44,147:INFO:Checking exceptions
2025-04-19 21:18:44,147:INFO:Preloading libraries
2025-04-19 21:18:44,147:INFO:Set up data.
2025-04-19 21:18:44,154:INFO:Set up index.
2025-04-19 21:18:44,393:INFO:Initializing predict_model()
2025-04-19 21:18:44,393:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=BayesianRidge(alpha_1=0.3, alpha_2=0.3, compute_score=True, lambda_2=0.005), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311705F5B0>)
2025-04-19 21:18:44,393:INFO:Checking exceptions
2025-04-19 21:18:44,393:INFO:Preloading libraries
2025-04-19 21:18:44,393:INFO:Set up data.
2025-04-19 21:18:44,393:INFO:Set up index.
2025-04-19 21:18:44,722:INFO:Initializing predict_model()
2025-04-19 21:18:44,722:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002311DB0FA30>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002311D9ABC70>)
2025-04-19 21:18:44,722:INFO:Checking exceptions
2025-04-19 21:18:44,722:INFO:Preloading libraries
2025-04-19 21:18:44,722:INFO:Set up data.
2025-04-19 21:18:44,731:INFO:Set up index.
2025-04-19 21:23:51,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:23:51,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:23:51,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:23:51,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 21:24:59,123:INFO:PyCaret ClassificationExperiment
2025-04-19 21:24:59,123:INFO:Logging name: agn_classification
2025-04-19 21:24:59,123:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 21:24:59,123:INFO:version 3.0.4
2025-04-19 21:24:59,123:INFO:Initializing setup()
2025-04-19 21:24:59,123:INFO:self.USI: 7409
2025-04-19 21:24:59,123:INFO:self._variable_keys: {'log_plots_param', 'data', 'X', 'fix_imbalance', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_name_log', 'html_param', 'fold_generator', '_available_plots', 'y', '_ml_usecase', 'memory', 'X_test', 'logging_param', 'USI', 'fold_shuffle_param', 'y_test', 'exp_id', 'pipeline', 'gpu_param', 'y_train', 'fold_groups_param', 'is_multiclass', 'idx', 'X_train', 'seed'}
2025-04-19 21:24:59,123:INFO:Checking environment
2025-04-19 21:24:59,123:INFO:python_version: 3.10.9
2025-04-19 21:24:59,123:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2025-04-19 21:24:59,123:INFO:machine: AMD64
2025-04-19 21:24:59,140:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 21:24:59,146:INFO:Memory: svmem(total=16952647680, available=4389588992, percent=74.1, used=12563058688, free=4389588992)
2025-04-19 21:24:59,146:INFO:Physical Core: 4
2025-04-19 21:24:59,146:INFO:Logical Core: 8
2025-04-19 21:24:59,146:INFO:Checking libraries
2025-04-19 21:24:59,146:INFO:System:
2025-04-19 21:24:59,146:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2025-04-19 21:24:59,146:INFO:executable: D:\College\agn\venv_py310\Scripts\python.exe
2025-04-19 21:24:59,146:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 21:24:59,146:INFO:PyCaret required dependencies:
2025-04-19 21:25:00,164:INFO:                 pip: 25.0.1
2025-04-19 21:25:00,164:INFO:          setuptools: 65.5.0
2025-04-19 21:25:00,164:INFO:             pycaret: 3.0.4
2025-04-19 21:25:00,164:INFO:             IPython: 8.35.0
2025-04-19 21:25:00,164:INFO:          ipywidgets: 8.1.6
2025-04-19 21:25:00,164:INFO:                tqdm: 4.67.1
2025-04-19 21:25:00,164:INFO:               numpy: 1.23.5
2025-04-19 21:25:00,164:INFO:              pandas: 1.5.3
2025-04-19 21:25:00,164:INFO:              jinja2: 3.1.6
2025-04-19 21:25:00,164:INFO:               scipy: 1.11.4
2025-04-19 21:25:00,164:INFO:              joblib: 1.2.0
2025-04-19 21:25:00,164:INFO:             sklearn: 1.2.2
2025-04-19 21:25:00,164:INFO:                pyod: 2.0.4
2025-04-19 21:25:00,164:INFO:            imblearn: 0.12.4
2025-04-19 21:25:00,164:INFO:   category_encoders: 2.7.0
2025-04-19 21:25:00,164:INFO:            lightgbm: 4.6.0
2025-04-19 21:25:00,164:INFO:               numba: 0.58.1
2025-04-19 21:25:00,164:INFO:            requests: 2.32.3
2025-04-19 21:25:00,164:INFO:          matplotlib: 3.7.1
2025-04-19 21:25:00,164:INFO:          scikitplot: 0.3.7
2025-04-19 21:25:00,164:INFO:         yellowbrick: 1.5
2025-04-19 21:25:00,164:INFO:              plotly: 5.24.1
2025-04-19 21:25:00,164:INFO:    plotly-resampler: Not installed
2025-04-19 21:25:00,164:INFO:             kaleido: 0.2.1
2025-04-19 21:25:00,164:INFO:           schemdraw: 0.15
2025-04-19 21:25:00,164:INFO:         statsmodels: 0.14.4
2025-04-19 21:25:00,164:INFO:              sktime: 0.21.1
2025-04-19 21:25:00,164:INFO:               tbats: 1.1.3
2025-04-19 21:25:00,164:INFO:            pmdarima: 2.0.4
2025-04-19 21:25:00,164:INFO:              psutil: 7.0.0
2025-04-19 21:25:00,164:INFO:          markupsafe: 2.1.5
2025-04-19 21:25:00,164:INFO:             pickle5: Not installed
2025-04-19 21:25:00,164:INFO:         cloudpickle: 2.2.1
2025-04-19 21:25:00,164:INFO:         deprecation: 2.1.0
2025-04-19 21:25:00,164:INFO:              xxhash: 3.5.0
2025-04-19 21:25:00,164:INFO:           wurlitzer: Not installed
2025-04-19 21:25:00,164:INFO:PyCaret optional dependencies:
2025-04-19 21:25:01,528:INFO:                shap: 0.47.2
2025-04-19 21:25:01,528:INFO:           interpret: 0.6.6
2025-04-19 21:25:01,528:INFO:                umap: 0.5.7
2025-04-19 21:25:01,528:INFO:    pandas_profiling: 4.6.0
2025-04-19 21:25:01,528:INFO:  explainerdashboard: 0.4.8
2025-04-19 21:25:01,528:INFO:             autoviz: 0.1.902
2025-04-19 21:25:01,528:INFO:           fairlearn: 0.7.0
2025-04-19 21:25:01,528:INFO:          deepchecks: 0.19.1
2025-04-19 21:25:01,528:INFO:             xgboost: 1.6.2
2025-04-19 21:25:01,528:INFO:            catboost: 1.2.8
2025-04-19 21:25:01,528:INFO:              kmodes: 0.12.2
2025-04-19 21:25:01,528:INFO:             mlxtend: 0.23.1
2025-04-19 21:25:01,528:INFO:       statsforecast: 2.0.1
2025-04-19 21:25:01,528:INFO:        tune_sklearn: 0.5.0
2025-04-19 21:25:01,528:INFO:                 ray: 2.44.1
2025-04-19 21:25:01,528:INFO:            hyperopt: 0.2.7
2025-04-19 21:25:01,528:INFO:              optuna: 4.3.0
2025-04-19 21:25:01,528:INFO:               skopt: 0.10.2
2025-04-19 21:25:01,528:INFO:              mlflow: 2.21.3
2025-04-19 21:25:01,528:INFO:              gradio: 3.50.2
2025-04-19 21:25:01,528:INFO:             fastapi: 0.115.12
2025-04-19 21:25:01,528:INFO:             uvicorn: 0.34.2
2025-04-19 21:25:01,528:INFO:              m2cgen: 0.10.0
2025-04-19 21:25:01,528:INFO:           evidently: 0.2.8
2025-04-19 21:25:01,528:INFO:               fugue: 0.8.6
2025-04-19 21:25:01,528:INFO:           streamlit: Not installed
2025-04-19 21:25:01,528:INFO:             prophet: Not installed
2025-04-19 21:25:01,528:INFO:None
2025-04-19 21:25:01,528:INFO:Set up data.
2025-04-19 21:25:01,541:INFO:Set up train/test split.
2025-04-19 21:25:01,545:INFO:Set up index.
2025-04-19 21:25:01,545:INFO:Set up folding strategy.
2025-04-19 21:25:01,545:INFO:Assigning column types.
2025-04-19 21:25:01,552:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 21:25:01,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,593:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,626:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:01,669:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:01,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,746:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,773:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:01,773:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:01,773:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 21:25:01,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,834:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:01,837:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:01,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 21:25:01,904:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:01,905:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:01,905:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 21:25:01,974:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:01,974:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:02,038:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:02,044:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:02,257:INFO:Preparing preprocessing pipeline...
2025-04-19 21:25:02,267:INFO:Set up simple imputation.
2025-04-19 21:25:02,267:INFO:Set up removing multicollinearity.
2025-04-19 21:25:02,267:INFO:Set up removing outliers.
2025-04-19 21:25:02,267:INFO:Set up feature normalization.
2025-04-19 21:25:02,438:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:02,809:INFO:Finished creating preprocessing pipeline.
2025-04-19 21:25:02,812:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_4', 'feature_66',
                                             'feature_6', 'feature_21',
                                             'feature_58', 'feature_76',
                                             'feature_55', 'feature_19',
                                             'feature_93', 'feature_43',
                                             'feature_28', 'feature_97',
                                             'feature_3', 'feature_49',
                                             'feature_31', 'feature_2...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=42,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 21:25:02,812:INFO:Creating final display dataframe.
2025-04-19 21:25:03,058:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:03,746:INFO:Setup _display_container:                     Description               Value
0                    Session id                  42
1                        Target              target
2                   Target type          Multiclass
3           Original data shape          (7999, 22)
4        Transformed data shape          (7719, 20)
5   Transformed train set shape          (5319, 20)
6    Transformed test set shape          (2400, 20)
7              Numeric features                  21
8      Rows with missing values               35.0%
9                    Preprocess                True
10              Imputation type              simple
11           Numeric imputation                mean
12       Categorical imputation                mode
13     Remove multicollinearity                True
14  Multicollinearity threshold                 0.9
15              Remove outliers                True
16           Outliers threshold                0.05
17                    Normalize                True
18             Normalize method              zscore
19               Fold Generator     StratifiedKFold
20                  Fold Number                  10
21                     CPU Jobs                  -1
22                      Use GPU               False
23               Log Experiment               False
24              Experiment Name  agn_classification
25                          USI                7409
2025-04-19 21:25:03,822:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:03,822:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:03,909:INFO:Soft dependency imported: xgboost: 1.6.2
2025-04-19 21:25:03,909:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-19 21:25:03,912:INFO:setup() successfully completed in 5.08s...............
2025-04-19 21:25:03,912:INFO:Initializing compare_models()
2025-04-19 21:25:03,912:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2025-04-19 21:25:03,912:INFO:Checking exceptions
2025-04-19 21:25:03,913:INFO:Preparing display monitor
2025-04-19 21:25:03,913:INFO:Initializing Logistic Regression
2025-04-19 21:25:03,913:INFO:Total runtime is 0.0 minutes
2025-04-19 21:25:03,913:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:03,913:INFO:Initializing create_model()
2025-04-19 21:25:03,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:03,913:INFO:Checking exceptions
2025-04-19 21:25:03,913:INFO:Importing libraries
2025-04-19 21:25:03,913:INFO:Copying training dataset
2025-04-19 21:25:03,925:INFO:Defining folds
2025-04-19 21:25:03,925:INFO:Declaring metric variables
2025-04-19 21:25:03,925:INFO:Importing untrained model
2025-04-19 21:25:03,925:INFO:Logistic Regression Imported successfully
2025-04-19 21:25:03,925:INFO:Starting cross validation
2025-04-19 21:25:03,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:12,511:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,526:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,562:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,569:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,663:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,694:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:12,707:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:13,070:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:14,631:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:14,787:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 21:25:16,973:INFO:Calculating mean and std
2025-04-19 21:25:16,975:INFO:Creating metrics dataframe
2025-04-19 21:25:17,387:INFO:Uploading results into container
2025-04-19 21:25:17,387:INFO:Uploading model into container now
2025-04-19 21:25:17,387:INFO:_master_model_container: 1
2025-04-19 21:25:17,387:INFO:_display_container: 2
2025-04-19 21:25:17,387:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 21:25:17,387:INFO:create_model() successfully completed......................................
2025-04-19 21:25:17,505:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:17,505:INFO:Creating metrics dataframe
2025-04-19 21:25:17,505:INFO:Initializing K Neighbors Classifier
2025-04-19 21:25:17,505:INFO:Total runtime is 0.22653962373733522 minutes
2025-04-19 21:25:17,505:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:17,505:INFO:Initializing create_model()
2025-04-19 21:25:17,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:17,505:INFO:Checking exceptions
2025-04-19 21:25:17,505:INFO:Importing libraries
2025-04-19 21:25:17,505:INFO:Copying training dataset
2025-04-19 21:25:17,511:INFO:Defining folds
2025-04-19 21:25:17,511:INFO:Declaring metric variables
2025-04-19 21:25:17,511:INFO:Importing untrained model
2025-04-19 21:25:17,511:INFO:K Neighbors Classifier Imported successfully
2025-04-19 21:25:17,511:INFO:Starting cross validation
2025-04-19 21:25:17,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:20,986:INFO:Calculating mean and std
2025-04-19 21:25:20,987:INFO:Creating metrics dataframe
2025-04-19 21:25:21,429:INFO:Uploading results into container
2025-04-19 21:25:21,429:INFO:Uploading model into container now
2025-04-19 21:25:21,429:INFO:_master_model_container: 2
2025-04-19 21:25:21,429:INFO:_display_container: 2
2025-04-19 21:25:21,429:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 21:25:21,429:INFO:create_model() successfully completed......................................
2025-04-19 21:25:21,541:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:21,541:INFO:Creating metrics dataframe
2025-04-19 21:25:21,545:INFO:Initializing Naive Bayes
2025-04-19 21:25:21,545:INFO:Total runtime is 0.2938667098681132 minutes
2025-04-19 21:25:21,545:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:21,545:INFO:Initializing create_model()
2025-04-19 21:25:21,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:21,545:INFO:Checking exceptions
2025-04-19 21:25:21,545:INFO:Importing libraries
2025-04-19 21:25:21,545:INFO:Copying training dataset
2025-04-19 21:25:21,549:INFO:Defining folds
2025-04-19 21:25:21,549:INFO:Declaring metric variables
2025-04-19 21:25:21,549:INFO:Importing untrained model
2025-04-19 21:25:21,549:INFO:Naive Bayes Imported successfully
2025-04-19 21:25:21,551:INFO:Starting cross validation
2025-04-19 21:25:21,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:24,990:INFO:Calculating mean and std
2025-04-19 21:25:24,991:INFO:Creating metrics dataframe
2025-04-19 21:25:25,411:INFO:Uploading results into container
2025-04-19 21:25:25,411:INFO:Uploading model into container now
2025-04-19 21:25:25,411:INFO:_master_model_container: 3
2025-04-19 21:25:25,411:INFO:_display_container: 2
2025-04-19 21:25:25,411:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 21:25:25,411:INFO:create_model() successfully completed......................................
2025-04-19 21:25:25,522:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:25,522:INFO:Creating metrics dataframe
2025-04-19 21:25:25,527:INFO:Initializing Decision Tree Classifier
2025-04-19 21:25:25,527:INFO:Total runtime is 0.3602423469225565 minutes
2025-04-19 21:25:25,527:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:25,527:INFO:Initializing create_model()
2025-04-19 21:25:25,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:25,527:INFO:Checking exceptions
2025-04-19 21:25:25,527:INFO:Importing libraries
2025-04-19 21:25:25,527:INFO:Copying training dataset
2025-04-19 21:25:25,527:INFO:Defining folds
2025-04-19 21:25:25,527:INFO:Declaring metric variables
2025-04-19 21:25:25,527:INFO:Importing untrained model
2025-04-19 21:25:25,527:INFO:Decision Tree Classifier Imported successfully
2025-04-19 21:25:25,527:INFO:Starting cross validation
2025-04-19 21:25:25,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:29,152:INFO:Calculating mean and std
2025-04-19 21:25:29,152:INFO:Creating metrics dataframe
2025-04-19 21:25:29,606:INFO:Uploading results into container
2025-04-19 21:25:29,614:INFO:Uploading model into container now
2025-04-19 21:25:29,614:INFO:_master_model_container: 4
2025-04-19 21:25:29,614:INFO:_display_container: 2
2025-04-19 21:25:29,614:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-19 21:25:29,614:INFO:create_model() successfully completed......................................
2025-04-19 21:25:29,721:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:29,721:INFO:Creating metrics dataframe
2025-04-19 21:25:29,727:INFO:Initializing SVM - Linear Kernel
2025-04-19 21:25:29,727:INFO:Total runtime is 0.4302339275677999 minutes
2025-04-19 21:25:29,727:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:29,727:INFO:Initializing create_model()
2025-04-19 21:25:29,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:29,727:INFO:Checking exceptions
2025-04-19 21:25:29,727:INFO:Importing libraries
2025-04-19 21:25:29,727:INFO:Copying training dataset
2025-04-19 21:25:29,727:INFO:Defining folds
2025-04-19 21:25:29,727:INFO:Declaring metric variables
2025-04-19 21:25:29,727:INFO:Importing untrained model
2025-04-19 21:25:29,727:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 21:25:29,727:INFO:Starting cross validation
2025-04-19 21:25:29,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:30,331:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,331:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,548:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,571:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,600:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,607:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,612:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:25:30,638:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:30,642:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:31,363:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:31,371:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:33,459:INFO:Calculating mean and std
2025-04-19 21:25:33,459:INFO:Creating metrics dataframe
2025-04-19 21:25:33,867:INFO:Uploading results into container
2025-04-19 21:25:33,867:INFO:Uploading model into container now
2025-04-19 21:25:33,867:INFO:_master_model_container: 5
2025-04-19 21:25:33,867:INFO:_display_container: 2
2025-04-19 21:25:33,867:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 21:25:33,867:INFO:create_model() successfully completed......................................
2025-04-19 21:25:33,973:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:33,973:INFO:Creating metrics dataframe
2025-04-19 21:25:33,973:INFO:Initializing Ridge Classifier
2025-04-19 21:25:33,973:INFO:Total runtime is 0.5010005235671997 minutes
2025-04-19 21:25:33,973:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:33,973:INFO:Initializing create_model()
2025-04-19 21:25:33,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:33,973:INFO:Checking exceptions
2025-04-19 21:25:33,973:INFO:Importing libraries
2025-04-19 21:25:33,973:INFO:Copying training dataset
2025-04-19 21:25:33,973:INFO:Defining folds
2025-04-19 21:25:33,973:INFO:Declaring metric variables
2025-04-19 21:25:33,973:INFO:Importing untrained model
2025-04-19 21:25:33,973:INFO:Ridge Classifier Imported successfully
2025-04-19 21:25:33,973:INFO:Starting cross validation
2025-04-19 21:25:33,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:34,149:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,149:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,149:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,163:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,167:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,167:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,171:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,177:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,181:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:25:34,764:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:34,771:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2025-04-19 21:25:36,990:INFO:Calculating mean and std
2025-04-19 21:25:36,990:INFO:Creating metrics dataframe
2025-04-19 21:25:37,418:INFO:Uploading results into container
2025-04-19 21:25:37,418:INFO:Uploading model into container now
2025-04-19 21:25:37,418:INFO:_master_model_container: 6
2025-04-19 21:25:37,418:INFO:_display_container: 2
2025-04-19 21:25:37,418:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 21:25:37,418:INFO:create_model() successfully completed......................................
2025-04-19 21:25:37,527:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:37,527:INFO:Creating metrics dataframe
2025-04-19 21:25:37,532:INFO:Initializing Random Forest Classifier
2025-04-19 21:25:37,532:INFO:Total runtime is 0.5603201746940613 minutes
2025-04-19 21:25:37,532:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:37,532:INFO:Initializing create_model()
2025-04-19 21:25:37,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:37,532:INFO:Checking exceptions
2025-04-19 21:25:37,532:INFO:Importing libraries
2025-04-19 21:25:37,532:INFO:Copying training dataset
2025-04-19 21:25:37,537:INFO:Defining folds
2025-04-19 21:25:37,537:INFO:Declaring metric variables
2025-04-19 21:25:37,537:INFO:Importing untrained model
2025-04-19 21:25:37,537:INFO:Random Forest Classifier Imported successfully
2025-04-19 21:25:37,537:INFO:Starting cross validation
2025-04-19 21:25:37,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:43,101:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:25:43,283:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:25:49,505:INFO:Calculating mean and std
2025-04-19 21:25:49,505:INFO:Creating metrics dataframe
2025-04-19 21:25:49,926:INFO:Uploading results into container
2025-04-19 21:25:49,926:INFO:Uploading model into container now
2025-04-19 21:25:49,926:INFO:_master_model_container: 7
2025-04-19 21:25:49,926:INFO:_display_container: 2
2025-04-19 21:25:49,926:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-19 21:25:49,926:INFO:create_model() successfully completed......................................
2025-04-19 21:25:50,040:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:50,048:INFO:Creating metrics dataframe
2025-04-19 21:25:50,048:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 21:25:50,048:INFO:Total runtime is 0.768911874294281 minutes
2025-04-19 21:25:50,048:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:50,048:INFO:Initializing create_model()
2025-04-19 21:25:50,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:50,048:INFO:Checking exceptions
2025-04-19 21:25:50,048:INFO:Importing libraries
2025-04-19 21:25:50,048:INFO:Copying training dataset
2025-04-19 21:25:50,057:INFO:Defining folds
2025-04-19 21:25:50,057:INFO:Declaring metric variables
2025-04-19 21:25:50,057:INFO:Importing untrained model
2025-04-19 21:25:50,057:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 21:25:50,057:INFO:Starting cross validation
2025-04-19 21:25:50,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:53,573:INFO:Calculating mean and std
2025-04-19 21:25:53,573:INFO:Creating metrics dataframe
2025-04-19 21:25:53,986:INFO:Uploading results into container
2025-04-19 21:25:53,986:INFO:Uploading model into container now
2025-04-19 21:25:53,986:INFO:_master_model_container: 8
2025-04-19 21:25:53,986:INFO:_display_container: 2
2025-04-19 21:25:53,986:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 21:25:53,986:INFO:create_model() successfully completed......................................
2025-04-19 21:25:54,087:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:54,087:INFO:Creating metrics dataframe
2025-04-19 21:25:54,099:INFO:Initializing Ada Boost Classifier
2025-04-19 21:25:54,099:INFO:Total runtime is 0.8364396492640177 minutes
2025-04-19 21:25:54,099:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:54,099:INFO:Initializing create_model()
2025-04-19 21:25:54,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:54,099:INFO:Checking exceptions
2025-04-19 21:25:54,099:INFO:Importing libraries
2025-04-19 21:25:54,099:INFO:Copying training dataset
2025-04-19 21:25:54,105:INFO:Defining folds
2025-04-19 21:25:54,105:INFO:Declaring metric variables
2025-04-19 21:25:54,105:INFO:Importing untrained model
2025-04-19 21:25:54,105:INFO:Ada Boost Classifier Imported successfully
2025-04-19 21:25:54,105:INFO:Starting cross validation
2025-04-19 21:25:54,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:25:59,291:INFO:Calculating mean and std
2025-04-19 21:25:59,292:INFO:Creating metrics dataframe
2025-04-19 21:25:59,825:INFO:Uploading results into container
2025-04-19 21:25:59,826:INFO:Uploading model into container now
2025-04-19 21:25:59,827:INFO:_master_model_container: 9
2025-04-19 21:25:59,827:INFO:_display_container: 2
2025-04-19 21:25:59,828:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-19 21:25:59,828:INFO:create_model() successfully completed......................................
2025-04-19 21:25:59,956:INFO:SubProcess create_model() end ==================================
2025-04-19 21:25:59,963:INFO:Creating metrics dataframe
2025-04-19 21:25:59,971:INFO:Initializing Gradient Boosting Classifier
2025-04-19 21:25:59,971:INFO:Total runtime is 0.9342994451522827 minutes
2025-04-19 21:25:59,971:INFO:SubProcess create_model() called ==================================
2025-04-19 21:25:59,971:INFO:Initializing create_model()
2025-04-19 21:25:59,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:25:59,971:INFO:Checking exceptions
2025-04-19 21:25:59,971:INFO:Importing libraries
2025-04-19 21:25:59,971:INFO:Copying training dataset
2025-04-19 21:25:59,976:INFO:Defining folds
2025-04-19 21:25:59,977:INFO:Declaring metric variables
2025-04-19 21:25:59,977:INFO:Importing untrained model
2025-04-19 21:25:59,977:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 21:25:59,977:INFO:Starting cross validation
2025-04-19 21:25:59,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:27:40,032:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:40,338:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:40,509:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:43,148:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:43,987:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:47,202:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:47,635:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:27:48,974:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:28:39,689:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:28:40,041:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:28:41,435:INFO:Calculating mean and std
2025-04-19 21:28:41,435:INFO:Creating metrics dataframe
2025-04-19 21:28:41,926:INFO:Uploading results into container
2025-04-19 21:28:41,926:INFO:Uploading model into container now
2025-04-19 21:28:41,926:INFO:_master_model_container: 10
2025-04-19 21:28:41,926:INFO:_display_container: 2
2025-04-19 21:28:41,926:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 21:28:41,926:INFO:create_model() successfully completed......................................
2025-04-19 21:28:42,045:INFO:SubProcess create_model() end ==================================
2025-04-19 21:28:42,047:INFO:Creating metrics dataframe
2025-04-19 21:28:42,049:INFO:Initializing Linear Discriminant Analysis
2025-04-19 21:28:42,049:INFO:Total runtime is 3.6356035709381103 minutes
2025-04-19 21:28:42,049:INFO:SubProcess create_model() called ==================================
2025-04-19 21:28:42,054:INFO:Initializing create_model()
2025-04-19 21:28:42,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:28:42,054:INFO:Checking exceptions
2025-04-19 21:28:42,054:INFO:Importing libraries
2025-04-19 21:28:42,054:INFO:Copying training dataset
2025-04-19 21:28:42,054:INFO:Defining folds
2025-04-19 21:28:42,054:INFO:Declaring metric variables
2025-04-19 21:28:42,054:INFO:Importing untrained model
2025-04-19 21:28:42,054:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 21:28:42,054:INFO:Starting cross validation
2025-04-19 21:28:42,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:28:45,053:INFO:Calculating mean and std
2025-04-19 21:28:45,053:INFO:Creating metrics dataframe
2025-04-19 21:28:45,559:INFO:Uploading results into container
2025-04-19 21:28:45,559:INFO:Uploading model into container now
2025-04-19 21:28:45,559:INFO:_master_model_container: 11
2025-04-19 21:28:45,559:INFO:_display_container: 2
2025-04-19 21:28:45,559:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 21:28:45,559:INFO:create_model() successfully completed......................................
2025-04-19 21:28:45,703:INFO:SubProcess create_model() end ==================================
2025-04-19 21:28:45,703:INFO:Creating metrics dataframe
2025-04-19 21:28:45,713:INFO:Initializing Extra Trees Classifier
2025-04-19 21:28:45,713:INFO:Total runtime is 3.696671974658966 minutes
2025-04-19 21:28:45,713:INFO:SubProcess create_model() called ==================================
2025-04-19 21:28:45,713:INFO:Initializing create_model()
2025-04-19 21:28:45,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:28:45,713:INFO:Checking exceptions
2025-04-19 21:28:45,713:INFO:Importing libraries
2025-04-19 21:28:45,713:INFO:Copying training dataset
2025-04-19 21:28:45,719:INFO:Defining folds
2025-04-19 21:28:45,719:INFO:Declaring metric variables
2025-04-19 21:28:45,719:INFO:Importing untrained model
2025-04-19 21:28:45,722:INFO:Extra Trees Classifier Imported successfully
2025-04-19 21:28:45,722:INFO:Starting cross validation
2025-04-19 21:28:45,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:28:52,659:INFO:Calculating mean and std
2025-04-19 21:28:52,659:INFO:Creating metrics dataframe
2025-04-19 21:28:53,118:INFO:Uploading results into container
2025-04-19 21:28:53,118:INFO:Uploading model into container now
2025-04-19 21:28:53,118:INFO:_master_model_container: 12
2025-04-19 21:28:53,118:INFO:_display_container: 2
2025-04-19 21:28:53,118:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 21:28:53,118:INFO:create_model() successfully completed......................................
2025-04-19 21:28:53,247:INFO:SubProcess create_model() end ==================================
2025-04-19 21:28:53,247:INFO:Creating metrics dataframe
2025-04-19 21:28:53,262:INFO:Initializing Extreme Gradient Boosting
2025-04-19 21:28:53,263:INFO:Total runtime is 3.822499120235443 minutes
2025-04-19 21:28:53,263:INFO:SubProcess create_model() called ==================================
2025-04-19 21:28:53,263:INFO:Initializing create_model()
2025-04-19 21:28:53,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:28:53,263:INFO:Checking exceptions
2025-04-19 21:28:53,263:INFO:Importing libraries
2025-04-19 21:28:53,263:INFO:Copying training dataset
2025-04-19 21:28:53,267:INFO:Defining folds
2025-04-19 21:28:53,269:INFO:Declaring metric variables
2025-04-19 21:28:53,269:INFO:Importing untrained model
2025-04-19 21:28:53,269:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:28:53,269:INFO:Starting cross validation
2025-04-19 21:28:53,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:30:00,365:INFO:Calculating mean and std
2025-04-19 21:30:00,378:INFO:Creating metrics dataframe
2025-04-19 21:30:00,802:INFO:Uploading results into container
2025-04-19 21:30:00,802:INFO:Uploading model into container now
2025-04-19 21:30:00,802:INFO:_master_model_container: 13
2025-04-19 21:30:00,802:INFO:_display_container: 2
2025-04-19 21:30:00,811:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=42, reg_alpha=None, ...)
2025-04-19 21:30:00,811:INFO:create_model() successfully completed......................................
2025-04-19 21:30:00,918:INFO:SubProcess create_model() end ==================================
2025-04-19 21:30:00,918:INFO:Creating metrics dataframe
2025-04-19 21:30:00,918:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 21:30:00,918:INFO:Total runtime is 4.9500873168309525 minutes
2025-04-19 21:30:00,918:INFO:SubProcess create_model() called ==================================
2025-04-19 21:30:00,918:INFO:Initializing create_model()
2025-04-19 21:30:00,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:30:00,918:INFO:Checking exceptions
2025-04-19 21:30:00,918:INFO:Importing libraries
2025-04-19 21:30:00,918:INFO:Copying training dataset
2025-04-19 21:30:00,930:INFO:Defining folds
2025-04-19 21:30:00,930:INFO:Declaring metric variables
2025-04-19 21:30:00,930:INFO:Importing untrained model
2025-04-19 21:30:00,930:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:30:00,930:INFO:Starting cross validation
2025-04-19 21:30:00,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:30:30,645:INFO:Calculating mean and std
2025-04-19 21:30:30,645:INFO:Creating metrics dataframe
2025-04-19 21:30:31,135:INFO:Uploading results into container
2025-04-19 21:30:31,135:INFO:Uploading model into container now
2025-04-19 21:30:31,135:INFO:_master_model_container: 14
2025-04-19 21:30:31,135:INFO:_display_container: 2
2025-04-19 21:30:31,135:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 21:30:31,135:INFO:create_model() successfully completed......................................
2025-04-19 21:30:31,272:INFO:SubProcess create_model() end ==================================
2025-04-19 21:30:31,272:INFO:Creating metrics dataframe
2025-04-19 21:30:31,278:INFO:Initializing Dummy Classifier
2025-04-19 21:30:31,278:INFO:Total runtime is 5.456083472569783 minutes
2025-04-19 21:30:31,278:INFO:SubProcess create_model() called ==================================
2025-04-19 21:30:31,278:INFO:Initializing create_model()
2025-04-19 21:30:31,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021840211510>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:30:31,278:INFO:Checking exceptions
2025-04-19 21:30:31,278:INFO:Importing libraries
2025-04-19 21:30:31,278:INFO:Copying training dataset
2025-04-19 21:30:31,287:INFO:Defining folds
2025-04-19 21:30:31,287:INFO:Declaring metric variables
2025-04-19 21:30:31,287:INFO:Importing untrained model
2025-04-19 21:30:31,287:INFO:Dummy Classifier Imported successfully
2025-04-19 21:30:31,288:INFO:Starting cross validation
2025-04-19 21:30:31,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:30:31,488:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,496:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,498:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,498:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,505:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,507:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,525:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:31,537:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:32,183:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:32,228:WARNING:D:\College\agn\venv_py310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 21:30:34,303:INFO:Calculating mean and std
2025-04-19 21:30:34,303:INFO:Creating metrics dataframe
2025-04-19 21:30:34,718:INFO:Uploading results into container
2025-04-19 21:30:34,718:INFO:Uploading model into container now
2025-04-19 21:30:34,718:INFO:_master_model_container: 15
2025-04-19 21:30:34,718:INFO:_display_container: 2
2025-04-19 21:30:34,718:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 21:30:34,718:INFO:create_model() successfully completed......................................
2025-04-19 21:30:34,835:INFO:SubProcess create_model() end ==================================
2025-04-19 21:30:34,835:INFO:Creating metrics dataframe
2025-04-19 21:30:34,835:INFO:Initializing create_model()
2025-04-19 21:30:34,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:30:34,841:INFO:Checking exceptions
2025-04-19 21:30:34,841:INFO:Importing libraries
2025-04-19 21:30:34,841:INFO:Copying training dataset
2025-04-19 21:30:34,847:INFO:Defining folds
2025-04-19 21:30:34,847:INFO:Declaring metric variables
2025-04-19 21:30:34,847:INFO:Importing untrained model
2025-04-19 21:30:34,847:INFO:Declaring custom model
2025-04-19 21:30:34,847:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 21:30:34,857:INFO:Cross validation set to False
2025-04-19 21:30:34,857:INFO:Fitting Model
2025-04-19 21:30:35,227:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 21:30:35,227:INFO:create_model() successfully completed......................................
2025-04-19 21:30:35,340:INFO:Initializing create_model()
2025-04-19 21:30:35,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:30:35,340:INFO:Checking exceptions
2025-04-19 21:30:35,340:INFO:Importing libraries
2025-04-19 21:30:35,340:INFO:Copying training dataset
2025-04-19 21:30:35,344:INFO:Defining folds
2025-04-19 21:30:35,344:INFO:Declaring metric variables
2025-04-19 21:30:35,344:INFO:Importing untrained model
2025-04-19 21:30:35,344:INFO:Declaring custom model
2025-04-19 21:30:35,346:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:30:35,352:INFO:Cross validation set to False
2025-04-19 21:30:35,352:INFO:Fitting Model
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2025-04-19 21:30:35,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Total Bins 4845
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Number of data points in the train set: 5319, number of used features: 19
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.022213
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.871930
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.003091
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.973239
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.026081
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.984329
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.065612
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.944251
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.933594
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -2.999311
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.098402
2025-04-19 21:30:35,432:INFO:[LightGBM] [Info] Start training from score -3.090103
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.995544
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -3.003091
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.991792
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.988054
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -3.010696
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.973239
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.995544
2025-04-19 21:30:35,435:INFO:[LightGBM] [Info] Start training from score -2.969569
2025-04-19 21:30:37,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 21:30:37,708:INFO:create_model() successfully completed......................................
2025-04-19 21:30:37,822:INFO:Initializing create_model()
2025-04-19 21:30:37,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=42, reg_alpha=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:30:37,822:INFO:Checking exceptions
2025-04-19 21:30:37,822:INFO:Importing libraries
2025-04-19 21:30:37,822:INFO:Copying training dataset
2025-04-19 21:30:37,838:INFO:Defining folds
2025-04-19 21:30:37,838:INFO:Declaring metric variables
2025-04-19 21:30:37,838:INFO:Importing untrained model
2025-04-19 21:30:37,838:INFO:Declaring custom model
2025-04-19 21:30:37,838:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:30:37,849:INFO:Cross validation set to False
2025-04-19 21:30:37,849:INFO:Fitting Model
2025-04-19 21:30:45,716:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...)
2025-04-19 21:30:45,716:INFO:create_model() successfully completed......................................
2025-04-19 21:30:45,830:INFO:_master_model_container: 15
2025-04-19 21:30:45,830:INFO:_display_container: 2
2025-04-19 21:30:45,836:INFO:[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...)]
2025-04-19 21:30:45,836:INFO:compare_models() successfully completed......................................
2025-04-19 21:30:45,836:INFO:Initializing tune_model()
2025-04-19 21:30:45,836:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>)
2025-04-19 21:30:45,836:INFO:Checking exceptions
2025-04-19 21:30:45,836:INFO:Copying training dataset
2025-04-19 21:30:45,845:INFO:Checking base model
2025-04-19 21:30:45,846:INFO:Base model : Quadratic Discriminant Analysis
2025-04-19 21:30:45,846:INFO:Declaring metric variables
2025-04-19 21:30:45,846:INFO:Defining Hyperparameters
2025-04-19 21:30:45,971:INFO:Tuning with n_jobs=-1
2025-04-19 21:30:45,971:INFO:Initializing RandomizedSearchCV
2025-04-19 21:31:17,321:INFO:best_params: {'actual_estimator__reg_param': 0.14}
2025-04-19 21:31:17,321:INFO:Hyperparameter search completed
2025-04-19 21:31:17,321:INFO:SubProcess create_model() called ==================================
2025-04-19 21:31:17,321:INFO:Initializing create_model()
2025-04-19 21:31:17,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002183C10BEB0>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.14})
2025-04-19 21:31:17,321:INFO:Checking exceptions
2025-04-19 21:31:17,321:INFO:Importing libraries
2025-04-19 21:31:17,321:INFO:Copying training dataset
2025-04-19 21:31:17,321:INFO:Defining folds
2025-04-19 21:31:17,321:INFO:Declaring metric variables
2025-04-19 21:31:17,321:INFO:Importing untrained model
2025-04-19 21:31:17,321:INFO:Declaring custom model
2025-04-19 21:31:17,321:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 21:31:17,321:INFO:Starting cross validation
2025-04-19 21:31:17,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:31:20,334:INFO:Calculating mean and std
2025-04-19 21:31:20,334:INFO:Creating metrics dataframe
2025-04-19 21:31:20,340:INFO:Finalizing model
2025-04-19 21:31:20,793:INFO:Uploading results into container
2025-04-19 21:31:20,793:INFO:Uploading model into container now
2025-04-19 21:31:20,793:INFO:_master_model_container: 16
2025-04-19 21:31:20,793:INFO:_display_container: 3
2025-04-19 21:31:20,793:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001)
2025-04-19 21:31:20,793:INFO:create_model() successfully completed......................................
2025-04-19 21:31:20,907:INFO:SubProcess create_model() end ==================================
2025-04-19 21:31:20,907:INFO:choose_better activated
2025-04-19 21:31:20,907:INFO:SubProcess create_model() called ==================================
2025-04-19 21:31:20,907:INFO:Initializing create_model()
2025-04-19 21:31:20,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:31:20,907:INFO:Checking exceptions
2025-04-19 21:31:20,907:INFO:Importing libraries
2025-04-19 21:31:20,907:INFO:Copying training dataset
2025-04-19 21:31:20,915:INFO:Defining folds
2025-04-19 21:31:20,915:INFO:Declaring metric variables
2025-04-19 21:31:20,915:INFO:Importing untrained model
2025-04-19 21:31:20,915:INFO:Declaring custom model
2025-04-19 21:31:20,915:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 21:31:20,915:INFO:Starting cross validation
2025-04-19 21:31:20,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:31:23,927:INFO:Calculating mean and std
2025-04-19 21:31:23,927:INFO:Creating metrics dataframe
2025-04-19 21:31:23,927:INFO:Finalizing model
2025-04-19 21:31:24,442:INFO:Uploading results into container
2025-04-19 21:31:24,442:INFO:Uploading model into container now
2025-04-19 21:31:24,442:INFO:_master_model_container: 17
2025-04-19 21:31:24,442:INFO:_display_container: 4
2025-04-19 21:31:24,442:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 21:31:24,442:INFO:create_model() successfully completed......................................
2025-04-19 21:31:24,562:INFO:SubProcess create_model() end ==================================
2025-04-19 21:31:24,562:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for AUC is 0.6649
2025-04-19 21:31:24,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001) result for AUC is 0.6716
2025-04-19 21:31:24,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001) is best model
2025-04-19 21:31:24,564:INFO:choose_better completed
2025-04-19 21:31:24,564:INFO:_master_model_container: 17
2025-04-19 21:31:24,564:INFO:_display_container: 3
2025-04-19 21:31:24,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001)
2025-04-19 21:31:24,564:INFO:tune_model() successfully completed......................................
2025-04-19 21:31:24,921:INFO:Initializing tune_model()
2025-04-19 21:31:24,921:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>)
2025-04-19 21:31:24,921:INFO:Checking exceptions
2025-04-19 21:31:24,937:INFO:Copying training dataset
2025-04-19 21:31:24,937:INFO:Checking base model
2025-04-19 21:31:24,937:INFO:Base model : Light Gradient Boosting Machine
2025-04-19 21:31:24,937:INFO:Declaring metric variables
2025-04-19 21:31:24,937:INFO:Defining Hyperparameters
2025-04-19 21:31:25,059:INFO:Tuning with n_jobs=-1
2025-04-19 21:31:25,059:INFO:Initializing RandomizedSearchCV
2025-04-19 21:35:25,229:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 86, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2025-04-19 21:35:25,229:INFO:Hyperparameter search completed
2025-04-19 21:35:25,229:INFO:SubProcess create_model() called ==================================
2025-04-19 21:35:25,231:INFO:Initializing create_model()
2025-04-19 21:35:25,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002183D93A8C0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.001, 'reg_alpha': 2, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.9, 'min_child_samples': 86, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2025-04-19 21:35:25,231:INFO:Checking exceptions
2025-04-19 21:35:25,231:INFO:Importing libraries
2025-04-19 21:35:25,231:INFO:Copying training dataset
2025-04-19 21:35:25,243:INFO:Defining folds
2025-04-19 21:35:25,243:INFO:Declaring metric variables
2025-04-19 21:35:25,243:INFO:Importing untrained model
2025-04-19 21:35:25,243:INFO:Declaring custom model
2025-04-19 21:35:25,247:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:35:25,247:INFO:Starting cross validation
2025-04-19 21:35:25,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:35:26,745:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:35:31,698:INFO:Calculating mean and std
2025-04-19 21:35:31,698:INFO:Creating metrics dataframe
2025-04-19 21:35:31,698:INFO:Finalizing model
2025-04-19 21:35:31,774:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-19 21:35:31,774:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-19 21:35:31,774:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-19 21:35:31,782:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-04-19 21:35:31,784:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2025-04-19 21:35:31,784:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2025-04-19 21:35:31,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-04-19 21:35:31,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-19 21:35:31,784:INFO:[LightGBM] [Info] Total Bins 4845
2025-04-19 21:35:31,784:INFO:[LightGBM] [Info] Number of data points in the train set: 5319, number of used features: 19
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -3.022213
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.871930
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -3.003091
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.973239
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -3.026081
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.984329
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -3.065612
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.944251
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.933594
2025-04-19 21:35:31,786:INFO:[LightGBM] [Info] Start training from score -2.999311
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -3.098402
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -3.090103
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.995544
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -3.003091
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.991792
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.988054
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -3.010696
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.973239
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.995544
2025-04-19 21:35:31,788:INFO:[LightGBM] [Info] Start training from score -2.969569
2025-04-19 21:35:31,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:32,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:33,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 21:35:34,550:INFO:Uploading results into container
2025-04-19 21:35:34,550:INFO:Uploading model into container now
2025-04-19 21:35:34,550:INFO:_master_model_container: 18
2025-04-19 21:35:34,550:INFO:_display_container: 4
2025-04-19 21:35:34,550:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 21:35:34,550:INFO:create_model() successfully completed......................................
2025-04-19 21:35:34,689:INFO:SubProcess create_model() end ==================================
2025-04-19 21:35:34,689:INFO:choose_better activated
2025-04-19 21:35:34,689:INFO:SubProcess create_model() called ==================================
2025-04-19 21:35:34,689:INFO:Initializing create_model()
2025-04-19 21:35:34,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:35:34,689:INFO:Checking exceptions
2025-04-19 21:35:34,689:INFO:Importing libraries
2025-04-19 21:35:34,689:INFO:Copying training dataset
2025-04-19 21:35:34,702:INFO:Defining folds
2025-04-19 21:35:34,707:INFO:Declaring metric variables
2025-04-19 21:35:34,707:INFO:Importing untrained model
2025-04-19 21:35:34,707:INFO:Declaring custom model
2025-04-19 21:35:34,710:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 21:35:34,710:INFO:Starting cross validation
2025-04-19 21:35:34,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:35:36,855:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:35:36,869:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:35:41,106:INFO:Calculating mean and std
2025-04-19 21:35:41,106:INFO:Creating metrics dataframe
2025-04-19 21:35:41,106:INFO:Finalizing model
2025-04-19 21:35:41,700:INFO:Uploading results into container
2025-04-19 21:35:41,700:INFO:Uploading model into container now
2025-04-19 21:35:41,700:INFO:_master_model_container: 19
2025-04-19 21:35:41,700:INFO:_display_container: 5
2025-04-19 21:35:41,700:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 21:35:41,700:INFO:create_model() successfully completed......................................
2025-04-19 21:35:41,811:INFO:SubProcess create_model() end ==================================
2025-04-19 21:35:41,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.6257
2025-04-19 21:35:41,813:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.6211
2025-04-19 21:35:41,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-04-19 21:35:41,813:INFO:choose_better completed
2025-04-19 21:35:41,815:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-19 21:35:41,815:INFO:_master_model_container: 19
2025-04-19 21:35:41,815:INFO:_display_container: 4
2025-04-19 21:35:41,824:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 21:35:41,824:INFO:tune_model() successfully completed......................................
2025-04-19 21:35:42,231:INFO:Initializing tune_model()
2025-04-19 21:35:42,231:INFO:tune_model(estimator=XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>)
2025-04-19 21:35:42,231:INFO:Checking exceptions
2025-04-19 21:35:42,231:INFO:Copying training dataset
2025-04-19 21:35:42,246:INFO:Checking base model
2025-04-19 21:35:42,246:INFO:Base model : Extreme Gradient Boosting
2025-04-19 21:35:42,246:INFO:Declaring metric variables
2025-04-19 21:35:42,246:INFO:Defining Hyperparameters
2025-04-19 21:35:42,357:INFO:Tuning with n_jobs=-1
2025-04-19 21:35:42,357:INFO:Initializing RandomizedSearchCV
2025-04-19 21:42:32,563:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2025-04-19 21:42:33,883:WARNING:D:\College\agn\venv_py310\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2025-04-19 21:44:46,849:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__scale_pos_weight': 33.0, 'actual_estimator__reg_lambda': 0.15, 'actual_estimator__reg_alpha': 10, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__colsample_bytree': 0.7}
2025-04-19 21:44:46,849:INFO:Hyperparameter search completed
2025-04-19 21:44:46,849:INFO:SubProcess create_model() called ==================================
2025-04-19 21:44:46,849:INFO:Initializing create_model()
2025-04-19 21:44:46,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002184463CA30>, model_only=True, return_train_score=False, kwargs={'subsample': 0.9, 'scale_pos_weight': 33.0, 'reg_lambda': 0.15, 'reg_alpha': 10, 'n_estimators': 170, 'min_child_weight': 2, 'max_depth': 8, 'learning_rate': 0.3, 'colsample_bytree': 0.7})
2025-04-19 21:44:46,849:INFO:Checking exceptions
2025-04-19 21:44:46,849:INFO:Importing libraries
2025-04-19 21:44:46,849:INFO:Copying training dataset
2025-04-19 21:44:46,853:INFO:Defining folds
2025-04-19 21:44:46,855:INFO:Declaring metric variables
2025-04-19 21:44:46,855:INFO:Importing untrained model
2025-04-19 21:44:46,855:INFO:Declaring custom model
2025-04-19 21:44:46,855:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:44:46,855:INFO:Starting cross validation
2025-04-19 21:44:46,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:44:59,246:INFO:Calculating mean and std
2025-04-19 21:44:59,246:INFO:Creating metrics dataframe
2025-04-19 21:44:59,248:INFO:Finalizing model
2025-04-19 21:45:08,138:INFO:Uploading results into container
2025-04-19 21:45:08,138:INFO:Uploading model into container now
2025-04-19 21:45:08,138:INFO:_master_model_container: 20
2025-04-19 21:45:08,138:INFO:_display_container: 5
2025-04-19 21:45:08,141:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,
              missing=nan, monotone_constraints='()', n_estimators=170,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=10, ...)
2025-04-19 21:45:08,141:INFO:create_model() successfully completed......................................
2025-04-19 21:45:08,252:INFO:SubProcess create_model() end ==================================
2025-04-19 21:45:08,252:INFO:choose_better activated
2025-04-19 21:45:08,252:INFO:SubProcess create_model() called ==================================
2025-04-19 21:45:08,252:INFO:Initializing create_model()
2025-04-19 21:45:08,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:45:08,252:INFO:Checking exceptions
2025-04-19 21:45:08,252:INFO:Importing libraries
2025-04-19 21:45:08,252:INFO:Copying training dataset
2025-04-19 21:45:08,252:INFO:Defining folds
2025-04-19 21:45:08,252:INFO:Declaring metric variables
2025-04-19 21:45:08,252:INFO:Importing untrained model
2025-04-19 21:45:08,252:INFO:Declaring custom model
2025-04-19 21:45:08,252:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 21:45:08,252:INFO:Starting cross validation
2025-04-19 21:45:08,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 21:55:47,398:INFO:Calculating mean and std
2025-04-19 21:55:47,398:INFO:Creating metrics dataframe
2025-04-19 21:55:47,406:INFO:Finalizing model
2025-04-19 21:55:54,842:INFO:Uploading results into container
2025-04-19 21:55:54,842:INFO:Uploading model into container now
2025-04-19 21:55:54,845:INFO:_master_model_container: 21
2025-04-19 21:55:54,845:INFO:_display_container: 6
2025-04-19 21:55:54,845:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...)
2025-04-19 21:55:54,845:INFO:create_model() successfully completed......................................
2025-04-19 21:55:54,949:INFO:SubProcess create_model() end ==================================
2025-04-19 21:55:54,949:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=0, ...) result for AUC is 0.6227
2025-04-19 21:55:54,949:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,
              missing=nan, monotone_constraints='()', n_estimators=170,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=10, ...) result for AUC is 0.6286
2025-04-19 21:55:54,949:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,
              missing=nan, monotone_constraints='()', n_estimators=170,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=10, ...) is best model
2025-04-19 21:55:54,949:INFO:choose_better completed
2025-04-19 21:55:54,949:INFO:_master_model_container: 21
2025-04-19 21:55:54,949:INFO:_display_container: 5
2025-04-19 21:55:54,964:INFO:XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,
              missing=nan, monotone_constraints='()', n_estimators=170,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=10, ...)
2025-04-19 21:55:54,964:INFO:tune_model() successfully completed......................................
2025-04-19 21:55:55,343:INFO:Initializing blend_models()
2025-04-19 21:55:55,343:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator_list=[QuadraticDiscriminantAnalysis(priors=None, reg_param=0.14,
                              store_covariance=False, tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,
              missing=nan, monotone_constraints='()', n_estimators=170,
              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',
              predictor='auto', random_state=42, reg_alpha=10, ...)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2025-04-19 21:55:55,343:INFO:Checking exceptions
2025-04-19 21:55:55,343:INFO:Importing libraries
2025-04-19 21:55:55,343:INFO:Copying training dataset
2025-04-19 21:55:55,343:INFO:Getting model names
2025-04-19 21:55:55,343:INFO:SubProcess create_model() called ==================================
2025-04-19 21:55:55,358:INFO:Initializing create_model()
2025-04-19 21:55:55,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002183F60E440>, estimator=VotingClassifier(estimators=[('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.14,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_we...
                                            learning_rate=0.3, max_bin=256,
                                            max_cat_to_onehot=4,
                                            max_delta_step=0, max_depth=8,
                                            max_leaves=0, min_child_weight=2,
                                            missing=nan,
                                            monotone_constraints='()',
                                            n_estimators=170, n_jobs=-1,
                                            num_parallel_tree=1,
                                            objective='multi:softprob',
                                            predictor='auto', random_state=42,
                                            reg_alpha=10, ...))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002183DA20CD0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 21:55:55,360:INFO:Checking exceptions
2025-04-19 21:55:55,360:INFO:Importing libraries
2025-04-19 21:55:55,360:INFO:Copying training dataset
2025-04-19 21:55:55,364:INFO:Defining folds
2025-04-19 21:55:55,364:INFO:Declaring metric variables
2025-04-19 21:55:55,364:INFO:Importing untrained model
2025-04-19 21:55:55,364:INFO:Declaring custom model
2025-04-19 21:55:55,364:INFO:Voting Classifier Imported successfully
2025-04-19 21:55:55,364:INFO:Starting cross validation
2025-04-19 21:55:55,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
